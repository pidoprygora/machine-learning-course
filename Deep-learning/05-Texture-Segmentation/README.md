# Texture / Object Segmentation (Сегментація текстур та об'єктів)

## Опис лабораторної

Ця лабораторна робота розширює попередню **Object Detection** і фокусується на
**сегментації об'єктів / текстур** (виділення пікселів об'єкта на фоні).

Реалізовано:

- **Власний детектор (40%)** – невелика U-Net‑подібна модель для бінарної
  сегментації класу `person` (людина) на основі датасету PASCAL VOC 2012.
- **Pre-trained детектор (20%)** – використання попередньо навченої моделі
  **DeepLabV3** з TensorFlow Hub.
- **ROC‑крива для 2‑класової задачі (20%)** – побудова ROC‑кривої для задачі
  `object (person) vs background`, порівняння власної моделі та pre-trained.
- **Live‑режим (20%)** – сегментація людей в реальному часі з веб‑камери.

Не використовується багато класів – фокус на одній сутності: **людина** (`person`)
проти **фону** (background), тобто **2 класи**.

## Використані дані

- **PASCAL VOC 2012 (segmentation)** – відкритий датасет зі
  **семантичною сегментацією**.
- Для лапки використовується **невеликий піднабір** (наприклад, 40 train +
  10 test зображень) – цього достатньо для демонстраційних цілей і не
  перевантажує CPU/GPU.
- Клас інтересу – **`person`**, всі інші пікселі вважаються фоном.

За бажанням, студент може **додати власні зображення** (наприклад, з веб‑камери,
людей, машин тощо) й використати їх для якісного аналізу роботи моделей.

## Структура проєкту

```text
Deep-learning/05-Texture-Segmentation/
│
├── main.py                    # Головний скрипт лабораторної
├── requirements.txt           # Залежності
├── README.md                  # Поточний файл (опис)
│
├── data/                      # (опціонально) додаткові зображення користувача
│   └── ...
│
├── models/                    # Збережені ваги власного детектора
│   └── simple_unet_person.h5
│
└── results/                   # Згенеровані результати
    ├── own_detector_history.csv
    ├── own_detector_y_true.npy
    ├── own_detector_y_prob.npy
    ├── deeplab_y_true.npy
    ├── deeplab_y_prob.npy
    ├── roc_curves_person_segmentation.png
    ├── live_segmentation_*.jpg
    └── ...
```

## Встановлення

### Вимоги

- Python 3.8+
- pip
- Веб‑камера (для live‑режиму)
- Бажано GPU, але робота можлива і на CPU (з меншим піднабором даних)

### Встановлення залежностей

```bash
cd Deep-learning/05-Texture-Segmentation

# (Опціонально) створення віртуального середовища
python -m venv venv

# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Встановлення залежностей
pip install -r requirements.txt
```

## Запуск

```bash
python main.py
```

Після запуску з'являється меню:

- **1** – навчити **власний сегментаційний детектор** (U-Net‑подібна модель) та
  оцінити його на test‑піднаборі.
- **2** – оцінити **pre-trained DeepLabV3** на тому ж test‑піднаборі.
- **3** – побудувати **ROC‑криву** для задачі `person vs background`
  (порівняння власної моделі та DeepLab).
- **4** – запустити **live‑сегментацію з веб‑камери** (DeepLabV3).
- **5** – виконати все послідовно: `1 → 2 → 3`.

## Деталі реалізації вимог

### 1. Власний детектор (40%)

- Архітектура: невеликий **U-Net‑подібний** сегментаційний детектор:
  - Encoder: кілька Conv+ReLU + MaxPool блоків.
  - Decoder: UpSampling + skip‑connection з encoder рівнями.
  - Вихід: карта ймовірностей `person` розміром `H×W×1` (через `sigmoid`).
- Навчання:
  - Датасет: **PASCAL VOC 2012**, клас `person`.
  - Лосс: `binary_crossentropy` (2 класи: person vs background).
  - Метрики: `accuracy` + додатково обчислюються **IoU** та **Dice**.
  - Використовується **EarlyStopping** по `val_loss`.
- Результати:
  - Зберігається `own_detector_history.csv` (loss/accuracy train/val по епохах).
  - Зберігаються вектори `y_true` та `y_prob` для побудови ROC.

### 2. Pre-trained детектор (20%)

- Використовується **DeepLabV3** з TensorFlow Hub (`voc/2012` класи).
- Для кожного зображення обчислюється **pixel-wise розподіл ймовірностей**
  по класах, береться канал для `person`.
- Після ресайзу й узгодження розміру отримується **карта ймовірностей** класу
  `person` для кожного пікселя.
- Оцінка:
  - **IoU** та **Dice** на test‑піднаборі.
  - Збір `y_true` і `y_prob` для побудови ROC‑кривої.

### 3. ROC‑крива для 2‑класової задачі (20%)

- Формулювання задачі: **бінарна класифікація пікселів** –
  `person` (1) vs `background` (0).
- Для **власної моделі** та **DeepLabV3**:
  - Обчислюються `y_true` (істинні мітки пікселів) та `y_prob` (ймовірність
    приналежності до класу `person`).
  - За допомогою `sklearn.metrics.roc_curve` та `roc_auc_score` будується
    ROC‑крива та обчислюється AUC.
- Зберігається графік `results/roc_curves_person_segmentation.png`, де на одному
  малюнку відображено:
  - ROC для власної моделі.
  - ROC для pre-trained DeepLabV3.
  - Лінія випадкового класифікатора (діагональ).

### 4. Live‑режим (20%)

- Використовується **DeepLabV3** як швидкий та точний pre-trained сегментатор.
- Pipeline:
  1. Читання кадру з веб‑камери (OpenCV).
  2. Ресайз, нормалізація.
  3. Прогон через DeepLabV3 → карта ймовірностей класу `person`.
  4. Порогування за `confidence_threshold` (регулюється клавішами `+`/`-`).
  5. Накладання маски на вихідний кадр (напівпрозорий червоний overlay).
  6. Вивід FPS, поточного threshold тощо.
- Керування:
  - `q` або `ESC` – вихід.
  - `+` / `-` – збільшити / зменшити threshold сегментації.
  - `s` – зберегти поточний кадр до `results/live_segmentation_*.jpg`.

## Як адаптувати під інші об'єкти (обличчя, фігури, машини тощо)

Хоча базова реалізація орієнтована на клас `person`, її можна легко
переналаштувати:

- **Інший клас VOC** (наприклад, `car`, `bus`):
  - змінити `TARGET_CLASS_ID` у `main.py` на відповідний індекс VOC,
  - перезапустити навчання власної моделі.
- **Власні дані** (обличчя, силуети людей, машини з камери):
  - зібрати невеликий набір зображень,
  - підготувати бінарні маски (object vs background),
  - замінити джерело даних у функції завантаження датасету на власний loader.

Таким чином, структура лабораторної повністю відповідає вимогам:

- **Є власний детектор**, натренований на відкритих даних.
- **Є pre-trained детектор** (DeepLabV3).
- **Є ROC‑крива** для бінарної задачі.
- **Є live‑режим** сегментації з веб‑камери.


