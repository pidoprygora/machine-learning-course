"""
Texture Segmentation / Binary Semantic Segmentation
–§–æ–∫—É—Å: –ø—Ä–æ—Å—Ç–∏–π –≤–ª–∞—Å–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä + pre-trained –º–æ–¥–µ–ª—å + ROC + live-—Ä–µ–∂–∏–º

–©–æ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ:
- –í–ª–∞—Å–Ω–∏–π –Ω–µ–≤–µ–ª–∏–∫–∏–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (2 –∫–ª–∞—Å–∏: –æ–±'—î–∫—Ç vs —Ñ–æ–Ω) –Ω–∞ –±–∞–∑—ñ TF/Keras
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ MobileNet SSD (OpenCV DNN) –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –ª—é–¥–µ–π
- –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –Ω–∞ —Ç–µ—Å—Ç-—Å–µ—Ç—ñ (accuracy, IoU, Dice)
- ROC-–∫—Ä–∏–≤–∞ –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∑–∞–¥–∞—á—ñ (–æ–±'—î–∫—Ç vs —Ñ–æ–Ω)
- Live-—Ä–µ–∂–∏–º: –¥–µ—Ç–µ–∫—Ü—ñ—è/—Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –æ–±'—î–∫—Ç—ñ–≤ —É –ø–æ—Ç–æ—Ü—ñ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏
"""

import time
import urllib.request
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report

from typing import Tuple, Optional

import cv2


# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
tf.random.set_seed(42)
np.random.seed(42)

sns.set(style="whitegrid", context="notebook")
plt.rcParams["figure.figsize"] = (12, 8)
plt.rcParams["font.size"] = 10

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
OUTPUT_DIR = Path("results")
OUTPUT_DIR.mkdir(exist_ok=True)

DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

MODELS_DIR = Path("models")
MODELS_DIR.mkdir(exist_ok=True)


def print_section(title: str) -> None:
    """–ö—Ä–∞—Å–∏–≤–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü—ñ—ó –≤ –∫–æ–Ω—Å–æ–ª—ñ."""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


# ---------------------------------------------------------------------------
# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–æ—Å—Ç–∏—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö (–±—ñ–Ω–∞—Ä–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è)
# ---------------------------------------------------------------------------

TARGET_CLASS_NAME = "object"
IMG_SIZE = (256, 256)
BATCH_SIZE = 4


def _generate_synthetic_image_and_mask() -> Tuple[np.ndarray, np.ndarray]:
    """
    –ì–µ–Ω–µ—Ä—É—î –ø—Ä–æ—Å—Ç–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–∞ –º–∞—Å–∫—É:
    - —Ñ–æ–Ω: —à—É–º/—Ç–µ–∫—Å—Ç—É—Ä–∞
    - –æ–±'—î–∫—Ç: –≤–∏–ø–∞–¥–∫–æ–≤–µ –∫–æ–ª–æ –∞–±–æ –∫–≤–∞–¥—Ä–∞—Ç –∑ —ñ–Ω—à–æ—é —Ç–µ–∫—Å—Ç—É—Ä–æ—é
    """
    h, w = IMG_SIZE

    # –§–æ–Ω ‚Äî –≤–∏–ø–∞–¥–∫–æ–≤–∏–π "—Ç–µ–∫—Å—Ç—É—Ä–æ–≤–∞–Ω–∏–π" —à—É–º
    background = np.random.uniform(0.0, 0.4, size=(h, w, 1)).astype(np.float32)
    noise = np.random.normal(loc=0.0, scale=0.05, size=(h, w, 1)).astype(np.float32)
    img = background + noise
    img = np.clip(img, 0.0, 1.0)
    img = np.repeat(img, 3, axis=-1)  # —Ä–æ–±–∏–º–æ 3 –∫–∞–Ω–∞–ª–∏

    # –ú–∞—Å–∫–∞ –æ–±'—î–∫—Ç–∞
    mask = np.zeros((h, w, 1), dtype=np.float32)

    # –í–∏–ø–∞–¥–∫–æ–≤–∏–π –æ–±'—î–∫—Ç: –∫–æ–ª–æ –∞–±–æ –∫–≤–∞–¥—Ä–∞—Ç
    shape_type = np.random.choice(["circle", "square"])
    cy = np.random.randint(h // 4, 3 * h // 4)
    cx = np.random.randint(w // 4, 3 * w // 4)
    r = np.random.randint(min(h, w) // 8, min(h, w) // 4)

    yy, xx = np.ogrid[:h, :w]

    if shape_type == "circle":
        dist_sq = (yy - cy) ** 2 + (xx - cx) ** 2
        obj_region = dist_sq <= r ** 2
    else:  # square
        y_min = max(cy - r, 0)
        y_max = min(cy + r, h)
        x_min = max(cx - r, 0)
        x_max = min(cx + r, w)
        obj_region = np.zeros((h, w), dtype=bool)
        obj_region[y_min:y_max, x_min:x_max] = True

    mask[obj_region, 0] = 1.0

    # –Ü–Ω—à–∞ —Ç–µ–∫—Å—Ç—É—Ä–∞/–∫–æ–ª—ñ—Ä –¥–ª—è –æ–±'—î–∫—Ç–∞
    color = np.random.uniform(0.6, 1.0, size=(1, 1, 3)).astype(np.float32)
    img[obj_region] = color

    # –¢—Ä–æ—Ö–∏ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —à—É–º—É
    img += np.random.normal(0.0, 0.03, size=img.shape).astype(np.float32)
    img = np.clip(img, 0.0, 1.0)

    return img.astype(np.float32), mask.astype(np.float32)


def _create_synthetic_dataset(num_samples: int) -> Tuple[np.ndarray, np.ndarray]:
    """–ì–µ–Ω–µ—Ä—É—î –Ω–∞–±—ñ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —ñ –º–∞—Å–æ–∫."""
    images = np.zeros((num_samples, IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)
    masks = np.zeros((num_samples, IMG_SIZE[0], IMG_SIZE[1], 1), dtype=np.float32)

    for i in range(num_samples):
        img, m = _generate_synthetic_image_and_mask()
        images[i] = img
        masks[i] = m

    return images, masks


def load_synthetic_dataset(
    num_train: int = 40,
    num_test: int = 10,
) -> Tuple[tf.data.Dataset, tf.data.Dataset]:
    """
    –ì–µ–Ω–µ—Ä—É—î —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó (object vs background).
    –ü–æ–≤–Ω—ñ—Å—Ç—é –æ—Ñ–ª–∞–π–Ω, –±–µ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤.
    """
    print_section("–ì–ï–ù–ï–†–ê–¶–Ü–Ø –°–ò–ù–¢–ï–¢–ò–ß–ù–ò–• –î–ê–ù–ò–• (object vs background)")

    train_images, train_masks = _create_synthetic_dataset(num_train)
    test_images, test_masks = _create_synthetic_dataset(num_test)

    train_ds = (
        tf.data.Dataset.from_tensor_slices((train_images, train_masks))
        .shuffle(100)
        .batch(BATCH_SIZE)
        .prefetch(tf.data.AUTOTUNE)
    )

    test_ds = (
        tf.data.Dataset.from_tensor_slices((test_images, test_masks))
        .batch(BATCH_SIZE)
        .prefetch(tf.data.AUTOTUNE)
    )

    print(f"\n‚úì –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ train –ø—Ä–∏–∫–ª–∞–¥—ñ–≤: {num_train}")
    print(f"‚úì –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ test –ø—Ä–∏–∫–ª–∞–¥—ñ–≤:  {num_test}")

    return train_ds, test_ds


def visualize_synthetic_samples(num_samples: int = 6) -> None:
    """
    –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫—ñ–ª—å–∫–æ—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ (–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è + –º–∞—Å–∫–∞).
    """
    print_section("–í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –°–ò–ù–¢–ï–¢–ò–ß–ù–ò–• –î–ê–ù–ò–•")

    num_samples = max(1, num_samples)
    images, masks = _create_synthetic_dataset(num_samples)

    fig, axes = plt.subplots(num_samples, 2, figsize=(8, 3 * num_samples))
    if num_samples == 1:
        axes = np.expand_dims(axes, axis=0)

    for i in range(num_samples):
        img = images[i]
        mask = masks[i, ..., 0]

        axes[i, 0].imshow(img)
        axes[i, 0].set_title(f"–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è #{i+1}", fontsize=10)
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray", vmin=0, vmax=1)
        axes[i, 1].set_title(f"–ú–∞—Å–∫–∞ –æ–±'—î–∫—Ç–∞ #{i+1}", fontsize=10)
        axes[i, 1].axis("off")

    plt.tight_layout()
    out_path = OUTPUT_DIR / "synthetic_samples.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {out_path}")
    plt.close(fig)


# ---------------------------------------------------------------------------
# 2. –í–ª–∞—Å–Ω–∏–π –ø—Ä–æ—Å—Ç–∏–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (–Ω–µ–≤–µ–ª–∏–∫–∏–π U-Net‚Äë–ø–æ–¥—ñ–±–Ω–∏–π)
# ---------------------------------------------------------------------------


def build_simple_unet(input_shape=(256, 256, 3)) -> keras.Model:
    """
    –ù–µ–≤–µ–ª–∏–∫–∞ U-Net‚Äë–ø–æ–¥—ñ–±–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó.
    –í–∏—Ö—ñ–¥: –∫–∞—Ä—Ç–∞ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π [H, W, 1] (—á–µ—Ä–µ–∑ —Å–∏–≥–º–æ—ó–¥—É).
    """
    inputs = keras.Input(shape=input_shape)

    # Encoder
    x1 = layers.Conv2D(32, 3, padding="same", activation="relu")(inputs)
    x1 = layers.Conv2D(32, 3, padding="same", activation="relu")(x1)
    p1 = layers.MaxPool2D(2)(x1)

    x2 = layers.Conv2D(64, 3, padding="same", activation="relu")(p1)
    x2 = layers.Conv2D(64, 3, padding="same", activation="relu")(x2)
    p2 = layers.MaxPool2D(2)(x2)

    x3 = layers.Conv2D(128, 3, padding="same", activation="relu")(p2)
    x3 = layers.Conv2D(128, 3, padding="same", activation="relu")(x3)

    # Decoder
    u2 = layers.UpSampling2D(2)(x3)
    u2 = layers.Concatenate()([u2, x2])
    x4 = layers.Conv2D(64, 3, padding="same", activation="relu")(u2)
    x4 = layers.Conv2D(64, 3, padding="same", activation="relu")(x4)

    u1 = layers.UpSampling2D(2)(x4)
    u1 = layers.Concatenate()([u1, x1])
    x5 = layers.Conv2D(32, 3, padding="same", activation="relu")(u1)
    x5 = layers.Conv2D(32, 3, padding="same", activation="relu")(x5)

    outputs = layers.Conv2D(1, 1, activation="sigmoid")(x5)

    model = keras.Model(inputs, outputs, name="simple_unet_object")
    model.compile(
        optimizer=keras.optimizers.Adam(1e-3),
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    return model


def train_own_detector(
    num_train: int = 40,
    num_test: int = 10,
    epochs: int = 5,
):
    """–ù–∞–≤—á–∞–Ω–Ω—è –≤–ª–∞—Å–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ç–∞ –æ—Ü—ñ–Ω–∫–∞ –Ω–∞ test set."""
    print_section("–í–õ–ê–°–ù–ò–ô –°–ï–ì–ú–ï–ù–¢–ê–¶–Ü–ô–ù–ò–ô –î–ï–¢–ï–ö–¢–û–† (TRAIN & EVAL)")

    # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ
    try:
        visualize_synthetic_samples(num_samples=4)
    except Exception as e:
        print(f"\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {e}")

    train_ds, test_ds = load_synthetic_dataset(num_train=num_train, num_test=num_test)

    model_path = MODELS_DIR / "simple_unet_object.h5"

    # –ó–∞–≤–∂–¥–∏ –ø–µ—Ä–µ–Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó
    print("\n  –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ...")
    model = build_simple_unet(input_shape=(*IMG_SIZE, 3))
    model.summary()

    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor="val_loss",
            patience=3,
            restore_best_weights=True,
        )
    ]

    print("\n  –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
    history = model.fit(
        train_ds,
        validation_data=test_ds,
        epochs=epochs,
        callbacks=callbacks,
        verbose=1,
    )

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –Ω–∞–≤—á–∞–Ω–Ω—è
    hist_df = pd.DataFrame(history.history)
    hist_df.to_csv(OUTPUT_DIR / "own_detector_history.csv", index=False)
    print(f"\n‚úì –Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ results/own_detector_history.csv")

    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–≤—á–∞–Ω–Ω—è
    plot_training_history(hist_df)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
    model.save(model_path)
    print(f"‚úì –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ {model_path}")

    # –û—Ü—ñ–Ω–∫–∞ –Ω–∞ test set
    print("\n  –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ –Ω–∞ test set...")
    metrics = model.evaluate(test_ds, verbose=1)
    metric_names = model.metrics_names
    metrics_dict = dict(zip(metric_names, metrics))

    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –≤–ª–∞—Å–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞:")
    for k, v in metrics_dict.items():
        print(f"  {k}: {v:.4f}")

    # –û–±—á–∏—Å–ª—é—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ (IoU, Dice) —Ç–∞ –∑–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –¥–ª—è ROC
    y_true_all = []
    y_prob_all = []

    for images, masks in test_ds:
        probs = model.predict(images, verbose=0)
        y_true_all.append(masks.numpy().ravel())
        y_prob_all.append(probs.ravel())

    y_true_all = np.concatenate(y_true_all, axis=0)
    y_prob_all = np.concatenate(y_prob_all, axis=0)

    # –ë—ñ–Ω–∞—Ä–Ω—ñ –ø—Ä–µ–¥–∏–∫—Ç–∏ –ø—Ä–∏ threshold=0.5
    y_pred_bin = (y_prob_all >= 0.5).astype(np.float32)

    intersection = np.sum(y_true_all * y_pred_bin)
    union = np.sum(y_true_all) + np.sum(y_pred_bin) - intersection
    iou = intersection / (union + 1e-8)
    dice = 2 * intersection / (np.sum(y_true_all) + np.sum(y_pred_bin) + 1e-8)

    print(f"\nüìê –î–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ (threshold=0.5):")
    print(f"  IoU:  {iou:.4f}")
    print(f"  Dice: {dice:.4f}")

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–∞—Å–∏–≤–∏ –¥–ª—è ROC
    np.save(OUTPUT_DIR / "own_detector_y_true.npy", y_true_all)
    np.save(OUTPUT_DIR / "own_detector_y_prob.npy", y_prob_all)
    print("\n‚úì –î–∞–Ω—ñ –¥–ª—è ROC –≤–ª–∞—Å–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ (y_true/y_prob)")

    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    try:
        visualize_segmentation_examples(model, test_ds, num_examples=4)
    except Exception as e:
        print(f"\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó: {e}")

    try:
        plot_probability_histograms(y_true_all, y_prob_all)
    except Exception as e:
        print(f"\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –≥—ñ—Å—Ç–æ–≥—Ä–∞–º—É –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π: {e}")

    try:
        plot_confusion_matrix_segmentation(y_true_all, y_pred_bin)
    except Exception as e:
        print(f"\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ confusion matrix: {e}")

    try:
        plot_iou_vs_threshold(y_true_all, y_prob_all)
    except Exception as e:
        print(f"\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ IoU vs threshold: {e}")

    return model, y_true_all, y_prob_all


def plot_training_history(hist_df: pd.DataFrame) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–≤—á–∞–Ω–Ω—è."""
    print_section("–í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –Ü–°–¢–û–†–Ü–á –ù–ê–í–ß–ê–ù–ù–Ø")

    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # Loss
    axes[0].plot(hist_df["loss"], label="Train Loss", marker="o")
    if "val_loss" in hist_df.columns:
        axes[0].plot(hist_df["val_loss"], label="Val Loss", marker="s")
    axes[0].set_xlabel("Epoch")
    axes[0].set_ylabel("Loss")
    axes[0].set_title("–§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç")
    axes[0].legend()
    axes[0].grid(alpha=0.3)

    # Accuracy
    axes[1].plot(hist_df["accuracy"], label="Train Accuracy", marker="o")
    if "val_accuracy" in hist_df.columns:
        axes[1].plot(hist_df["val_accuracy"], label="Val Accuracy", marker="s")
    axes[1].set_xlabel("Epoch")
    axes[1].set_ylabel("Accuracy")
    axes[1].set_title("–¢–æ—á–Ω—ñ—Å—Ç—å")
    axes[1].legend()
    axes[1].grid(alpha=0.3)

    plt.tight_layout()
    out_path = OUTPUT_DIR / "training_history.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–≤—á–∞–Ω–Ω—è: {out_path}")
    plt.close(fig)


def visualize_segmentation_examples(
    model: keras.Model,
    test_ds: tf.data.Dataset,
    num_examples: int = 4,
) -> None:
    """
    –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–±–æ—Ç–∏ –≤–ª–∞—Å–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞:
    –¥–ª—è –∫—ñ–ª—å–∫–æ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å –ø–æ–∫–∞–∑—É—î–º–æ: –æ—Ä–∏–≥—ñ–Ω–∞–ª, GT –º–∞—Å–∫—É, –ø—Ä–µ–¥–∏–∫—Ç–æ–≤–∞–Ω—É –º–∞—Å–∫—É, –æ–≤–µ—Ä–ª–µ–π.
    """
    print_section("–í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –ü–†–ò–ö–õ–ê–î–Ü–í –°–ï–ì–ú–ï–ù–¢–ê–¶–Ü–á (–í–õ–ê–°–ù–ò–ô –î–ï–¢–ï–ö–¢–û–†)")

    images_list = []
    masks_list = []

    for images, masks in test_ds:
        for i in range(images.shape[0]):
            images_list.append(images[i].numpy())
            masks_list.append(masks[i].numpy())
            if len(images_list) >= num_examples:
                break
        if len(images_list) >= num_examples:
            break

    if not images_list:
        print("‚ö† –ù–µ–º–∞—î –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ —É test_ds –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó.")
        return

    images_arr = np.stack(images_list, axis=0)
    masks_arr = np.stack(masks_list, axis=0)

    preds = model.predict(images_arr, verbose=0)
    preds_bin = (preds >= 0.5).astype(np.float32)

    n = images_arr.shape[0]
    fig, axes = plt.subplots(n, 4, figsize=(14, 3.5 * n))
    if n == 1:
        axes = np.expand_dims(axes, axis=0)

    for i in range(n):
        img = images_arr[i]
        gt = masks_arr[i, ..., 0]
        pr = preds_bin[i, ..., 0]
        pr_prob = preds[i, ..., 0]

        # –û–≤–µ—Ä–ª–µ–π
        overlay = img.copy()
        overlay_color = np.zeros_like(img)
        overlay_color[..., 1] = pr  # green channel
        overlay = 0.6 * overlay + 0.4 * overlay_color

        axes[i, 0].imshow(img)
        axes[i, 0].set_title("–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è", fontsize=10)
        axes[i, 0].axis("off")

        axes[i, 1].imshow(gt, cmap="gray", vmin=0, vmax=1)
        axes[i, 1].set_title("GT –º–∞—Å–∫–∞", fontsize=10)
        axes[i, 1].axis("off")

        axes[i, 2].imshow(pr_prob, cmap="hot", vmin=0, vmax=1)
        axes[i, 2].set_title("–ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ", fontsize=10)
        axes[i, 2].axis("off")

        axes[i, 3].imshow(overlay)
        axes[i, 3].set_title("–û–≤–µ—Ä–ª–µ–π", fontsize=10)
        axes[i, 3].axis("off")

    plt.tight_layout()
    out_path = OUTPUT_DIR / "own_detector_segmentation_examples.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó –≤–ª–∞—Å–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {out_path}")
    plt.close(fig)


def plot_probability_histograms(y_true: np.ndarray, y_prob: np.ndarray) -> None:
    """
    –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö —Ç–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –ø—ñ–∫—Å–µ–ª—ñ–≤.
    """
    print_section("–†–û–ó–ü–û–î–Ü–õ –ô–ú–û–í–Ü–†–ù–û–°–¢–ï–ô (–í–õ–ê–°–ù–ò–ô –î–ï–¢–ï–ö–¢–û–†)")

    y_true = y_true.astype(np.float32)
    pos = y_prob[y_true == 1]
    neg = y_prob[y_true == 0]

    plt.figure(figsize=(10, 6))
    bins = np.linspace(0.0, 1.0, 50)
    plt.hist(neg, bins=bins, alpha=0.6, label=f"background (n={len(neg):,})", color="steelblue", density=True)
    plt.hist(pos, bins=bins, alpha=0.6, label=f"object (n={len(pos):,})", color="orange", density=True)
    plt.axvline(x=0.5, color="red", linestyle="--", label="Threshold = 0.5")
    plt.xlabel("–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—É 'object'")
    plt.ylabel("–©—ñ–ª—å–Ω—ñ—Å—Ç—å")
    plt.title("–†–æ–∑–ø–æ–¥—ñ–ª –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø—ñ–∫—Å–µ–ª—ñ–≤ (object vs background)")
    plt.legend()
    plt.grid(alpha=0.3)

    out_path = OUTPUT_DIR / "own_detector_probability_hist.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≥—ñ—Å—Ç–æ–≥—Ä–∞–º—É –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π: {out_path}")
    plt.close()


def plot_confusion_matrix_segmentation(y_true: np.ndarray, y_pred: np.ndarray) -> None:
    """Confusion matrix –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó."""
    print_section("CONFUSION MATRIX (–í–õ–ê–°–ù–ò–ô –î–ï–¢–ï–ö–¢–û–†)")

    cm = confusion_matrix(y_true.astype(int), y_pred.astype(int))

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Background", "Object"],
                yticklabels=["Background", "Object"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix (pixel-level)")

    out_path = OUTPUT_DIR / "confusion_matrix.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ confusion matrix: {out_path}")
    plt.close()

    # Classification report
    print("\nüìä Classification Report:")
    print(classification_report(y_true.astype(int), y_pred.astype(int),
                                target_names=["Background", "Object"]))


def plot_iou_vs_threshold(y_true: np.ndarray, y_prob: np.ndarray) -> None:
    """–ì—Ä–∞—Ñ—ñ–∫ IoU –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ –ø–æ—Ä–æ–≥—É."""
    print_section("IoU vs THRESHOLD")

    thresholds = np.linspace(0.1, 0.9, 17)
    ious = []
    dices = []

    for thr in thresholds:
        y_pred = (y_prob >= thr).astype(np.float32)
        intersection = np.sum(y_true * y_pred)
        union = np.sum(y_true) + np.sum(y_pred) - intersection
        iou = intersection / (union + 1e-8)
        dice = 2 * intersection / (np.sum(y_true) + np.sum(y_pred) + 1e-8)
        ious.append(iou)
        dices.append(dice)

    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, ious, marker="o", label="IoU", linewidth=2)
    plt.plot(thresholds, dices, marker="s", label="Dice", linewidth=2)
    plt.axvline(x=0.5, color="red", linestyle="--", alpha=0.7, label="Default threshold")
    plt.xlabel("Threshold")
    plt.ylabel("Score")
    plt.title("IoU —Ç–∞ Dice –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ –ø–æ—Ä–æ–≥—É")
    plt.legend()
    plt.grid(alpha=0.3)

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥
    best_idx = np.argmax(ious)
    best_thr = thresholds[best_idx]
    best_iou = ious[best_idx]
    plt.scatter([best_thr], [best_iou], color="green", s=100, zorder=5, label=f"Best IoU={best_iou:.3f} @ thr={best_thr:.2f}")
    plt.legend()

    out_path = OUTPUT_DIR / "iou_vs_threshold.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ IoU vs threshold: {out_path}")
    print(f"  –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥: {best_thr:.2f} (IoU = {best_iou:.4f})")
    plt.close()


# ---------------------------------------------------------------------------
# 3. Pre-trained –¥–µ—Ç–µ–∫—Ç–æ—Ä (OpenCV Haar Cascade –¥–ª—è –æ–±–ª–∏—á—å)
# ---------------------------------------------------------------------------

# Haar Cascade –≤–∂–µ –≤–±—É–¥–æ–≤–∞–Ω–∏–π –≤ OpenCV ‚Äî –Ω—ñ—á–æ–≥–æ –∫–∞—á–∞—Ç–∏ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ!
FACE_CASCADE_NAME = "haarcascade_frontalface_default.xml"


def load_haar_cascade():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Haar Cascade –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±–ª–∏—á—å (–≤–±—É–¥–æ–≤–∞–Ω–∏–π –≤ OpenCV)."""
    print_section("–ü–û–ü–ï–†–ï–î–ù–¨–û –ù–ê–í–ß–ï–ù–ò–ô –î–ï–¢–ï–ö–¢–û–† (Haar Cascade - –û–±–ª–∏—á—á—è)")

    # –®–ª—è—Ö –¥–æ –∫–∞—Å–∫–∞–¥—É –≤ OpenCV
    cascade_path = cv2.data.haarcascades + FACE_CASCADE_NAME

    print(f"  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–∞—Å–∫–∞–¥—É: {cascade_path}")

    face_cascade = cv2.CascadeClassifier(cascade_path)

    if face_cascade.empty():
        print("\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Haar Cascade.")
        return None

    print("\n‚úì Haar Cascade –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
    print("  –î–µ—Ç–µ–∫—Ç–æ—Ä: –æ–±–ª–∏—á—á—è (frontal face)")
    print("  –ü–µ—Ä–µ–≤–∞–≥–∏: —à–≤–∏–¥–∫–∏–π, –æ—Ñ–ª–∞–π–Ω, –Ω–µ –ø–æ—Ç—Ä–µ–±—É—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")
    return face_cascade


def detect_faces_haar(cascade, image: np.ndarray, scale_factor: float = 1.1, min_neighbors: int = 5):
    """
    –î–µ—Ç–µ–∫—Ü—ñ—è –æ–±–ª–∏—á—å –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Haar Cascade.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ bounding boxes —Ç–∞ confidence scores (—Ñ—ñ–∫—Ç–∏–≤–Ω—ñ, –±–æ Haar –Ω–µ –¥–∞—î score).
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ grayscale
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # –î–µ—Ç–µ–∫—Ü—ñ—è
    faces = cascade.detectMultiScale(
        gray,
        scaleFactor=scale_factor,
        minNeighbors=min_neighbors,
        minSize=(30, 30),
        flags=cv2.CASCADE_SCALE_IMAGE
    )

    boxes = []
    scores = []

    for (x, y, w, h) in faces:
        boxes.append([x, y, x + w, y + h])
        # Haar Cascade –Ω–µ –ø–æ–≤–µ—Ä—Ç–∞—î confidence, —Å—Ç–∞–≤–∏–º–æ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
        scores.append(0.9)

    return boxes, scores


def create_detection_mask(boxes: list, image_shape: tuple) -> np.ndarray:
    """–°—Ç–≤–æ—Ä—é—î –±—ñ–Ω–∞—Ä–Ω—É –º–∞—Å–∫—É –∑ bounding boxes."""
    h, w = image_shape[:2]
    mask = np.zeros((h, w), dtype=np.float32)

    for box in boxes:
        x1, y1, x2, y2 = box
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(w, x2)
        y2 = min(h, y2)
        mask[y1:y2, x1:x2] = 1.0

    return mask


def evaluate_pretrained_detector(num_test: int = 20):
    """
    –û—Ü—ñ–Ω–∫–∞ pre-trained Haar Cascade –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö.
    –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –≥–µ–Ω–µ—Ä—É—î–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ "–æ–±–ª–∏—á—á—è" (–∫–æ–ª–∞ –∑ "–æ—á–∏–º–∞").
    """
    print_section("–û–¶–Ü–ù–ö–ê PRE-TRAINED –î–ï–¢–ï–ö–¢–û–†–ê (Haar Cascade - –û–±–ª–∏—á—á—è)")

    cascade = load_haar_cascade()
    if cascade is None:
        print("\n‚ö† Pre-trained –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π.")
        return None, None, None

    print("\n  ‚ÑπÔ∏è  –ü—Ä–∏–º—ñ—Ç–∫–∞: Haar Cascade —à—É–∫–∞—î –æ–±–ª–∏—á—á—è.")
    print("     –ì–µ–Ω–µ—Ä—É—î–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ '–æ–±–ª–∏—á—á—è' –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó...")

    # –ì–µ–Ω–µ—Ä—É—î–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ "–æ–±–ª–∏—á—á—è" (–æ–≤–∞–ª–∏ –∑ –æ—á–∏–º–∞)
    test_images, test_masks = _create_face_like_dataset(num_test)

    y_true_all = []
    y_prob_all = []

    for i in range(num_test):
        img = (test_images[i] * 255).astype(np.uint8)
        mask = test_masks[i, ..., 0]

        # –î–µ—Ç–µ–∫—Ü—ñ—è
        boxes, scores = detect_faces_haar(cascade, img)

        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–∞—Å–∫—É –¥–µ—Ç–µ–∫—Ü—ñ–π
        prob_mask = np.zeros_like(mask)
        for box, score in zip(boxes, scores):
            x1, y1, x2, y2 = box
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(mask.shape[1], x2)
            y2 = min(mask.shape[0], y2)
            prob_mask[y1:y2, x1:x2] = score

        y_true_all.append(mask.ravel())
        y_prob_all.append(prob_mask.ravel())

    y_true_all = np.concatenate(y_true_all, axis=0)
    y_prob_all = np.concatenate(y_prob_all, axis=0)

    # –ú–µ—Ç—Ä–∏–∫–∏
    y_pred_bin = (y_prob_all >= 0.5).astype(np.float32)
    intersection = np.sum(y_true_all * y_pred_bin)
    union = np.sum(y_true_all) + np.sum(y_pred_bin) - intersection
    iou = intersection / (union + 1e-8)

    print(f"\nüìê –ú–µ—Ç—Ä–∏–∫–∏ Haar Cascade (–Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö):")
    print(f"  IoU: {iou:.4f}")
    print("  (Haar —à—É–∫–∞—î —Ä–µ–∞–ª—å–Ω—ñ –æ–±–ª–∏—á—á—è ‚Äî –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—Ü—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ –±—É—Ç–∏ –Ω–∏–∑—å–∫–∏–º)")

    np.save(OUTPUT_DIR / "pretrained_y_true.npy", y_true_all)
    np.save(OUTPUT_DIR / "pretrained_y_prob.npy", y_prob_all)
    print("\n‚úì –î–∞–Ω—ñ –¥–ª—è ROC pre-trained –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ")

    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–µ—Ç–µ–∫—Ü—ñ–π
    visualize_pretrained_detections(cascade, test_images[:4])

    return cascade, y_true_all, y_prob_all


def _create_face_like_dataset(num_samples: int) -> Tuple[np.ndarray, np.ndarray]:
    """–ì–µ–Ω–µ—Ä—É—î —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ '–æ–±–ª–∏—á—á—è' –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è Haar Cascade."""
    images = np.zeros((num_samples, IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)
    masks = np.zeros((num_samples, IMG_SIZE[0], IMG_SIZE[1], 1), dtype=np.float32)

    h, w = IMG_SIZE

    for i in range(num_samples):
        # –§–æ–Ω
        img = np.random.uniform(0.1, 0.3, size=(h, w, 3)).astype(np.float32)

        # –û–≤–∞–ª "–æ–±–ª–∏—á—á—è"
        cy = np.random.randint(h // 3, 2 * h // 3)
        cx = np.random.randint(w // 3, 2 * w // 3)
        ry = np.random.randint(h // 6, h // 4)
        rx = np.random.randint(w // 8, w // 5)

        yy, xx = np.ogrid[:h, :w]
        ellipse = ((yy - cy) / ry) ** 2 + ((xx - cx) / rx) ** 2 <= 1

        # –ö–æ–ª—ñ—Ä "—à–∫—ñ—Ä–∏"
        skin_color = np.array([0.8, 0.7, 0.6], dtype=np.float32)
        img[ellipse] = skin_color + np.random.normal(0, 0.05, 3)

        # "–û—á—ñ" (—Ç–µ–º–Ω—ñ –∫–æ–ª–∞)
        eye_y = cy - ry // 3
        eye_x_left = cx - rx // 2
        eye_x_right = cx + rx // 2
        eye_r = max(3, rx // 6)

        for ex in [eye_x_left, eye_x_right]:
            eye_mask = (yy - eye_y) ** 2 + (xx - ex) ** 2 <= eye_r ** 2
            img[eye_mask] = np.array([0.1, 0.1, 0.1])

        # –ú–∞—Å–∫–∞
        mask = np.zeros((h, w, 1), dtype=np.float32)
        mask[ellipse, 0] = 1.0

        images[i] = np.clip(img, 0, 1)
        masks[i] = mask

    return images, masks


def visualize_pretrained_detections(cascade, images: np.ndarray, num_examples: int = 4) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–µ—Ç–µ–∫—Ü—ñ–π Haar Cascade."""
    print_section("–í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–ï–¢–ï–ö–¶–Ü–ô (Haar Cascade)")

    n = min(num_examples, len(images))
    fig, axes = plt.subplots(n, 2, figsize=(12, 4 * n))
    if n == 1:
        axes = np.expand_dims(axes, axis=0)

    for i in range(n):
        img = (images[i] * 255).astype(np.uint8)

        boxes, scores = detect_faces_haar(cascade, img)

        # –ú–∞–ª—é—î–º–æ boxes
        img_with_boxes = img.copy()
        for box, score in zip(boxes, scores):
            x1, y1, x2, y2 = box
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img_with_boxes, f"face",
                       (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        axes[i, 0].imshow(img)
        axes[i, 0].set_title("–û—Ä–∏–≥—ñ–Ω–∞–ª (—Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–µ '–æ–±–ª–∏—á—á—è')", fontsize=10)
        axes[i, 0].axis("off")

        axes[i, 1].imshow(img_with_boxes)
        axes[i, 1].set_title(f"–î–µ—Ç–µ–∫—Ü—ñ—ó ({len(boxes)} –∑–Ω–∞–π–¥–µ–Ω–æ)", fontsize=10)
        axes[i, 1].axis("off")

    plt.tight_layout()
    out_path = OUTPUT_DIR / "pretrained_detections.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–∏–∫–ª–∞–¥–∏ –¥–µ—Ç–µ–∫—Ü—ñ–π: {out_path}")
    plt.close(fig)


# ---------------------------------------------------------------------------
# 4. ROC-–∫—Ä–∏–≤–∞ –¥–ª—è 2‚Äë–∫–ª–∞—Å–æ–≤–æ—ó –∑–∞–¥–∞—á—ñ (object vs background)
# ---------------------------------------------------------------------------


def plot_roc_curves(
    own_y_true: np.ndarray,
    own_y_prob: np.ndarray,
    pretrained_y_true: Optional[np.ndarray] = None,
    pretrained_y_prob: Optional[np.ndarray] = None,
) -> None:
    """
    –ú–∞–ª—é—î ROC-–∫—Ä–∏–≤—É –¥–ª—è –≤–ª–∞—Å–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ç–∞ (–æ–ø—Ü—ñ–π–Ω–æ) pre-trained.
    """
    print_section("ROC-–ö–†–ò–í–ê –î–õ–Ø 2-–ö–õ–ê–°–û–í–û–á –ó–ê–î–ê–ß–Ü (OBJECT vs BACKGROUND)")

    plt.figure(figsize=(10, 8))

    # –í–ª–∞—Å–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä
    fpr_own, tpr_own, _ = roc_curve(own_y_true, own_y_prob)
    auc_own = roc_auc_score(own_y_true, own_y_prob)
    plt.plot(fpr_own, tpr_own, label=f"–í–ª–∞—Å–Ω–∏–π U-Net –¥–µ—Ç–µ–∫—Ç–æ—Ä (AUC = {auc_own:.3f})", lw=2, color="blue")

    # Pre-trained –¥–µ—Ç–µ–∫—Ç–æ—Ä
    if pretrained_y_true is not None and pretrained_y_prob is not None:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å
        if len(np.unique(pretrained_y_prob)) > 1:
            fpr_pt, tpr_pt, _ = roc_curve(pretrained_y_true, pretrained_y_prob)
            auc_pt = roc_auc_score(pretrained_y_true, pretrained_y_prob)
            plt.plot(fpr_pt, tpr_pt, label=f"Pre-trained MobileNet SSD (AUC = {auc_pt:.3f})",
                    lw=2, linestyle="--", color="green")

    # –í–∏–ø–∞–¥–∫–æ–≤–∏–π –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä
    plt.plot([0, 1], [0, 1], "k--", label="–í–∏–ø–∞–¥–∫–æ–≤–∏–π –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä (AUC = 0.5)", alpha=0.5)

    plt.xlabel("False Positive Rate", fontsize=12)
    plt.ylabel("True Positive Rate", fontsize=12)
    plt.title("ROC-–∫—Ä–∏–≤–∞: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è 'object' vs 'background'", fontsize=14)
    plt.legend(loc="lower right", fontsize=10)
    plt.grid(alpha=0.3)

    # –î–æ–¥–∞—î–º–æ –∞–Ω–æ—Ç–∞—Ü—ñ—ó
    plt.annotate(f"AUC –≤–ª–∞—Å–Ω–æ–≥–æ = {auc_own:.3f}", xy=(0.6, 0.3), fontsize=11,
                bbox=dict(boxstyle="round", facecolor="lightblue", alpha=0.8))

    out_path = OUTPUT_DIR / "roc_curves.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    print(f"\n‚úì ROC-–∫—Ä–∏–≤–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞ –≤ {out_path}")
    plt.show()


# ---------------------------------------------------------------------------
# 5. Live-—Ä–µ–∂–∏–º: –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏ (MobileNet SSD)
# ---------------------------------------------------------------------------


def live_detection(min_neighbors: int = 5):
    """
    Live-—Ä–µ–∂–∏–º: –¥–µ—Ç–µ–∫—Ü—ñ—è –æ–±–ª–∏—á—å —É –ø–æ—Ç–æ—Ü—ñ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Haar Cascade.
    """
    print_section("LIVE –î–ï–¢–ï–ö–¶–Ü–Ø –ó –í–ï–ë-–ö–ê–ú–ï–†–ò (Haar Cascade - –û–±–ª–∏—á—á—è)")

    cascade = load_haar_cascade()
    if cascade is None:
        print("\n‚ö† Live-–¥–µ—Ç–µ–∫—Ü—ñ—è –Ω–µ–º–æ–∂–ª–∏–≤–∞.")
        return

    print("\n  –í—ñ–¥–∫—Ä–∏—Ç—Ç—è –≤–µ–±-–∫–∞–º–µ—Ä–∏...")
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤–µ–±-–∫–∞–º–µ—Ä—É")
        return

    print("\n‚úì Live-–¥–µ—Ç–µ–∫—Ü—ñ—è –∑–∞–ø—É—â–µ–Ω–∞!")
    print("\n  –ö–µ—Ä—É–≤–∞–Ω–Ω—è:")
    print("    - 'q' –∞–±–æ 'ESC' ‚Äî –≤–∏—Ö—ñ–¥")
    print("    - '+' ‚Äî –∑–±—ñ–ª—å—à–∏—Ç–∏ min_neighbors (–º–µ–Ω—à–µ –¥–µ—Ç–µ–∫—Ü—ñ–π, —Ç–æ—á–Ω—ñ—à–µ)")
    print("    - '-' ‚Äî –∑–º–µ–Ω—à–∏—Ç–∏ min_neighbors (–±—ñ–ª—å—à–µ –¥–µ—Ç–µ–∫—Ü—ñ–π)")
    print("    - 's' ‚Äî –∑–±–µ—Ä–µ–≥—Ç–∏ –∫–∞–¥—Ä")

    fps_history = []
    saved_frames = 0

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∫–∞–¥—Ä")
                break

            start_time = time.time()

            # –î–µ—Ç–µ–∫—Ü—ñ—è
            boxes, scores = detect_faces_haar(cascade, frame, min_neighbors=min_neighbors)

            # –ú–∞–ª—é—î–º–æ boxes
            for box, score in zip(boxes, scores):
                x1, y1, x2, y2 = box
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, "face", (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            # FPS
            dt = time.time() - start_time
            fps = 1.0 / dt if dt > 0 else 0.0
            fps_history.append(fps)
            if len(fps_history) > 30:
                fps_history.pop(0)
            avg_fps = np.mean(fps_history)

            # Info overlay
            info_lines = [
                f"FPS: {avg_fps:.1f}",
                f"Min neighbors: {min_neighbors}",
                f"Faces: {len(boxes)}",
            ]

            y = 30
            for line in info_lines:
                cv2.putText(frame, line, (10, y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                y += 30

            cv2.imshow("Live Detection - Haar Cascade (Face)", frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord("q") or key == 27:
                print("\n  –ó—É–ø–∏–Ω–∫–∞...")
                break
            elif key == ord("+") or key == ord("="):
                min_neighbors = min(15, min_neighbors + 1)
                print(f"  Min neighbors: {min_neighbors}")
            elif key == ord("-") or key == ord("_"):
                min_neighbors = max(1, min_neighbors - 1)
                print(f"  Min neighbors: {min_neighbors}")
            elif key == ord("s"):
                saved_frames += 1
                out_path = OUTPUT_DIR / f"live_detection_{saved_frames}.jpg"
                cv2.imwrite(str(out_path), frame)
                print(f"  ‚úì –ö–∞–¥—Ä –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {out_path}")

    except KeyboardInterrupt:
        print("\n  –ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    finally:
        cap.release()
        cv2.destroyAllWindows()

        print("\n‚úì Live-–¥–µ—Ç–µ–∫—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        if fps_history:
            print(f"  –°–µ—Ä–µ–¥–Ω—ñ–π FPS: {np.mean(fps_history):.1f}")
        print(f"  –ó–±–µ—Ä–µ–∂–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤: {saved_frames}")


# ---------------------------------------------------------------------------
# 6. –ì–æ–ª–æ–≤–Ω–µ –º–µ–Ω—é
# ---------------------------------------------------------------------------


def main():
    print("\n" + "=" * 80)
    print("  TEXTURE / OBJECT SEGMENTATION")
    print("  –í–ª–∞—Å–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä + Pre-trained MobileNet SSD + ROC + Live-—Ä–µ–∂–∏–º")
    print("=" * 80)

    print("\nüìã –ú–µ–Ω—é:")
    print("  1. –ù–∞–≤—á–∏—Ç–∏ –í–õ–ê–°–ù–ò–ô —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (U-Net)")
    print("  2. –û—Ü—ñ–Ω–∏—Ç–∏ PRE-TRAINED –¥–µ—Ç–µ–∫—Ç–æ—Ä (Haar Cascade - –æ–±–ª–∏—á—á—è)")
    print("  3. –ü–æ–±—É–¥—É–≤–∞—Ç–∏ ROC-–∫—Ä–∏–≤—É")
    print("  4. Live-–¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏ (Haar Cascade)")
    print("  5. –í–∏–∫–æ–Ω–∞—Ç–∏ –≤—Å–µ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ (1‚Üí2‚Üí3)")

    choice = input("\n  –í–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é (1-5): ").strip()

    own_y_true = own_y_prob = None
    pretrained_y_true = pretrained_y_prob = None

    if choice == "1" or choice == "5":
        _, own_y_true, own_y_prob = train_own_detector(
            num_train=50,
            num_test=15,
            epochs=10,
        )

    if choice == "2" or choice == "5":
        _, pretrained_y_true, pretrained_y_prob = evaluate_pretrained_detector(num_test=15)

    if choice == "3":
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –¥–∞–Ω—ñ
        try:
            own_y_true = np.load(OUTPUT_DIR / "own_detector_y_true.npy")
            own_y_prob = np.load(OUTPUT_DIR / "own_detector_y_prob.npy")
        except Exception:
            print("\n‚ö† –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø—É–Ω–∫—Ç 1.")
            return

        try:
            pretrained_y_true = np.load(OUTPUT_DIR / "pretrained_y_true.npy")
            pretrained_y_prob = np.load(OUTPUT_DIR / "pretrained_y_prob.npy")
        except Exception:
            pass

    if choice in {"1", "2", "3", "5"}:
        # –ü—ñ–¥–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        if own_y_true is None:
            try:
                own_y_true = np.load(OUTPUT_DIR / "own_detector_y_true.npy")
                own_y_prob = np.load(OUTPUT_DIR / "own_detector_y_prob.npy")
            except Exception:
                pass

        if pretrained_y_true is None:
            try:
                pretrained_y_true = np.load(OUTPUT_DIR / "pretrained_y_true.npy")
                pretrained_y_prob = np.load(OUTPUT_DIR / "pretrained_y_prob.npy")
            except Exception:
                pass

        if own_y_true is not None:
            plot_roc_curves(own_y_true, own_y_prob, pretrained_y_true, pretrained_y_prob)
        else:
            print("\n‚ö† –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ ROC.")

    if choice == "4":
        live_detection(min_neighbors=5)

    print_section("–ü–Ü–î–°–£–ú–û–ö")
    print("\n‚úÖ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ ¬´Texture / Object Segmentation¬ª –≤–∏–∫–æ–Ω–∞–Ω–∞.")
    print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ 'results':")
    print("  - synthetic_samples.png ‚Äî –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
    print("  - training_history.png ‚Äî –≥—Ä–∞—Ñ—ñ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è")
    print("  - own_detector_segmentation_examples.png ‚Äî –ø—Ä–∏–∫–ª–∞–¥–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó")
    print("  - own_detector_probability_hist.png ‚Äî —Ä–æ–∑–ø–æ–¥—ñ–ª –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π")
    print("  - confusion_matrix.png ‚Äî –º–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫")
    print("  - iou_vs_threshold.png ‚Äî IoU –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ –ø–æ—Ä–æ–≥—É")
    print("  - pretrained_detections.png ‚Äî –¥–µ—Ç–µ–∫—Ü—ñ—ó MobileNet SSD")
    print("  - roc_curves.png ‚Äî ROC-–∫—Ä–∏–≤–∞ (2 –∫–ª–∞—Å–∏)")
    print("  - live_detection_*.jpg ‚Äî –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –∫–∞–¥—Ä–∏ –∑ live-—Ä–µ–∂–∏–º—É")


if __name__ == "__main__":
    main()
