# Виконавче резюме: Бенчмаркінг екстракторів ознак

## 🎯 Ціль дослідження
Порівняти 5 різних feature extractors (Custom CNN, Autoencoder, VGG16, ResNet50, MobileNetV2) на 3 датасетах різної складності для оцінки якості екстракції ознак та їх придатності до кластеризації.

## 📊 Ключові результати

### Переможці за датасетами:

| Датасет | Переможець | ARI | NMI | Час (s) | Чому переміг |
|---------|------------|-----|-----|---------|--------------|
| **MNIST (легко)** | Custom CNN 🏆 | 0.439 | 0.570 | 0.80 | Supervised навчання на конкретній задачі |
| **Fashion-MNIST (важко)** | Autoencoder 🏆 | 0.335 | 0.518 | 0.56 | Unsupervised підхід ефективний для текстур |
| **CIFAR-10 (колірні)** | Custom CNN 🏆 | 0.073 | 0.138 | 0.75 | Всі показали погано, але custom найкращий |

### Рейтинг швидкості:
1. 🥇 **Autoencoder** - 0.58s (найшвидший)
2. 🥈 **Custom CNN** - 0.75s (швидкий)
3. 🥉 **MobileNetV2** - 4.44s (середній)
4. **ResNet50** - 12.05s (повільний)
5. **VGG16** - 13.78s (найповільніший)

## 💡 Головні висновки

### ✅ ТОП-3 інсайти:

1. **Custom CNN - найкращий вибір для більшості задач**
   - Оптимальний баланс якості (ARI=0.439 на MNIST) та швидкості (0.75s)
   - Переміг на 2 з 3 датасетів
   - В 16× швидше за претрейновані моделі

2. **Pretrained моделі переоцінені для простих задач**
   - VGG16 та ResNet50 гірші за Custom CNN на MNIST та Fashion-MNIST
   - В 16-18× повільніше
   - Transfer learning працює тільки на подібних доменах

3. **Unsupervised кластеризація має межі**
   - CIFAR-10: навіть найкращий результат ARI=0.073 (майже випадковий)
   - Природні зображення потребують supervised підходу
   - Autoencoder несподівано ефективний на Fashion-MNIST (NMI=0.518)

## 🎯 Практичні рекомендації

### Швидкий гайд вибору екстрактора:

```
┌─────────────────────────────────────────────────┐
│  Потрібна МАКСИМАЛЬНА ЯКІСТЬ?                   │
│  → Custom CNN + fine-tuning на вашому датасеті  │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  НЕМАЄ МІТОК класів?                            │
│  → Autoencoder (найкращий unsupervised)         │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  Потрібна ШВИДКІСТЬ?                            │
│  → Custom CNN або Autoencoder (<1s)             │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  ПРИРОДНІ ЗОБРАЖЕННЯ (ImageNet-like)?           │
│  → ResNet50 (але з GPU!)                        │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  MOBILE/EDGE deployment?                        │
│  → MobileNetV2 (найшвидший pretrained)          │
└─────────────────────────────────────────────────┘
```

## 📈 Порівняльна таблиця

| Екстрактор | Якість 🎯 | Швидкість ⚡ | Versatility 🔧 | Рекомендація |
|------------|----------|-------------|----------------|--------------|
| **Custom CNN** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | **Оптимальний вибір** для 80% задач |
| **Autoencoder** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | Найкращий для **unsupervised** |
| **VGG16** | ⭐⭐ | ⭐ | ⭐⭐⭐ | Тільки для ImageNet-подібних |
| **ResNet50** | ⭐⭐ | ⭐ | ⭐⭐⭐ | Тільки з GPU та подібним доменом |
| **MobileNetV2** | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | Для **mobile/edge** deployment |

## 🔬 Технічні метрики

### MNIST (легко розділити):
- **Найкраща якість:** Custom CNN (ARI=0.439, NMI=0.570)
- **Найшвидший:** Autoencoder (0.61s)
- **Найгірший:** MobileNetV2 (ARI=0.163)

### Fashion-MNIST (важко розділити):
- **Найкраща якість:** Autoencoder (ARI=0.335, NMI=0.518) ⭐
- **Найшвидший:** Autoencoder (0.56s)
- **Найгірший:** MobileNetV2 (ARI=0.165)

### CIFAR-10 (колірні, природні):
- **Найкраща якість:** Custom CNN (ARI=0.073, NMI=0.138)
- **Найшвидший:** Autoencoder (0.59s)
- **Висновок:** ❌ Всі показали погано - unsupervised не працює

## 📊 Візуалізації

Проєкт створив 14 детальних візуалізацій:

### 1. CNN Internals (3 файли):
- **Фільтри conv1** - edge/corner детектори ✅
- **Активації шарів** - прогресія від простих до складних ознак ✅
- **Feature maps** - що "бачить" кожен фільтр ✅

### 2. PCA Проекції (3 файли):
- Лінійне зменшення розмірності
- MNIST: чіткі кластери ✅
- Fashion-MNIST: перекриття ⚠️
- CIFAR-10: хаос ❌

### 3. t-SNE Проекції (3 файли):
- Нелінійне зменшення розмірності
- Краща візуалізація кластерів
- Виявляє підгрупи всередині класів

### 4. Порівняльні діаграми (1 файл):
- Box plots для всіх метрик
- Зведене порівняння екстракторів

## 🎓 Основний урок

> **Складність моделі ≠ Якість результату**

Претрейновані моделі (VGG16, ResNet50) з мільйонами параметрів показали **гірші** результати за простий Custom CNN на MNIST та Fashion-MNIST.

**Чому?**
- Transfer learning працює тільки на подібних доменах
- ImageNet features занадто загальні для простих датасетів
- Швидкість критично страждає (в 16-18× повільніше)
- Розмірність features не гарантує якість

## 🚀 Для production використовуйте:

### Базовий вибір: **Custom CNN**
```python
Переваги:
✅ Найкращий баланс якість/швидкість
✅ Працює без GPU
✅ Легко оптимізувати (quantization, pruning)
✅ Малий розмір моделі (~5MB)
✅ Адаптується під конкретну задачу
```

### Альтернатива: **Autoencoder** (якщо немає міток)
```python
Переваги:
✅ Не потребує labeled даних
✅ Найшвидший inference (0.56s)
✅ Ефективний для складних текстур
✅ Компактний latent space (128-D)
```

## 📁 Структура результатів

```
results/
├── dataset_samples.png              # Приклади даних
├── cnn_filters_conv1.png            # Фільтри CNN
├── cnn_activations_progression.png  # Активації
├── cnn_feature_maps_conv1.png       # Feature maps
├── pca_projections_*.png            # PCA (×3)
├── tsne_projections_*.png           # t-SNE (×3)
├── extractors_comparison.png        # Порівняння
└── benchmark_*.csv                  # Метрики (×3)
```

## ⏱️ Статистика виконання

- **Датасетів:** 3 (MNIST, Fashion-MNIST, CIFAR-10)
- **Екстракторів:** 5
- **Експериментів:** 15
- **Зображень:** 19,500
- **Візуалізацій:** 14
- **Час виконання:** ~20-30 хвилин (CPU)

## 🎯 Висновок

**Для більшості практичних задач комп'ютерного зору:**
1. Почніть з Custom CNN (256-D features)
2. Якщо немає міток → Autoencoder (128-D latent)
3. Тільки для складних природних зображень → Pretrained моделі

**Не використовуйте pretrained моделі "за замовчуванням"** - вони не завжди кращі і значно повільніші!

---

**Детальний аналіз:** Див. [ВИСНОВКИ.md](ВИСНОВКИ.md)  
**Код:** [main.py](main.py)  
**Документація:** [README.md](README.md)

