"""
–î–µ—Ç–µ–∫—Ç—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ (Object Detection)
–§–æ–∫—É—Å: –ù–∞–≤—á–∞–Ω–Ω—è –¥–µ—Ç–µ–∫—Ç–æ—Ä—ñ–≤, –æ—Ü—ñ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ, real-time –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –∫–∞–º–µ—Ä–∏

–ú–µ—Ç–∞: –ù–∞–≤—á–∏—Ç–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä –æ–±'—î–∫—Ç—ñ–≤, –æ—Ü—ñ–Ω–∏—Ç–∏ –π–æ–≥–æ —Ç–æ—á–Ω—ñ—Å—Ç—å —Ç–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–∏
—É live —Ä–µ–∂–∏–º—ñ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±'—î–∫—Ç—ñ–≤ —É –≤—ñ–¥–µ–æ –ø–æ—Ç–æ—Ü—ñ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏.

–ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ –æ–±'—î–∫—Ç–∏:
- –û–±–ª–∏—á—á—è (faces)
- –§—ñ–≥—É—Ä–∏ –ª—é–¥–µ–π (persons)
- –ê–≤—Ç–æ–º–æ–±—ñ–ª—ñ (cars)
- –Ü–Ω—à—ñ COCO –æ–±'—î–∫—Ç–∏

–ú–æ–¥–µ–ª—ñ:
- SSD MobileNet V2 (—à–≤–∏–¥–∫–∏–π, –ª–µ–≥–∫–∏–π)
- Faster R-CNN ResNet50 (—Ç–æ—á–Ω–∏–π, –ø–æ–≤—ñ–ª—å–Ω—ñ—à–∏–π)
- EfficientDet (–±–∞–ª–∞–Ω—Å —à–≤–∏–¥–∫–æ—Å—Ç—ñ/—Ç–æ—á–Ω–æ—Å—Ç—ñ)

–ú–µ—Ç—Ä–∏–∫–∏:
- mAP (mean Average Precision)
- IoU (Intersection over Union)
- Precision/Recall
- FPS (frames per second)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
import cv2
import time
import os
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import urllib.request
import tarfile
import json

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
tf.random.set_seed(42)
np.random.seed(42)

sns.set(style="whitegrid", context="notebook")
plt.rcParams["figure.figsize"] = (12, 8)
plt.rcParams['font.size'] = 10
plt.rcParams['font.family'] = 'DejaVu Sans'

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
OUTPUT_DIR = Path("results")
OUTPUT_DIR.mkdir(exist_ok=True)

DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

MODELS_DIR = Path("models")
MODELS_DIR.mkdir(exist_ok=True)


def print_section(title):
    """–í–∏–≤–æ–¥–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü—ñ—ó"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


# COCO –∫–ª–∞—Å–∏ (80 –∫–ª–∞—Å—ñ–≤)
COCO_CLASSES = {
    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',
    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',
    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',
    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',
    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',
    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',
    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',
    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',
    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork',
    49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple',
    54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog',
    59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch',
    64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv',
    73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone',
    78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator',
    84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',
    89: 'hair drier', 90: 'toothbrush'
}

# –°–ø—Ä–æ—â–µ–Ω–∏–π –Ω–∞–±—ñ—Ä –∫–ª–∞—Å—ñ–≤ (—â–æ–± –∑–∞–¥–∞—á–∞ –±—É–ª–∞ –ª–µ–≥—à–æ—é –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É)
# –í–ê–ñ–õ–ò–í–û: —Ç—É—Ç –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –ø—Ä–∏—Å—É—Ç–Ω—ñ–π –∫–ª–∞—Å "person"
SIMPLE_CLASSES = {
    1: 'person',   # –ª—é–¥–∏–Ω–∞
    3: 'car',      # –∞–≤—Ç–æ–º–æ–±—ñ–ª—å
    8: 'truck',    # –≤–∞–Ω—Ç–∞–∂—ñ–≤–∫–∞
    17: 'cat',     # –∫—ñ—Ç
    18: 'dog',     # —Å–æ–±–∞–∫–∞
}

# –Ø–∫—â–æ True ‚Äî –¥–µ—Ç–µ–∫—Ç–æ—Ä –±—É–¥–µ –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏ –ª–∏—à–µ –∫–ª–∞—Å–∏ –∑ SIMPLE_CLASSES
# –Ø–∫—â–æ False ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤—Å—ñ COCO –∫–ª–∞—Å–∏
USE_SIMPLE_CLASSES = True


def download_sample_images():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∏–∫–ª–∞–¥–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è"""
    print_section("–ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ï–°–¢–û–í–ò–• –ó–û–ë–†–ê–ñ–ï–ù–¨")
    
    # –°–ø–∏—Å–æ–∫ URL –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    sample_urls = [
        "https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/image1.jpg",
        "https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/image2.jpg",
    ]
    
    images = []
    
    for idx, url in enumerate(sample_urls):
        try:
            print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {idx+1}...")
            image_path = DATA_DIR / f"test_image_{idx+1}.jpg"
            
            if not image_path.exists():
                urllib.request.urlretrieve(url, image_path)
                print(f"  ‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ: {image_path}")
            else:
                print(f"  ‚úì –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –∫–µ—à: {image_path}")
            
            # –ß–∏—Ç–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            img = cv2.imread(str(image_path))
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            images.append(img_rgb)
            
        except Exception as e:
            print(f"  ‚ö† –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ: {e}")
    
    print(f"\n‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(images)} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
    return images


def load_detection_model(model_name='ssd_mobilenet_v2'):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î pretrained object detection –º–æ–¥–µ–ª—å"""
    print_section(f"–ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ú–û–î–ï–õ–Ü: {model_name.upper()}")
    
    # TensorFlow Hub URLs –¥–ª—è different –º–æ–¥–µ–ª–µ–π
    model_urls = {
        'ssd_mobilenet_v2': 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',
        'faster_rcnn_resnet50': 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',
        'efficientdet_d0': 'https://tfhub.dev/tensorflow/efficientdet/d0/1',
        'centernet_resnet50': 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1'
    }
    
    if model_name not in model_urls:
        print(f"  ‚ö† –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é ssd_mobilenet_v2")
        model_name = 'ssd_mobilenet_v2'
    
    model_url = model_urls[model_name]
    
    print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ TensorFlow Hub...")
    print(f"  URL: {model_url}")
    
    try:
        start_time = time.time()
        detector = hub.load(model_url)
        load_time = time.time() - start_time
        
        print(f"  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑–∞ {load_time:.2f}s")
        
        return detector, model_name
        
    except Exception as e:
        print(f"  ‚ö† –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –º–æ–¥–µ–ª—ñ: {e}")
        return None, None


def detect_objects(detector, image, confidence_threshold=0.5):
    """–í–∏–∫–æ–Ω—É—î –¥–µ—Ç–µ–∫—Ü—ñ—é –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ"""
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —Ç–µ–Ω–∑–æ—Ä
    input_tensor = tf.convert_to_tensor(image)
    input_tensor = input_tensor[tf.newaxis, ...]
    
    # –î–µ—Ç–µ–∫—Ü—ñ—è
    start_time = time.time()
    detections = detector(input_tensor)
    inference_time = time.time() - start_time
    
    # –í–∏—Ç—è–≥—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                  for key, value in detections.items()}
    detections['num_detections'] = num_detections
    
    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø–æ confidence
    scores = detections['detection_scores']
    classes = detections['detection_classes'].astype(np.int32)
    indices = scores >= confidence_threshold

    # –î–û–î–ê–¢–ö–û–í–û: —Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–ª–∞—Å–∏, —è–∫—â–æ —Å–ø—Ä–æ—â–µ–Ω–∏–π —Ä–µ–∂–∏–º —É–≤—ñ–º–∫–Ω–µ–Ω–æ
    if USE_SIMPLE_CLASSES:
        allowed_ids = np.array(list(SIMPLE_CLASSES.keys()), dtype=np.int32)
        class_mask = np.isin(classes, allowed_ids)
        indices = indices & class_mask
    
    results = {
        'boxes': detections['detection_boxes'][indices],
        'classes': classes[indices],
        'scores': scores[indices],
        'num_detections': np.sum(indices),
        'inference_time': inference_time
    }
    
    return results


def draw_detections(image, results, min_score=0.5):
    """–ú–∞–ª—é—î bounding boxes –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ"""
    
    img_with_boxes = image.copy()
    height, width = img_with_boxes.shape[:2]
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ –∫–æ–ª—å–æ—Ä–∏ –¥–ª—è –∫–ª–∞—Å—ñ–≤
    np.random.seed(42)
    colors = {}
    for class_id in COCO_CLASSES.keys():
        colors[class_id] = tuple(np.random.randint(0, 255, 3).tolist())
    
    # –ú–∞–ª—é—î–º–æ –∫–æ–∂–µ–Ω detection
    for i in range(results['num_detections']):
        if results['scores'][i] < min_score:
            continue
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ box (normalized)
        ymin, xmin, ymax, xmax = results['boxes'][i]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ pixel –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏
        left = int(xmin * width)
        right = int(xmax * width)
        top = int(ymin * height)
        bottom = int(ymax * height)
        
        # –ö–ª–∞—Å —Ç–∞ score
        class_id = results['classes'][i]
        score = results['scores'][i]
        class_name = COCO_CLASSES.get(class_id, f'class_{class_id}')
        
        # –ö–æ–ª—ñ—Ä –¥–ª—è —Ü—å–æ–≥–æ –∫–ª–∞—Å—É
        color = colors.get(class_id, (0, 255, 0))
        
        # –ú–∞–ª—é—î–º–æ box
        cv2.rectangle(img_with_boxes, (left, top), (right, bottom), color, 2)
        
        # –¢–µ–∫—Å—Ç –∑ –∫–ª–∞—Å–æ–º —Ç–∞ score
        label = f'{class_name}: {score:.2f}'
        
        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç—É
        (label_width, label_height), baseline = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        
        cv2.rectangle(
            img_with_boxes,
            (left, top - label_height - baseline - 5),
            (left + label_width, top),
            color,
            -1
        )
        
        # –¢–µ–∫—Å—Ç
        cv2.putText(
            img_with_boxes,
            label,
            (left, top - baseline - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1
        )
    
    return img_with_boxes


def visualize_detections(images, detector, model_name):
    """–í—ñ–∑—É–∞–ª—ñ–∑—É—î –¥–µ—Ç–µ–∫—Ü—ñ—ó –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö"""
    print_section("–î–ï–¢–ï–ö–¶–Ü–Ø –ù–ê –¢–ï–°–¢–û–í–ò–• –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø–•")
    
    n_images = len(images)
    fig, axes = plt.subplots(n_images, 2, figsize=(16, 6 * n_images))
    
    if n_images == 1:
        axes = axes.reshape(1, -1)
    
    for idx, image in enumerate(images):
        print(f"\n  –û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {idx+1}/{n_images}...")
        
        # –î–µ—Ç–µ–∫—Ü—ñ—è
        results = detect_objects(detector, image, confidence_threshold=0.3)
        
        print(f"  ‚úì –ó–Ω–∞–π–¥–µ–Ω–æ {results['num_detections']} –æ–±'—î–∫—Ç—ñ–≤")
        print(f"  ‚úì –ß–∞—Å —ñ–Ω—Ñ–µ—Ä–µ–Ω—Ü—ñ—ó: {results['inference_time']*1000:.1f}ms")
        
        # –ú–∞–ª—é—î–º–æ
        img_with_boxes = draw_detections(image, results, min_score=0.3)
        
        # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
        axes[idx, 0].imshow(image)
        axes[idx, 0].set_title(f'–û—Ä–∏–≥—ñ–Ω–∞–ª #{idx+1}', fontsize=12, weight='bold')
        axes[idx, 0].axis('off')
        
        axes[idx, 1].imshow(img_with_boxes)
        axes[idx, 1].set_title(
            f'–î–µ—Ç–µ–∫—Ü—ñ—ó #{idx+1} ({results["num_detections"]} –æ–±\'—î–∫—Ç—ñ–≤, {results["inference_time"]*1000:.0f}ms)',
            fontsize=12, weight='bold'
        )
        axes[idx, 1].axis('off')
        
        # –í–∏–≤–æ–¥–∏–º–æ –∑–Ω–∞–π–¥–µ–Ω—ñ –∫–ª–∞—Å–∏
        detected_classes = {}
        for i in range(results['num_detections']):
            class_id = results['classes'][i]
            class_name = COCO_CLASSES.get(class_id, f'class_{class_id}')
            score = results['scores'][i]
            
            if class_name not in detected_classes:
                detected_classes[class_name] = []
            detected_classes[class_name].append(score)
        
        print(f"  –ó–Ω–∞–π–¥–µ–Ω—ñ –∫–ª–∞—Å–∏:")
        for class_name, scores in detected_classes.items():
            avg_score = np.mean(scores)
            count = len(scores)
            print(f"    - {class_name}: {count}x (avg score: {avg_score:.3f})")
    
    plt.suptitle(f'Object Detection: {model_name.upper()}', fontsize=16, weight='bold')
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / f'detections_{model_name}.png', dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ: results/detections_{model_name}.png")
    plt.show()


def compute_iou(box1, box2):
    """–û–±—á–∏—Å–ª—é—î IoU (Intersection over Union) –º—ñ–∂ –¥–≤–æ–º–∞ boxes"""
    
    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –ø–µ—Ä–µ—Ç–∏–Ω—É
    ymin = max(box1[0], box2[0])
    xmin = max(box1[1], box2[1])
    ymax = min(box1[2], box2[2])
    xmax = min(box1[3], box2[3])
    
    # –ü–ª–æ—â–∞ –ø–µ—Ä–µ—Ç–∏–Ω—É
    intersection_area = max(0, xmax - xmin) * max(0, ymax - ymin)
    
    # –ü–ª–æ—â—ñ boxes
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # Union
    union_area = box1_area + box2_area - intersection_area
    
    # IoU
    iou = intersection_area / union_area if union_area > 0 else 0
    
    return iou


def evaluate_detector(detector, test_images, ground_truth, iou_threshold=0.5):
    """–û—Ü—ñ–Ω—é—î —Ç–æ—á–Ω—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ"""
    print_section("–û–¶–Ü–ù–ö–ê –¢–û–ß–ù–û–°–¢–Ü –î–ï–¢–ï–ö–¢–û–†–ê")
    
    all_precisions = []
    all_recalls = []
    all_ious = []
    all_fps = []
    
    for idx, (image, gt) in enumerate(zip(test_images, ground_truth)):
        print(f"\n  –û—Ü—ñ–Ω–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {idx+1}/{len(test_images)}...")
        
        # –î–µ—Ç–µ–∫—Ü—ñ—è
        results = detect_objects(detector, image, confidence_threshold=0.5)
        
        # FPS
        fps = 1.0 / results['inference_time']
        all_fps.append(fps)
        
        # Ground truth boxes
        gt_boxes = gt['boxes']
        gt_classes = gt['classes']
        
        # Predicted boxes
        pred_boxes = results['boxes']
        pred_classes = results['classes']
        pred_scores = results['scores']
        
        # Matching predictions to ground truth
        matched_gt = set()
        true_positives = 0
        false_positives = 0
        
        for pred_idx in range(len(pred_boxes)):
            pred_box = pred_boxes[pred_idx]
            pred_class = pred_classes[pred_idx]
            
            best_iou = 0
            best_gt_idx = -1
            
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–∫—Ä–∞—â–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è –∑ ground truth
            for gt_idx in range(len(gt_boxes)):
                if gt_idx in matched_gt:
                    continue
                
                gt_box = gt_boxes[gt_idx]
                gt_class = gt_classes[gt_idx]
                
                # –ö–ª–∞—Å–∏ –º–∞—é—Ç—å —Å–ø—ñ–≤–ø–∞–¥–∞—Ç–∏
                if pred_class != gt_class:
                    continue
                
                iou = compute_iou(pred_box, gt_box)
                
                if iou > best_iou:
                    best_iou = iou
                    best_gt_idx = gt_idx
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ true positive
            if best_iou >= iou_threshold and best_gt_idx != -1:
                true_positives += 1
                matched_gt.add(best_gt_idx)
                all_ious.append(best_iou)
            else:
                false_positives += 1
        
        # False negatives - ground truth boxes, —è–∫—ñ –Ω–µ –±—É–ª–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ
        false_negatives = len(gt_boxes) - len(matched_gt)
        
        # Precision —Ç–∞ Recall
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        
        all_precisions.append(precision)
        all_recalls.append(recall)
        
        print(f"  ‚úì Precision: {precision:.3f}")
        print(f"  ‚úì Recall: {recall:.3f}")
        print(f"  ‚úì FPS: {fps:.1f}")
    
    # –°–µ—Ä–µ–¥–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    metrics = {
        'mean_precision': np.mean(all_precisions),
        'mean_recall': np.mean(all_recalls),
        'mean_iou': np.mean(all_ious) if all_ious else 0,
        'mean_fps': np.mean(all_fps),
        'f1_score': 2 * np.mean(all_precisions) * np.mean(all_recalls) / (np.mean(all_precisions) + np.mean(all_recalls)) if (np.mean(all_precisions) + np.mean(all_recalls)) > 0 else 0
    }
    
    print("\nüìä –ü—ñ–¥—Å—É–º–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"  Precision: {metrics['mean_precision']:.3f}")
    print(f"  Recall: {metrics['mean_recall']:.3f}")
    print(f"  F1-Score: {metrics['f1_score']:.3f}")
    print(f"  Mean IoU: {metrics['mean_iou']:.3f}")
    print(f"  Mean FPS: {metrics['mean_fps']:.1f}")
    
    return metrics


def benchmark_models(images):
    """–ü–æ—Ä—ñ–≤–Ω—é—î —Ä—ñ–∑–Ω—ñ –º–æ–¥–µ–ª—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó"""
    print_section("–ë–ï–ù–ß–ú–ê–†–ö –ú–û–î–ï–õ–ï–ô")
    
    models_to_test = [
        'ssd_mobilenet_v2',
        'efficientdet_d0',
    ]
    
    results = {}
    
    for model_name in models_to_test:
        print(f"\n{'='*80}")
        print(f"  –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è: {model_name.upper()}")
        print('='*80)
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
            detector, _ = load_detection_model(model_name)
            
            if detector is None:
                continue
            
            # –¢–µ—Å—Ç—É—î–º–æ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö
            total_time = 0
            total_detections = 0
            
            for idx, image in enumerate(images):
                result = detect_objects(detector, image, confidence_threshold=0.5)
                total_time += result['inference_time']
                total_detections += result['num_detections']
            
            avg_time = total_time / len(images)
            avg_fps = 1.0 / avg_time
            avg_detections = total_detections / len(images)
            
            results[model_name] = {
                'Avg Time (ms)': avg_time * 1000,
                'Avg FPS': avg_fps,
                'Avg Detections': avg_detections
            }
            
            print(f"\n  ‚úì –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å: {avg_time*1000:.1f}ms")
            print(f"  ‚úì –°–µ—Ä–µ–¥–Ω—ñ–π FPS: {avg_fps:.1f}")
            print(f"  ‚úì –°–µ—Ä–µ–¥–Ω—è –∫-—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ–π: {avg_detections:.1f}")
            
            # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó
            visualize_detections(images[:2], detector, model_name)
            
            # –û—á–∏—â—É—î–º–æ –ø–∞–º'—è—Ç—å
            del detector
            
        except Exception as e:
            print(f"  ‚ö† –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—ñ {model_name}: {e}")
    
    # –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
    if results:
        print("\nüìä –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è:")
        results_df = pd.DataFrame(results).T
        print(results_df.round(2).to_string())
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ
        results_df.to_csv(OUTPUT_DIR / 'models_benchmark.csv')
        print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ: results/models_benchmark.csv")
        
        # –ì—Ä–∞—Ñ—ñ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # FPS
        ax = axes[0]
        results_df['Avg FPS'].plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')
        ax.set_title('–®–≤–∏–¥–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π (FPS)', fontsize=13, weight='bold')
        ax.set_ylabel('FPS', fontsize=11)
        ax.set_xlabel('–ú–æ–¥–µ–ª—å', fontsize=11)
        ax.grid(alpha=0.3, axis='y')
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        # Time
        ax = axes[1]
        results_df['Avg Time (ms)'].plot(kind='bar', ax=ax, color='coral', edgecolor='black')
        ax.set_title('–ß–∞—Å —ñ–Ω—Ñ–µ—Ä–µ–Ω—Ü—ñ—ó (ms)', fontsize=13, weight='bold')
        ax.set_ylabel('Milliseconds', fontsize=11)
        ax.set_xlabel('–ú–æ–¥–µ–ª—å', fontsize=11)
        ax.grid(alpha=0.3, axis='y')
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        plt.suptitle('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π', fontsize=16, weight='bold')
        plt.tight_layout()
        plt.savefig(OUTPUT_DIR / 'models_comparison.png', dpi=300, bbox_inches='tight')
        print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ: results/models_comparison.png")
        plt.show()
    
    return results


def live_detection(model_name='ssd_mobilenet_v2', confidence_threshold=0.5):
    """–ó–∞–ø—É—Å–∫–∞—î –¥–µ—Ç–µ–∫—Ü—ñ—é —É live —Ä–µ–∂–∏–º—ñ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏"""
    print_section("LIVE –î–ï–¢–ï–ö–¶–Ü–Ø –ó –í–ï–ë-–ö–ê–ú–ï–†–ò")
    
    print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {model_name}...")
    detector, _ = load_detection_model(model_name)
    
    if detector is None:
        print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å")
        return
    
    print("\n  –í—ñ–¥–∫—Ä–∏—Ç—Ç—è –≤–µ–±-–∫–∞–º–µ—Ä–∏...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤–µ–±-–∫–∞–º–µ—Ä—É")
        return
    
    print("\n‚úì Live –¥–µ—Ç–µ–∫—Ü—ñ—è –∑–∞–ø—É—â–µ–Ω–∞!")
    print("\n  –ö–µ—Ä—É–≤–∞–Ω–Ω—è:")
    print("    - 'q' –∞–±–æ 'ESC' - –≤–∏—Ö—ñ–¥")
    print("    - 's' - –∑–±–µ—Ä–µ–≥—Ç–∏ –∫–∞–¥—Ä")
    print("    - '+' - –∑–±—ñ–ª—å—à–∏—Ç–∏ confidence threshold")
    print("    - '-' - –∑–º–µ–Ω—à–∏—Ç–∏ confidence threshold")
    
    frame_count = 0
    fps_history = []
    saved_frames = 0
    
    try:
        while True:
            ret, frame = cap.read()
            
            if not ret:
                print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∫–∞–¥—Ä")
                break
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ BGR -> RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # –î–µ—Ç–µ–∫—Ü—ñ—è
            start_time = time.time()
            results = detect_objects(detector, frame_rgb, confidence_threshold=confidence_threshold)
            inference_time = time.time() - start_time
            
            # –ú–∞–ª—é—î–º–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó
            frame_with_boxes = draw_detections(frame_rgb, results, min_score=confidence_threshold)
            frame_with_boxes = cv2.cvtColor(frame_with_boxes, cv2.COLOR_RGB2BGR)
            
            # –û–±—á–∏—Å–ª—é—î–º–æ FPS
            fps = 1.0 / inference_time if inference_time > 0 else 0
            fps_history.append(fps)
            if len(fps_history) > 30:
                fps_history.pop(0)
            avg_fps = np.mean(fps_history)
            
            # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ –Ω–∞ –µ–∫—Ä–∞–Ω
            info_text = [
                f'FPS: {avg_fps:.1f}',
                f'Detections: {results["num_detections"]}',
                f'Confidence: {confidence_threshold:.2f}',
                f'Time: {inference_time*1000:.0f}ms'
            ]
            
            y_offset = 30
            for text in info_text:
                cv2.putText(
                    frame_with_boxes,
                    text,
                    (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0, 255, 0),
                    2
                )
                y_offset += 30
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –∫–∞–¥—Ä
            cv2.imshow('Object Detection - Live', frame_with_boxes)
            
            # –û–±—Ä–æ–±–∫–∞ –∫–ª–∞–≤—ñ—à
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == 27:  # q –∞–±–æ ESC
                print("\n  –ó—É–ø–∏–Ω–∫–∞...")
                break
            elif key == ord('s'):  # –ó–±–µ—Ä–µ–≥—Ç–∏ –∫–∞–¥—Ä
                saved_frames += 1
                filename = OUTPUT_DIR / f'live_capture_{saved_frames}.jpg'
                cv2.imwrite(str(filename), frame_with_boxes)
                print(f"\n  ‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –∫–∞–¥—Ä: {filename}")
            elif key == ord('+') or key == ord('='):  # –ó–±—ñ–ª—å—à–∏—Ç–∏ threshold
                confidence_threshold = min(0.95, confidence_threshold + 0.05)
                print(f"\n  Confidence threshold: {confidence_threshold:.2f}")
            elif key == ord('-') or key == ord('_'):  # –ó–º–µ–Ω—à–∏—Ç–∏ threshold
                confidence_threshold = max(0.05, confidence_threshold - 0.05)
                print(f"\n  Confidence threshold: {confidence_threshold:.2f}")
            
            frame_count += 1
    
    except KeyboardInterrupt:
        print("\n  –ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        print(f"\n‚úì Live –¥–µ—Ç–µ–∫—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤: {frame_count}")
        print(f"  –ó–±–µ—Ä–µ–∂–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤: {saved_frames}")
        print(f"  –°–µ—Ä–µ–¥–Ω—ñ–π FPS: {np.mean(fps_history):.1f}")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    print("\n" + "="*80)
    print("  OBJECT DETECTION")
    print("  –î–µ—Ç–µ–∫—Ç—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –∑ –Ω–∞–≤—á–∞–Ω–Ω—è–º —Ç–∞ live —Ä–µ–∂–∏–º–æ–º")
    print("="*80)
    
    print("\nüìã –ú–µ–Ω—é:")
    print("  1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ç–µ—Å—Ç–æ–≤—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—Ä–æ—Ç–µ—Å—Ç—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—ñ")
    print("  2. –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–µ–π")
    print("  3. Live –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏")
    print("  4. –í–∏–∫–æ–Ω–∞—Ç–∏ –≤—Å–µ")
    
    choice = input("\n  –í–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é (1-4): ").strip()
    
    if choice == '1' or choice == '4':
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        images = download_sample_images()
        
        if not images:
            print("\n‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é fallback...")
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            images = [test_img]
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–∞ —Ç–µ—Å—Ç—É—î–º–æ –º–æ–¥–µ–ª—å
        detector, model_name = load_detection_model('ssd_mobilenet_v2')
        
        if detector:
            visualize_detections(images, detector, model_name)
    
    if choice == '2' or choice == '4':
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫—â–æ —â–µ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ
        if choice == '2':
            images = download_sample_images()
            if not images:
                test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
                images = [test_img]
        
        # –ë–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–µ–π
        benchmark_results = benchmark_models(images)
    
    if choice == '3' or choice == '4':
        # Live –¥–µ—Ç–µ–∫—Ü—ñ—è
        print("\n" + "="*80)
        if choice == '4':
            response = input("\n  –ó–∞–ø—É—Å—Ç–∏—Ç–∏ live –¥–µ—Ç–µ–∫—Ü—ñ—é? (y/n): ").strip().lower()
            if response != 'y':
                print("\n  Live –¥–µ—Ç–µ–∫—Ü—ñ—é –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                return
        
        live_detection(model_name='ssd_mobilenet_v2', confidence_threshold=0.5)
    
    # –ü—ñ–¥—Å—É–º–æ–∫
    print_section("–ü–Ü–î–°–£–ú–û–ö")
    print("\n‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("\nüìÅ –°—Ç–≤–æ—Ä–µ–Ω—ñ —Ñ–∞–π–ª–∏:")
    print("  - results/detections_*.png - –¥–µ—Ç–µ–∫—Ü—ñ—ó –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö")
    print("  - results/models_benchmark.csv - –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π")
    print("  - results/models_comparison.png - –≥—Ä–∞—Ñ—ñ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
    print("  - results/live_capture_*.jpg - –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –∫–∞–¥—Ä–∏ –∑ live –¥–µ—Ç–µ–∫—Ü—ñ—ó")
    
    print("\nüí° –ü—ñ–¥–∫–∞–∑–∫–∏:")
    print("  - –î–ª—è –∫—Ä–∞—â–æ—ó —Ç–æ—á–Ω–æ—Å—Ç—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ faster_rcnn_resnet50")
    print("  - –î–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ ssd_mobilenet_v2")
    print("  - –£ live —Ä–µ–∂–∏–º—ñ –º–æ–∂–Ω–∞ —Ä–µ–≥—É–ª—é–≤–∞—Ç–∏ confidence threshold")
    print("  - –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å 's' –≤ live —Ä–µ–∂–∏–º—ñ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–∞–¥—Ä—É")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()

