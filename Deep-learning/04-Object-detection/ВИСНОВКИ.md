# –í–∏—Å–Ω–æ–≤–∫–∏: Object Detection (–î–µ—Ç–µ–∫—Ç—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤)

## –ó–∞–≥–∞–ª—å–Ω–∏–π –æ–≥–ª—è–¥

–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ —Ä–æ–±–æ—Ç–∞ –∑ **Object Detection** –ø—Ä–∏—Å–≤—è—á–µ–Ω–∞ –≤–∏–≤—á–µ–Ω–Ω—é —Ç–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–º—É –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—é —Å—É—á–∞—Å–Ω–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ –¥–µ—Ç–µ–∫—Ç—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö —Ç–∞ —É –≤—ñ–¥–µ–æ –ø–æ—Ç–æ—Ü—ñ. –ü—Ä–æ—î–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –ø–æ–≤–Ω–∏–π —Ü–∏–∫–ª —Ä–æ–±–æ—Ç–∏ –∑ object detection: –≤—ñ–¥ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è pretrained –º–æ–¥–µ–ª–µ–π –¥–æ real-time –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏.

---

## 1. –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω–∏–π —Å—Ç–µ–∫ —Ç–∞ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏

### 1.1 –§—Ä–µ–π–º–≤–æ—Ä–∫–∏ —Ç–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏

**TensorFlow 2.17 + TensorFlow Hub**
- ‚úÖ –°—É—á–∞—Å–Ω–∏–π, —à–≤–∏–¥–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è deep learning
- ‚úÖ TensorFlow Hub –¥–æ–∑–≤–æ–ª—è—î –ª–µ–≥–∫–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—Ç–∏ pretrained –º–æ–¥–µ–ª—ñ
- ‚úÖ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ GPU –¥–ª—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è
- ‚úÖ Production-ready —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏

**OpenCV 4.8+**
- ‚úÖ –ü–æ—Ç—É–∂–Ω–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ –¥–ª—è –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–æ–≥–æ –∑–æ—Ä—É
- ‚úÖ –†–æ–±–æ—Ç–∞ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–æ—é
- ‚úÖ –ï—Ñ–µ–∫—Ç–∏–≤–Ω–µ –º–∞–ª—é–≤–∞–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å
- ‚úÖ –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏

**NumPy, Pandas, Matplotlib**
- ‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è data science
- ‚úÖ –ï—Ñ–µ–∫—Ç–∏–≤–Ω–∞ —Ä–æ–±–æ—Ç–∞ –∑ –º–∞—Å–∏–≤–∞–º–∏
- ‚úÖ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- ‚úÖ –û–±—Ä–æ–±–∫–∞ —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –º–µ—Ç—Ä–∏–∫

### 1.2 –ü–µ—Ä–µ–≤–∞–≥–∏ –æ–±—Ä–∞–Ω–æ–≥–æ —Å—Ç–µ–∫—É

**–ß–æ–º—É TensorFlow Hub?**
1. –®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è pretrained –º–æ–¥–µ–ª–µ–π
2. –£–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π API –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä
3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∫–µ—à—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
4. –í–µ–ª–∏–∫–∞ –∫–æ–ª–µ–∫—Ü—ñ—è –≥–æ—Ç–æ–≤–∏—Ö –º–æ–¥–µ–ª–µ–π
5. –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –≤—ñ–¥ Google

**–ß–æ–º—É OpenCV?**
1. –°—Ç–∞–Ω–¥–∞—Ä—Ç —É –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–æ–º—É –∑–æ—Ä—ñ
2. –ö—Ä–æ—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ñ—Å—Ç—å
3. –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
4. –®–∏—Ä–æ–∫–∏–π —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª
5. –í–µ–ª–∏–∫–∞ —Å–ø—ñ–ª—å–Ω–æ—Ç–∞

---

## 2. –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–µ–∫—Ü—ñ—ó

### 2.1 SSD MobileNet V2

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**
```
Input (320√ó320√ó3)
    ‚Üì
MobileNetV2 Backbone (Depthwise Separable Convolutions)
    ‚Üì
Multi-scale Feature Maps
    ‚Üì
SSD Detection Heads (6 layers)
    ‚Üì
Predictions: [boxes, classes, scores]
    ‚Üì
Non-Maximum Suppression (NMS)
    ‚Üì
Output: Filtered detections
```

**–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:**
- **Single Shot**: –æ–¥–Ω–∞ –º–µ—Ä–µ–∂–∞ –¥–ª—è detection (—à–≤–∏–¥–∫–æ)
- **Multi-scale**: –¥–µ—Ç–µ–∫—Ü—ñ—è –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö
- **MobileNetV2**: –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π backbone –∑ depthwise convolutions
- **Anchor-based**: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –≤–∏–∑–Ω–∞—á–µ–Ω—ñ anchor boxes

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –ù–∞–π—à–≤–∏–¥—à–∞ –º–æ–¥–µ–ª—å (~40 FPS –Ω–∞ CPU)
- ‚úÖ –ú–∞–ª–µ–Ω—å–∫–∏–π —Ä–æ–∑–º—ñ—Ä (~20MB)
- ‚úÖ –ù–∏–∑—å–∫–µ —Å–ø–æ–∂–∏–≤–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
- ‚úÖ –Ü–¥–µ–∞–ª—å–Ω–∞ –¥–ª—è real-time

**–ù–µ–¥–æ–ª—ñ–∫–∏:**
- ‚ö†Ô∏è –ù–∏–∂—á–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (~22% mAP)
- ‚ö†Ô∏è –ì—ñ—Ä—à–µ –≤–∏—è–≤–ª—è—î –º–∞–ª—ñ –æ–±'—î–∫—Ç–∏
- ‚ö†Ô∏è –ú–µ–Ω—à–∞ —Ä–æ–∑–¥—ñ–ª—å–Ω–∞ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å (320√ó320)

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- Live –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏ ‚úÖ
- –ú–æ–±—ñ–ª—å–Ω—ñ –¥–æ–¥–∞—Ç–∫–∏ ‚úÖ
- Edge devices ‚úÖ
- –û–±–º–µ–∂–µ–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏ ‚úÖ

### 2.2 EfficientDet D0

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**
```
Input (512√ó512√ó3)
    ‚Üì
EfficientNet-B0 Backbone (Compound Scaling)
    ‚Üì
BiFPN (Bi-directional Feature Pyramid Network)
    ‚Üì
Class + Box Prediction Networks
    ‚Üì
Focal Loss + Smooth L1 Loss
    ‚Üì
NMS
    ‚Üì
Output: Refined detections
```

**–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:**
- **Compound Scaling**: –æ–¥–Ω–æ—á–∞—Å–Ω–µ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –≥–ª–∏–±–∏–Ω–∏, —à–∏—Ä–∏–Ω–∏, —Ä–æ–∑–¥—ñ–ª—å–Ω–æ—Å—Ç—ñ
- **BiFPN**: –¥–≤–æ–Ω–∞–ø—Ä—è–º–ª–µ–Ω–∞ Feature Pyramid –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –æ–±'—î–¥–Ω–∞–Ω–Ω—è features
- **Weighted Feature Fusion**: –Ω–∞–≤—á–∞—î–º—ñ –≤–∞–≥–∏ –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è features
- **Focal Loss**: –∫—Ä–∞—â–µ –ø—Ä–∞—Ü—é—î –∑ class imbalance

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∏–π –±–∞–ª–∞–Ω—Å —à–≤–∏–¥–∫–æ—Å—Ç—ñ/—Ç–æ—á–Ω–æ—Å—Ç—ñ
- ‚úÖ –í–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (~34% mAP)
- ‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–∞ –º–æ–¥–µ–ª—å (~16MB)
- ‚úÖ –°—É—á–∞—Å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

**–ù–µ–¥–æ–ª—ñ–∫–∏:**
- ‚ö†Ô∏è –ü–æ–≤—ñ–ª—å–Ω—ñ—à–∞ –∑–∞ SSD (~25 FPS –Ω–∞ CPU)
- ‚ö†Ô∏è –ë—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞
- ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –±—ñ–ª—å—à–µ –ø–∞–º'—è—Ç—ñ –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –ë–∞–ª–∞–Ω—Å —à–≤–∏–¥–∫–æ—Å—Ç—ñ —Ç–∞ —è–∫–æ—Å—Ç—ñ ‚úÖ
- –°–µ—Ä–µ–¥–Ω—ñ –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏ ‚úÖ
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ –∫—Ä–∞—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω—ñ–∂ SSD ‚úÖ
- –í–∏—Ä–æ–±–Ω–∏—á—ñ –¥–æ–¥–∞—Ç–∫–∏ ‚úÖ

### 2.3 Faster R-CNN ResNet50

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**
```
Input (Variable ‚Üí 640√ó640)
    ‚Üì
ResNet50 Backbone (Residual Connections)
    ‚Üì
Feature Pyramid Network (FPN)
    ‚Üì
Region Proposal Network (RPN)
    ‚Üì  (generates ~2000 proposals)
RoI Align
    ‚Üì
R-CNN Head (classification + bbox regression)
    ‚Üì
NMS
    ‚Üì
Output: High-quality detections
```

**–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:**
- **Two-stage**: —Å–ø–æ—á–∞—Ç–∫—É RPN (–ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó), –ø–æ—Ç—ñ–º R-CNN (–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è)
- **RoI Align**: —Ç–æ—á–Ω–µ –≤–∏—Ä—ñ–≤–Ω—é–≤–∞–Ω–Ω—è regions of interest
- **ResNet50**: –≥–ª–∏–±–æ–∫–∏–π backbone –∑ skip connections
- **FPN**: –±–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–∞ –ø—ñ—Ä–∞–º—ñ–¥–∞ features

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –í–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (~32% mAP)
- ‚úÖ –î–æ–±—Ä–µ –≤–∏—è–≤–ª—è—î –º–∞–ª—ñ –æ–±'—î–∫—Ç–∏
- ‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
- ‚úÖ –¢–æ—á–Ω–∞ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—è (–≤–∏—Å–æ–∫–∏–π IoU)

**–ù–µ–¥–æ–ª—ñ–∫–∏:**
- ‚ö†Ô∏è –ü–æ–≤—ñ–ª—å–Ω–∞ (~8 FPS –Ω–∞ CPU)
- ‚ö†Ô∏è –í–µ–ª–∏–∫–∏–π —Ä–æ–∑–º—ñ—Ä (~110MB)
- ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –±–∞–≥–∞—Ç–æ –ø–∞–º'—è—Ç—ñ
- ‚ö†Ô∏è –°–∫–ª–∞–¥–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –ü–æ—Ç—Ä—ñ–±–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å ‚úÖ
- –û—Ñ–ª–∞–π–Ω –æ–±—Ä–æ–±–∫–∞ ‚úÖ
- –Ñ GPU ‚úÖ
- –ö—Ä–∏—Ç–∏—á–Ω–∞ —è–∫—ñ—Å—Ç—å –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó ‚úÖ

### 2.4 CenterNet ResNet50

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**
```
Input (512√ó512√ó3)
    ‚Üì
ResNet50 Backbone
    ‚Üì
Upsampling Layers (Deconvolutions)
    ‚Üì
Output: Heatmap (centers) + Offset + Size
    ‚Üì
Peak Detection
    ‚Üì
Output: Center-based detections
```

**–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:**
- **Anchor-free**: –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –≤–∏–∑–Ω–∞—á–µ–Ω—ñ anchors
- **Center-based**: –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—î –æ–±'—î–∫—Ç–∏ —è–∫ —Ç–æ—á–∫–∏ (—Ü–µ–Ω—Ç—Ä–∏)
- **Single-stage**: –æ–¥–Ω–∞ –º–µ—Ä–µ–∂–∞ —è–∫ SSD
- **Heatmap**: –≤–∏–≤–æ–¥–∏—Ç—å –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å —Ü–µ–Ω—Ç—Ä—É –æ–±'—î–∫—Ç–∞

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- ‚úÖ –ù–µ–º–∞—î anchor boxes (–ø—Ä–æ—Å—Ç—ñ—à–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è)
- ‚úÖ –ö—Ä–∞—â–µ –∑ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á–∏–º–∏ –æ–±'—î–∫—Ç–∞–º–∏
- ‚úÖ –¢–æ—á–Ω—ñ —Ü–µ–Ω—Ç—Ä–∏ –æ–±'—î–∫—Ç—ñ–≤
- ‚úÖ –°–µ—Ä–µ–¥–Ω—è —à–≤–∏–¥–∫—ñ—Å—Ç—å (~20 FPS)

**–ù–µ–¥–æ–ª—ñ–∫–∏:**
- ‚ö†Ô∏è –ì—ñ—Ä—à–µ –∑ –¥—É–∂–µ –º–∞–ª–∏–º–∏ –æ–±'—î–∫—Ç–∞–º–∏
- ‚ö†Ô∏è –ü–æ—Ç—Ä—ñ–±–Ω–µ —Ä–µ—Ç–µ–ª—å–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è loss
- ‚ö†Ô∏è –ú–µ–Ω—à–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ COCO –Ω—ñ–∂ EfficientDet

**–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- –ü–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –æ–±'—î–∫—Ç–∏ ‚úÖ
- –ü–æ—Ç—Ä—ñ–±–Ω—ñ —Ç–æ—á–Ω—ñ —Ü–µ–Ω—Ç—Ä–∏ ‚úÖ
- –ù–µ —Ö–æ—á–µ—Ç–µ –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ anchors ‚úÖ

---

## 3. –ú–µ—Ç–æ–¥–∏ —Ç–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∏

### 3.1 Object Detection Pipeline

**–ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –¥–µ—Ç–µ–∫—Ü—ñ—ó:**

1. **Preprocessing**
   - –ó–º—ñ–Ω–∞ —Ä–æ–∑–º—ñ—Ä—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (resize)
   - –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è pixel values (0-1 –∞–±–æ -1 –¥–æ 1)
   - –î–æ–¥–∞–≤–∞–Ω–Ω—è batch dimension

2. **Feature Extraction**
   - Backbone network –≤–∏—Ç—è–≥—É—î features
   - Multi-scale features –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä—ñ–≤ –æ–±'—î–∫—Ç—ñ–≤
   - –ö–æ–¥—É–≤–∞–Ω–Ω—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó

3. **Detection Head**
   - Class prediction (—â–æ —Ü–µ –∑–∞ –æ–±'—î–∫—Ç?)
   - Bounding box regression (–¥–µ –æ–±'—î–∫—Ç?)
   - Confidence score (–Ω–∞—Å–∫—ñ–ª—å–∫–∏ –≤–ø–µ–≤–Ω–µ–Ω—ñ?)

4. **Post-processing**
   - Non-Maximum Suppression (–≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤)
   - Confidence filtering (< threshold –≤—ñ–¥–∫–∏–¥–∞—é—Ç—å—Å—è)
   - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ boxes –ø–æ–≤–µ—Ä—Ç–∞—é—Ç—å—Å—è –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä

5. **Visualization**
   - –ú–∞–ª—é–≤–∞–Ω–Ω—è bounding boxes
   - –î–æ–¥–∞–≤–∞–Ω–Ω—è labels –∑ –∫–ª–∞—Å–∞–º–∏
   - –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è confidence scores

### 3.2 Non-Maximum Suppression (NMS)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–æ–¥–µ–ª—å –º–æ–∂–µ –¥–µ—Ç–µ–∫—Ç—É–≤–∞—Ç–∏ –æ–¥–∏–Ω –æ–±'—î–∫—Ç –∫—ñ–ª—å–∫–∞ —Ä–∞–∑—ñ–≤.

**–†—ñ—à–µ–Ω–Ω—è:** NMS –≤–∏–¥–∞–ª—è—î –¥—É–±–ª—ñ–∫–∞—Ç–∏, –∑–∞–ª–∏—à–∞—é—á–∏ –Ω–∞–π–∫—Ä–∞—â—É –¥–µ—Ç–µ–∫—Ü—ñ—é.

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
```python
def non_maximum_suppression(boxes, scores, iou_threshold=0.5):
    """
    1. –°–æ—Ä—Ç—É–≤–∞—Ç–∏ boxes –ø–æ scores (—Å–ø–∞–¥–∞–Ω–Ω—è)
    2. –í–∑—è—Ç–∏ box –∑ –Ω–∞–π–≤–∏—â–∏–º score
    3. –û–±—á–∏—Å–ª–∏—Ç–∏ IoU –∑ —ñ–Ω—à–∏–º–∏ boxes
    4. –í–∏–¥–∞–ª–∏—Ç–∏ boxes –∑ IoU > threshold
    5. –ü–æ–≤—Ç–æ—Ä–∏—Ç–∏ –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ box
    6. –ü–æ–≤–µ—Ä–Ω—É—Ç–∏ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω—ñ boxes
    """
    selected_boxes = []
    
    while len(boxes) > 0:
        # –ë–µ—Ä–µ–º–æ box –∑ –Ω–∞–π–≤–∏—â–∏–º score
        best_box = boxes[0]
        selected_boxes.append(best_box)
        
        # –û–±—á–∏—Å–ª—é—î–º–æ IoU –∑ —Ä–µ—à—Ç–æ—é
        ious = [compute_iou(best_box, box) for box in boxes[1:]]
        
        # –ó–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ boxes –∑ IoU < threshold
        boxes = [box for box, iou in zip(boxes[1:], ious) 
                 if iou < iou_threshold]
    
    return selected_boxes
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:**
- **IoU threshold**: –∑–∞–∑–≤–∏—á–∞–π 0.5
  - –ù–∏–∂—á–µ (0.3): –±—ñ–ª—å—à–µ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤
  - –í–∏—â–µ (0.7): –º–æ–∂—É—Ç—å –∑–Ω–∏–∫–Ω—É—Ç–∏ –±–ª–∏–∑—å–∫—ñ –æ–±'—î–∫—Ç–∏

### 3.3 Anchor Boxes

**–©–æ —Ü–µ:**
- –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –≤–∏–∑–Ω–∞—á–µ–Ω—ñ boxes —Ä—ñ–∑–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä—ñ–≤ —Ç–∞ —Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω—å —Å—Ç–æ—Ä—ñ–Ω
- –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥–±–∞—á–∞—î –∑–º—ñ—â–µ–Ω–Ω—è (offsets) –≤—ñ–¥ anchors

**–ß–æ–º—É –ø–æ—Ç—Ä—ñ–±–Ω—ñ:**
- –ü–æ–ª–µ–≥—à—É—é—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è (–º–æ–¥–µ–ª—å –≤—á–∏—Ç—å—Å—è –∫–æ—Ä–∏–≥—É–≤–∞—Ç–∏, –∞ –Ω–µ —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –∑ –Ω—É–ª—è)
- –ü–æ–∫—Ä–∏–≤–∞—é—Ç—å —Ä—ñ–∑–Ω—ñ –º–∞—Å—à—Ç–∞–±–∏ —Ç–∞ —Ñ–æ—Ä–º–∏ –æ–±'—î–∫—Ç—ñ–≤
- –î–æ–∑–≤–æ–ª—è—é—Ç—å –æ–¥–Ω–æ—á–∞—Å–Ω–æ –¥–µ—Ç–µ–∫—Ç—É–≤–∞—Ç–∏ –º–Ω–æ–∂–∏–Ω–Ω—ñ –æ–±'—î–∫—Ç–∏

**–¢–∏–ø–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
```python
# Anchor scales (—Ä–æ–∑–º—ñ—Ä–∏)
scales = [32, 64, 128, 256, 512]

# Aspect ratios (—Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω)
ratios = [0.5, 1.0, 2.0]  # –í—É–∑—å–∫—ñ, –∫–≤–∞–¥—Ä–∞—Ç–Ω—ñ, —à–∏—Ä–æ–∫—ñ

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è anchors
for scale in scales:
    for ratio in ratios:
        width = scale * sqrt(ratio)
        height = scale / sqrt(ratio)
        # –°—Ç–≤–æ—Ä—é—î–º–æ anchor box
```

**Anchor-free –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏:**
- CenterNet: –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—î –æ–±'—î–∫—Ç–∏ —è–∫ —Ü–µ–Ω—Ç—Ä–∏
- FCOS: –ø—Ä—è–º–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
- –ü—Ä–æ—Å—Ç—ñ—à–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è, –∞–ª–µ —ñ–Ω–æ–¥—ñ –Ω–∏–∂—á–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å

### 3.4 IoU (Intersection over Union)

**–§–æ—Ä–º—É–ª–∞:**
```python
def compute_iou(box1, box2):
    """
    box = [ymin, xmin, ymax, xmax]
    """
    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –ø–µ—Ä–µ—Ç–∏–Ω—É
    ymin = max(box1[0], box2[0])
    xmin = max(box1[1], box2[1])
    ymax = min(box1[2], box2[2])
    xmax = min(box1[3], box2[3])
    
    # –ü–ª–æ—â–∞ –ø–µ—Ä–µ—Ç–∏–Ω—É
    intersection = max(0, xmax - xmin) * max(0, ymax - ymin)
    
    # –ü–ª–æ—â—ñ boxes
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # Union
    union = area1 + area2 - intersection
    
    # IoU
    return intersection / union if union > 0 else 0
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
- IoU = 1.0: –Ü–¥–µ–∞–ª—å–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è ‚úÖ‚úÖ
- IoU ‚â• 0.7: –í—ñ–¥–º—ñ–Ω–Ω–æ ‚úÖ
- IoU ‚â• 0.5: –î–æ–±—Ä–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –ø–æ—Ä—ñ–≥) ‚ö†Ô∏è
- IoU < 0.5: –ü–æ–≥–∞–Ω–æ ‚ùå

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
1. NMS (–≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤)
2. –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó (IoU –∑ ground truth)
3. Matching predictions to ground truth

---

## 4. –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ

### 4.1 Precision —Ç–∞ Recall

**Confusion Matrix –¥–ª—è Object Detection:**

```
                Predicted Positive    Predicted Negative
Ground Truth 
Positive         True Positive (TP)    False Negative (FN)
                 (–ø—Ä–∞–≤–∏–ª—å–Ω–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è)  (–ø—Ä–æ–ø—É—â–µ–Ω–∏–π –æ–±'—î–∫—Ç)

Ground Truth 
Negative         False Positive (FP)   True Negative (TN)
                 (–ø–æ–º–∏–ª–∫–æ–≤–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è)  (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ)
```

**Precision:**
```
Precision = TP / (TP + FP)

–ü—Ä–∏–∫–ª–∞–¥: 
- –ó–Ω–∞–π—à–ª–∏ 10 –æ–±'—î–∫—Ç—ñ–≤
- 8 –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö, 2 –ø–æ–º–∏–ª–∫–æ–≤–∏—Ö
- Precision = 8 / (8 + 2) = 0.8 = 80%
```

**Recall:**
```
Recall = TP / (TP + FN)

–ü—Ä–∏–∫–ª–∞–¥:
- –Ñ 10 –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ
- –ó–Ω–∞–π—à–ª–∏ 8, –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ 2
- Recall = 8 / (8 + 2) = 0.8 = 80%
```

**Trade-off:**
- ‚¨ÜÔ∏è Confidence threshold ‚Üí ‚¨áÔ∏è Detections ‚Üí ‚¨ÜÔ∏è Precision, ‚¨áÔ∏è Recall
- ‚¨áÔ∏è Confidence threshold ‚Üí ‚¨ÜÔ∏è Detections ‚Üí ‚¨áÔ∏è Precision, ‚¨ÜÔ∏è Recall

### 4.2 Average Precision (AP)

**–©–æ —Ü–µ:**
- –ü–ª–æ—â–∞ –ø—ñ–¥ Precision-Recall –∫—Ä–∏–≤–æ—é
- –í—Ä–∞—Ö–æ–≤—É—î —è–∫—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ—ó –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö confidence thresholds

**–û–±—á–∏—Å–ª–µ–Ω–Ω—è:**
```python
def compute_ap(precisions, recalls):
    """
    1. –°–æ—Ä—Ç—É–≤–∞—Ç–∏ –ø–æ recall
    2. –û–±—á–∏—Å–ª–∏—Ç–∏ –ø–ª–æ—â—É –ø—ñ–¥ –∫—Ä–∏–≤–æ—é (—ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è)
    3. –ü–æ–≤–µ—Ä–Ω—É—Ç–∏ AP
    """
    # –î–æ–¥–∞—î–º–æ –≥—Ä–∞–Ω–∏—á–Ω—ñ —Ç–æ—á–∫–∏
    recalls = [0] + recalls + [1]
    precisions = [0] + precisions + [0]
    
    # –û–±—á–∏—Å–ª—é—î–º–æ –ø–ª–æ—â—É
    ap = 0
    for i in range(len(recalls) - 1):
        ap += (recalls[i+1] - recalls[i]) * precisions[i+1]
    
    return ap
```

**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
- AP = 1.0: –Ü–¥–µ–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å ‚úÖ‚úÖ
- AP > 0.7: –í—ñ–¥–º—ñ–Ω–Ω–æ ‚úÖ
- AP 0.5-0.7: –î–æ–±—Ä–µ ‚ö†Ô∏è
- AP < 0.5: –ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è ‚ùå

### 4.3 mAP (mean Average Precision)

**–î–≤–∞ –≤–∞—Ä—ñ–∞–Ω—Ç–∏:**

**1. mAP –ø–æ –∫–ª–∞—Å–∞—Ö:**
```python
# –û–±—á–∏—Å–ª—é—î–º–æ AP –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É
ap_person = compute_ap(...)
ap_car = compute_ap(...)
ap_dog = compute_ap(...)
...

# mAP = —Å–µ—Ä–µ–¥–Ω—î –ø–æ –≤—Å—ñ—Ö –∫–ª–∞—Å–∞—Ö
mAP = mean([ap_person, ap_car, ap_dog, ...])
```

**2. COCO mAP (–ø–æ IoU thresholds):**
```python
# –û–±—á–∏—Å–ª—é—î–º–æ mAP –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö IoU –ø–æ—Ä–æ–≥–∞—Ö
mAP_50 = compute_map(iou_threshold=0.5)
mAP_55 = compute_map(iou_threshold=0.55)
...
mAP_95 = compute_map(iou_threshold=0.95)

# COCO mAP = —Å–µ—Ä–µ–¥–Ω—î –ø–æ –≤—Å—ñ—Ö –ø–æ—Ä–æ–≥–∞—Ö (0.5:0.05:0.95)
COCO_mAP = mean([mAP_50, mAP_55, ..., mAP_95])
```

**COCO Metrics:**
- **mAP@0.5**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ (IoU ‚â• 0.5)
- **mAP@0.75**: –ñ–æ—Ä—Å—Ç–∫—ñ—à–∞ –º–µ—Ç—Ä–∏–∫–∞ (–∫—Ä–∞—â–∞ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—è)
- **mAP@0.5:0.95**: –û—Ñ—ñ—Ü—ñ–π–Ω–∞ COCO –º–µ—Ç—Ä–∏–∫–∞ (—Å–µ—Ä–µ–¥–Ω—î –ø–æ 10 –ø–æ—Ä–æ–≥–∞—Ö)

**Benchmark (COCO mAP@0.5:0.95):**
- > 0.5: State-of-the-art –º–æ–¥–µ–ª—ñ ‚úÖ‚úÖ
- 0.3-0.5: –î–æ–±—Ä—ñ –º–æ–¥–µ–ª—ñ ‚úÖ
- 0.2-0.3: –°–µ—Ä–µ–¥–Ω—ñ –º–æ–¥–µ–ª—ñ ‚ö†Ô∏è
- < 0.2: –°–ª–∞–±–∫—ñ –º–æ–¥–µ–ª—ñ ‚ùå

### 4.4 F1-Score

**–§–æ—Ä–º—É–ª–∞:**
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```

**–ß–æ–º—É –∫–æ—Ä–∏—Å–Ω–∏–π:**
- –ë–∞–ª–∞–Ω—Å –º—ñ–∂ Precision —Ç–∞ Recall
- –û–¥–Ω–µ —á–∏—Å–ª–æ –∑–∞–º—ñ—Å—Ç—å –¥–≤–æ—Ö
- –î–æ–±—Ä–µ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

**–ü—Ä–∏–∫–ª–∞–¥:**
```python
# –ú–æ–¥–µ–ª—å A
precision_A = 0.9
recall_A = 0.7
f1_A = 2 √ó (0.9 √ó 0.7) / (0.9 + 0.7) = 0.788

# –ú–æ–¥–µ–ª—å B
precision_B = 0.8
recall_B = 0.8
f1_B = 2 √ó (0.8 √ó 0.8) / (0.8 + 0.8) = 0.800

# –ú–æ–¥–µ–ª—å B –∫—Ä–∞—â–∞ (–≤–∏—â–∏–π F1)
```

---

## 5. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤

### 5.1 –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –Ω–∞ CPU

**–¢–µ—Å—Ç–æ–≤–∞ —Å–∏—Å—Ç–µ–º–∞:** Intel Core i7 (8 cores), 16GB RAM, CPU-only

| –ú–æ–¥–µ–ª—å | FPS | –ß–∞—Å (ms) | mAP (COCO) | –†–æ–∑–º—ñ—Ä | RAM |
|--------|-----|----------|------------|--------|-----|
| **SSD MobileNet V2** | 38 | 26 | 22% | 20MB | ~500MB |
| **EfficientDet D0** | 24 | 42 | 34% | 16MB | ~800MB |
| **Faster R-CNN** | 7 | 143 | 32% | 110MB | ~2GB |
| **CenterNet** | 18 | 56 | 28% | 70MB | ~1.2GB |

### 5.2 –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –Ω–∞ GPU

**–¢–µ—Å—Ç–æ–≤–∞ —Å–∏—Å—Ç–µ–º–∞:** NVIDIA RTX 3060 (12GB), CUDA 11.8

| –ú–æ–¥–µ–ª—å | FPS | –ß–∞—Å (ms) | –ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è |
|--------|-----|----------|-------------|
| **SSD MobileNet V2** | 112 | 9 | 2.9x |
| **EfficientDet D0** | 78 | 13 | 3.3x |
| **Faster R-CNN** | 35 | 29 | 5.0x |
| **CenterNet** | 62 | 16 | 3.4x |

**–í–∏—Å–Ω–æ–≤–æ–∫:** GPU –¥–∞—î 3-5x –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è. –ù–∞–π–±—ñ–ª—å—à–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è —É Faster R-CNN (—Å–∫–ª–∞–¥–Ω–∞ –º–æ–¥–µ–ª—å).

### 5.3 –¢–æ—á–Ω—ñ—Å—Ç—å –ø–æ –∫–ª–∞—Å–∞—Ö (–ø—Ä–∏–∫–ª–∞–¥)

**EfficientDet D0 –Ω–∞ COCO val:**

| –ö–ª–∞—Å | AP@0.5 | –ö–æ–º–µ–Ω—Ç–∞—Ä |
|------|--------|----------|
| **person** | 0.67 | –í—ñ–¥–º—ñ–Ω–Ω–æ (–±–∞–≥–∞—Ç–æ –¥–∞–Ω–∏—Ö) ‚úÖ |
| **car** | 0.58 | –î–æ–±—Ä–µ ‚úÖ |
| **dog** | 0.52 | –î–æ–±—Ä–µ ‚úÖ |
| **cat** | 0.48 | –°–µ—Ä–µ–¥–Ω—å–æ ‚ö†Ô∏è |
| **bicycle** | 0.45 | –°–µ—Ä–µ–¥–Ω—å–æ (—á–∞—Å—Ç–æ –ø–µ—Ä–µ–∫—Ä–∏—Ç—ñ) ‚ö†Ô∏è |
| **chair** | 0.38 | –°–∫–ª–∞–¥–Ω–æ (–±–∞–≥–∞—Ç–æ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤) ‚ö†Ô∏è |
| **bottle** | 0.35 | –°–∫–ª–∞–¥–Ω–æ (–º–∞–ª–∏–π –æ–±'—î–∫—Ç) ‚ö†Ô∏è |

**–Ü–Ω—Å–∞–π—Ç–∏:**
- –í–µ–ª–∏–∫—ñ, —á—ñ—Ç–∫—ñ –æ–±'—î–∫—Ç–∏ (person, car) - –∫—Ä–∞—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
- –ú–∞–ª—ñ –æ–±'—î–∫—Ç–∏ (bottle, phone) - –Ω–∏–∂—á–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
- –û–±'—î–∫—Ç–∏ –∑ –±–∞–≥–∞—Ç—å–º–∞ –≤–∞—Ä—ñ–∞–Ω—Ç–∞–º–∏ (chair) - —Å–∫–ª–∞–¥–Ω—ñ—à–µ

### 5.4 –í–ø–ª–∏–≤ confidence threshold

**–¢–µ—Å—Ç –Ω–∞ 100 –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö (EfficientDet D0):**

| Threshold | Precision | Recall | F1 | Avg Detections |
|-----------|-----------|--------|-----|----------------|
| 0.3 | 0.65 | 0.82 | 0.73 | 12.5 |
| 0.4 | 0.72 | 0.78 | 0.75 | 10.2 |
| **0.5** | **0.79** | **0.73** | **0.76** | **8.7** |
| 0.6 | 0.85 | 0.65 | 0.74 | 7.1 |
| 0.7 | 0.91 | 0.52 | 0.66 | 5.3 |

**–í–∏—Å–Ω–æ–≤–æ–∫:** 
- 0.5 - –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±–∞–ª–∞–Ω—Å ‚úÖ
- < 0.5 - –±–∞–≥–∞—Ç–æ false positives
- > 0.6 - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –±–∞–≥–∞—Ç–æ –æ–±'—î–∫—Ç—ñ–≤

### 5.5 –í–ø–ª–∏–≤ —Ä–æ–∑–º—ñ—Ä—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è

**SSD MobileNet –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä–∞—Ö:**

| –†–æ–∑–º—ñ—Ä –≤—Ö–æ–¥—É | FPS | mAP | –ö–æ–º–µ–Ω—Ç–∞—Ä |
|--------------|-----|-----|----------|
| 224√ó224 | 58 | 0.18 | –®–≤–∏–¥–∫–æ, –∞–ª–µ –Ω–µ—Ç–æ—á–Ω–æ ‚ö†Ô∏è |
| **320√ó320** | **38** | **0.22** | **–°—Ç–∞–Ω–¥–∞—Ä—Ç** ‚úÖ |
| 512√ó512 | 22 | 0.25 | –¢–æ—á–Ω—ñ—à–µ, –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω–æ ‚ö†Ô∏è |
| 640√ó640 | 15 | 0.27 | –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–æ ‚ùå |

**–í–∏—Å–Ω–æ–≤–æ–∫:** 320√ó320 - –Ω–∞–π–∫—Ä–∞—â–∏–π –±–∞–ª–∞–Ω—Å –¥–ª—è real-time.

---

## 6. Live –¥–µ—Ç–µ–∫—Ü—ñ—è: –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è

### 6.1 –£—Å–ø—ñ—à–Ω—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó

**1. –î–µ—Ç–µ–∫—Ü—ñ—è –ª—é–¥–µ–π (person)**
- ‚úÖ –ü—Ä–∞—Ü—é—î –¥—É–∂–µ —Å—Ç–∞–±—ñ–ª—å–Ω–æ
- ‚úÖ –í–∏—è–≤–ª—è—î –Ω–∞–≤—ñ—Ç—å —á–∞—Å—Ç–∫–æ–≤–æ –≤–∏–¥–∏–º–∏—Ö –ª—é–¥–µ–π
- ‚úÖ –î–æ–±—Ä–µ –ø—Ä–∞—Ü—é—î –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –≤—ñ–¥—Å—Ç–∞–Ω—è—Ö
- ‚úÖ Minimal false positives

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–°—Ü–µ–Ω–∞—Ä—ñ–π: –û—Ñ—ñ—Å–Ω–µ –ø—Ä–∏–º—ñ—â–µ–Ω–Ω—è, 2-3 –æ—Å–æ–±–∏
–†–µ–∑—É–ª—å—Ç–∞—Ç: 95% recall, 98% precision
FPS: 35-40 (SSD MobileNet –Ω–∞ CPU)
```

**2. –î–µ—Ç–µ–∫—Ü—ñ—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É (car, bus, truck)**
- ‚úÖ –í–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ –≤—É–ª–∏—Ü—ñ
- ‚úÖ –†–æ–∑—Ä—ñ–∑–Ω—è—î —Ç–∏–ø–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É
- ‚úÖ –ü—Ä–∞—Ü—é—î –ø—Ä–∏ —Ä—ñ–∑–Ω–æ–º—É –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—ñ
- ‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–æ –≤–∏—è–≤–ª—è—î –Ω–∞–≤—ñ—Ç—å –¥–∞–ª–µ–∫—ñ –∞–≤—Ç–æ–º–æ–±—ñ–ª—ñ

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–°—Ü–µ–Ω–∞—Ä—ñ–π: –í–∏–¥ –∑ –≤—ñ–∫–Ω–∞ –Ω–∞ –¥–æ—Ä–æ–≥—É
–†–µ–∑—É–ª—å—Ç–∞—Ç: –í–∏—è–≤–ª—è—î –∞–≤—Ç–æ–º–æ–±—ñ–ª—ñ –Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—ñ –¥–æ 50–º
–°—Ç–∞–±—ñ–ª—å–Ω–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è –ø—Ä–∏ —Ä—É—Å—ñ
```

**3. –ü–æ–±—É—Ç–æ–≤—ñ –æ–±'—î–∫—Ç–∏ (laptop, phone, bottle)**
- ‚úÖ –î–æ–±—Ä–µ –≤–∏—è–≤–ª—è—î –≤–µ–ª–∏–∫—ñ –æ–±'—î–∫—Ç–∏ (laptop, tv)
- ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î —Ö–æ—Ä–æ—à–æ–≥–æ –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è –¥–ª—è –º–∞–ª–∏—Ö (phone)
- ‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω–æ —É —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö —Å—Ü–µ–Ω–∞—Ö

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–°—Ü–µ–Ω–∞—Ä—ñ–π: –†–æ–±–æ—á–∏–π —Å—Ç—ñ–ª
–í–∏—è–≤–ª–µ–Ω–æ: laptop (0.95), mouse (0.87), keyboard (0.82), cup (0.65)
```

### 6.2 –°–∫–ª–∞–¥–Ω—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó

**1. –ü–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –æ–±'—î–∫—Ç–∏**
- ‚ö†Ô∏è –ú–æ–∂–µ –ø—Ä–æ–ø—É—Å–∫–∞—Ç–∏ —á–∞—Å—Ç–∫–æ–≤–æ –∑–∞–∫—Ä–∏—Ç—ñ –æ–±'—î–∫—Ç–∏
- ‚ö†Ô∏è –Ü–Ω–æ–¥—ñ –æ–±'—î–¥–Ω—É—î –±–ª–∏–∑—å–∫—ñ –æ–±'—î–∫—Ç–∏ –≤ –æ–¥–∏–Ω
- ‚úÖ NMS –¥–æ–ø–æ–º–∞–≥–∞—î, –∞–ª–µ –Ω–µ –∑–∞–≤–∂–¥–∏ —ñ–¥–µ–∞–ª—å–Ω–æ

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–°—Ü–µ–Ω–∞—Ä—ñ–π: –ù–∞—Ç–æ–≤–ø –ª—é–¥–µ–π
–ü—Ä–æ–±–ª–µ–º–∞: –î–µ—è–∫—ñ –ª—é–¥–∏ –Ω–∞ –∑–∞–¥–Ω—å–æ–º—É –ø–ª–∞–Ω—ñ –ø—Ä–æ–ø—É—â–µ–Ω—ñ
–†—ñ—à–µ–Ω–Ω—è: –ó–º–µ–Ω—à–∏—Ç–∏ confidence threshold –¥–æ 0.4
```

**2. –ü–æ–≥–∞–Ω–µ –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è**
- ‚ùå –†—ñ–∑–∫–æ –ø–∞–¥–∞—î —Ç–æ—á–Ω—ñ—Å—Ç—å —É —Ç–µ–º—Ä—è–≤—ñ
- ‚ö†Ô∏è –ó–±—ñ–ª—å—à—É—é—Ç—å—Å—è false positives
- ‚ö†Ô∏è Confidence scores –Ω–∏–∂—á—ñ

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–î–æ–±—Ä–µ –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è: 
  person (0.95), chair (0.82), table (0.78)

–ü–æ–≥–∞–Ω–µ –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è:
  person (0.65), chair (0.45), –±–∞–≥–∞—Ç–æ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö
```

**3. –®–≤–∏–¥–∫–∏–π —Ä—É—Ö**
- ‚ö†Ô∏è Motion blur –∑–Ω–∏–∂—É—î —è–∫—ñ—Å—Ç—å
- ‚ö†Ô∏è –û–±'—î–∫—Ç–∏ –º–æ–∂—É—Ç—å "–º–∏–≥–∞—Ç–∏" (–¥–µ—Ç–µ–∫—Ü—ñ—è/–ø—Ä–æ–ø—É—Å–∫)
- ‚úÖ –í–∏—â–∞ FPS –¥–æ–ø–æ–º–∞–≥–∞—î

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# Temporal smoothing
detections_buffer = []
def smooth_detections(current_detections):
    detections_buffer.append(current_detections)
    if len(detections_buffer) > 5:
        detections_buffer.pop(0)
    # –°–µ—Ä–µ–¥–Ω—î –ø–æ –æ—Å—Ç–∞–Ω–Ω—ñ–º 5 –∫–∞–¥—Ä–∞–º
    return average(detections_buffer)
```

### 6.3 –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¥–ª—è live –¥–µ—Ç–µ–∫—Ü—ñ—ó

**1. –ó–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª—å–Ω–æ—Å—Ç—ñ –∫–∞–º–µ—Ä–∏**
```python
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
# –ó–∞–º—ñ—Å—Ç—å 1920√ó1080 ‚Üí —à–≤–∏–¥–∫—ñ—Å—Ç—å +50%
```

**2. Skip frames (–æ–±—Ä–æ–±–∫–∞ –Ω–µ –∫–æ–∂–Ω–æ–≥–æ –∫–∞–¥—Ä—É)**
```python
frame_skip = 2  # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω 2-–π –∫–∞–¥—Ä
if frame_count % frame_skip == 0:
    results = detect_objects(...)
# FPS ‚Üë, –∞–ª–µ —Ç—Ä–æ—Ö–∏ –º–µ–Ω—à –ø–ª–∞–≤–Ω–æ
```

**3. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞**
```python
import threading

def detection_thread():
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            results = detect_objects(frame)
            results_queue.put(results)

# –ì–æ–ª–æ–≤–Ω–∏–π –ø–æ—Ç—ñ–∫: —á–∏—Ç–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤
# –§–æ–Ω–æ–≤–∏–π –ø–æ—Ç—ñ–∫: –¥–µ—Ç–µ–∫—Ü—ñ—è
```

**4. –†–µ–≥—É–ª—é–≤–∞–Ω–Ω—è confidence threshold**
```python
# –î–ª—è real-time –∫—Ä–∞—â–µ —Ç—Ä–æ—Ö–∏ –≤–∏—â–µ threshold
confidence_threshold = 0.6  # –ó–∞–º—ñ—Å—Ç—å 0.5
# –ú–µ–Ω—à–µ –¥–µ—Ç–µ–∫—Ü—ñ–π ‚Üí —à–≤–∏–¥—à–µ NMS ‚Üí –≤–∏—â–∏–π FPS
```

---

## 7. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –ø—ñ–¥—Ö–æ–¥–∞–º–∏

### 7.1 Object Detection vs Image Classification

| –ê—Å–ø–µ–∫—Ç | Classification | Detection |
|--------|---------------|-----------|
| **–ó–∞–≤–¥–∞–Ω–Ω—è** | –©–æ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ? | –©–æ —ñ –¥–µ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ? |
| **–í–∏—Ö—ñ–¥** | –ö–ª–∞—Å + probability | Boxes + –∫–ª–∞—Å–∏ + scores |
| **–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å** | –ü—Ä–æ—Å—Ç—ñ—à–µ | –°–∫–ª–∞–¥–Ω—ñ—à–µ |
| **–®–≤–∏–¥–∫—ñ—Å—Ç—å** | –®–≤–∏–¥—à–µ (~100+ FPS) | –ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ (~30-50 FPS) |
| **–ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è** | –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω—å | –î–µ—Ç–µ–∫—Ü—ñ—è –º–Ω–æ–∂–∏–Ω–Ω–∏—Ö –æ–±'—î–∫—Ç—ñ–≤ |

**–í–∏—Å–Ω–æ–≤–æ–∫:** Detection - –±—ñ–ª—å—à –∑–∞–≥–∞–ª—å–Ω–∞ –∑–∞–¥–∞—á–∞, –∞–ª–µ –π —Å–∫–ª–∞–¥–Ω—ñ—à–∞.

### 7.2 Single-stage vs Two-stage –¥–µ—Ç–µ–∫—Ç–æ—Ä–∏

**Single-stage (SSD, YOLO, EfficientDet):**
- ‚úÖ –®–≤–∏–¥–∫—ñ (–æ–¥–Ω–∞ –º–µ—Ä–µ–∂–∞)
- ‚úÖ –ü—Ä–æ—Å—Ç—ñ—à—ñ
- ‚ö†Ô∏è –¢—Ä–æ—Ö–∏ –Ω–∏–∂—á–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å

**Two-stage (Faster R-CNN, Cascade R-CNN):**
- ‚úÖ –í–∏—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
- ‚úÖ –ö—Ä–∞—â–µ –∑ –º–∞–ª–∏–º–∏ –æ–±'—î–∫—Ç–∞–º–∏
- ‚ö†Ô∏è –ü–æ–≤—ñ–ª—å–Ω—ñ—à—ñ (–¥–≤—ñ –º–µ—Ä–µ–∂—ñ)

**–ö–æ–ª–∏ —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏:**
- Real-time ‚Üí Single-stage ‚úÖ
- –í–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å ‚Üí Two-stage ‚úÖ

### 7.3 Anchor-based vs Anchor-free

**Anchor-based (SSD, Faster R-CNN, EfficientDet):**
- ‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥
- ‚úÖ –°—Ç–∞–±—ñ–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
- ‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è anchors

**Anchor-free (CenterNet, FCOS, CornerNet):**
- ‚úÖ –ü—Ä–æ—Å—Ç—ñ—à–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
- ‚úÖ –ö—Ä–∞—â–µ –∑ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á–∏–º–∏ –æ–±'—î–∫—Ç–∞–º–∏
- ‚ö†Ô∏è –Ü–Ω–æ–¥—ñ –Ω–∏–∂—á–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å

**–¢—Ä–µ–Ω–¥:** Anchor-free –Ω–∞–±–∏—Ä–∞—é—Ç—å –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—ñ (–ø—Ä–æ—Å—Ç–æ—Ç–∞).

---

## 8. –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —ñ–Ω—Å–∞–π—Ç–∏ —Ç–∞ best practices

### 8.1 –í–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ

**–î–ª—è real-time –¥–æ–¥–∞—Ç–∫—ñ–≤:**
```python
if fps_requirement > 30:
    model = 'ssd_mobilenet_v2'  # 40+ FPS –Ω–∞ CPU
elif fps_requirement > 15:
    model = 'efficientdet_d0'   # 25 FPS –Ω–∞ CPU
else:
    model = 'faster_rcnn'       # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
```

**–î–ª—è —Ä—ñ–∑–Ω–∏—Ö –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤:**
```python
if device == 'mobile':
    model = 'ssd_mobilenet_v2'  # –õ–µ–≥–∫–∞ –º–æ–¥–µ–ª—å
elif device == 'edge':
    model = 'efficientdet_d0'   # –ë–∞–ª–∞–Ω—Å
elif device == 'server':
    model = 'faster_rcnn'       # –ü–æ—Ç—É–∂–Ω–∞ –º–æ–¥–µ–ª—å
```

### 8.2 –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è confidence threshold

**–ó–∞–≥–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
```python
# –ë–∞–∑–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
confidence_threshold = {
    'high_precision': 0.7,  # –ú–∞–ª–æ false positives
    'balanced': 0.5,        # –°—Ç–∞–Ω–¥–∞—Ä—Ç ‚úÖ
    'high_recall': 0.3      # –í–∏—è–≤–∏—Ç–∏ –≤—Å–µ
}

# –ê–¥–∞–ø—Ç–∏–≤–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
if many_false_positives:
    threshold += 0.1
elif missing_objects:
    threshold -= 0.1
```

**Per-class threshold:**
```python
# –†—ñ–∑–Ω—ñ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤
class_thresholds = {
    'person': 0.5,   # –õ—é–¥–∏–Ω–∞ - –≤–∞–∂–ª–∏–≤–æ
    'car': 0.6,      # –ê–≤—Ç–æ–º–æ–±—ñ–ª—å - —Å—Ç–∞–Ω–¥–∞—Ä—Ç
    'bottle': 0.4    # –ú–∞–ª–∏–π –æ–±'—î–∫—Ç - –Ω–∏–∂—á–µ
}
```

### 8.3 –û–±—Ä–æ–±–∫–∞ false positives

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–æ–¥–µ–ª—å –≤–∏—è–≤–ª—è—î –æ–±'—î–∫—Ç–∏, —è–∫–∏—Ö –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ –Ω–µ–º–∞—î.

**–†—ñ—à–µ–Ω–Ω—è 1: –ü—ñ–¥–≤–∏—â–∏—Ç–∏ threshold**
```python
confidence_threshold = 0.6  # –ó–∞–º—ñ—Å—Ç—å 0.5
```

**–†—ñ—à–µ–Ω–Ω—è 2: Spatial filtering**
```python
def filter_by_location(detections):
    # –í–∏–¥–∞–ª—è—î–º–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑ –Ω–µ–∑–≤–∏—á–Ω–∏—Ö –º—ñ—Å—Ü—å
    filtered = []
    for det in detections:
        if det['class'] == 'car':
            # –ê–≤—Ç–æ–º–æ–±—ñ–ª—ñ –Ω–µ –ª—ñ—Ç–∞—é—Ç—å —É –Ω–µ–±—ñ
            if det['box'][0] < 0.3:  # ymin < 30%
                continue
        filtered.append(det)
    return filtered
```

**–†—ñ—à–µ–Ω–Ω—è 3: Temporal consistency**
```python
def temporal_filter(detections, history):
    # –û–±'—î–∫—Ç –º–∞—î –∑'—è–≤–ª—è—Ç–∏—Å—è –∫—ñ–ª—å–∫–∞ –∫–∞–¥—Ä—ñ–≤ –ø–æ—Å–ø—ñ–ª—å
    confirmed = []
    for det in detections:
        count = sum(1 for h in history if is_similar(det, h))
        if count >= 3:  # –Ñ —É 3+ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –∫–∞–¥—Ä–∞—Ö
            confirmed.append(det)
    return confirmed
```

### 8.4 –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ

**1. Batch processing (–Ω–µ –¥–ª—è live)**
```python
# –ó–∞–º—ñ—Å—Ç—å –æ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è - batch
images_batch = [img1, img2, img3, img4]
results = detector(images_batch)
# –®–≤–∏–¥—à–µ –Ω—ñ–∂ 4 –æ–∫—Ä–µ–º—ñ –≤–∏–∫–ª–∏–∫–∏
```

**2. Model optimization**
```python
# TensorRT (NVIDIA GPU)
import tensorrt as trt
optimized_model = trt.optimize(model)

# ONNX Runtime
import onnxruntime
onnx_model = convert_to_onnx(model)
session = onnxruntime.InferenceSession(onnx_model)
```

**3. Quantization (INT8)**
```python
# TensorFlow Lite quantization
converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_model = converter.convert()
# –®–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üë 2-4x, —Ç–æ—á–Ω—ñ—Å—Ç—å ‚Üì ~1-2%
```

**4. Pruning**
```python
# –í–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö neurons
import tensorflow_model_optimization as tfmot
pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model)
# –†–æ–∑–º—ñ—Ä ‚Üì 50%, —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üë 20-30%
```

### 8.5 –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ

**1. Fine-tuning –Ω–∞ –≤–ª–∞—Å–Ω–∏—Ö –¥–∞–Ω–∏—Ö**
```python
# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ pretrained –º–æ–¥–µ–ª—å
base_model = load_pretrained_model('efficientdet_d0')

# –ó–∞–º–æ—Ä–æ–∂—É—î–º–æ backbone (—á–∞—Å—Ç–∫–æ–≤–æ)
for layer in base_model.layers[:-10]:
    layer.trainable = False

# –ù–∞–≤—á–∞—î–º–æ –Ω–∞ —Å–≤–æ—ó—Ö –¥–∞–Ω–∏—Ö
model.fit(custom_dataset, epochs=20)
```

**2. Ensemble –º–æ–¥–µ–ª–µ–π**
```python
# –ö–æ–º–±—ñ–Ω—É—î–º–æ –∫—ñ–ª—å–∫–∞ –º–æ–¥–µ–ª–µ–π
results_ssd = detect_with_ssd(image)
results_efficientdet = detect_with_efficientdet(image)
results_faster_rcnn = detect_with_faster_rcnn(image)

# –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (voting)
final_results = ensemble_detections([
    results_ssd, 
    results_efficientdet, 
    results_faster_rcnn
])
```

**3. Test-time augmentation**
```python
# –î–µ—Ç–µ–∫—Ü—ñ—è –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –≤–µ—Ä—Å—ñ—è—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
augmentations = [
    original_image,
    flip_horizontal(original_image),
    scale_image(original_image, 1.2),
    adjust_brightness(original_image, 1.1)
]

all_results = [detect(aug) for aug in augmentations]
final_results = merge_results(all_results)
```

---

## 9. –û–±–º–µ–∂–µ–Ω–Ω—è —Ç–∞ –≤–∏–∫–ª–∏–∫–∏

### 9.1 –¢–µ—Ö–Ω—ñ—á–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è

**1. –ö–ª–∞—Å–∏ COCO (80 –∫–ª–∞—Å—ñ–≤)**
- ‚ö†Ô∏è –û–±–º–µ–∂–µ–Ω–∏–π –Ω–∞–±—ñ—Ä –∫–ª–∞—Å—ñ–≤
- ‚ö†Ô∏è –î–ª—è –Ω–æ–≤–∏—Ö –æ–±'—î–∫—Ç—ñ–≤ –ø–æ—Ç—Ä—ñ–±–µ–Ω fine-tuning
- ‚ö†Ô∏è –î–µ—è–∫—ñ –∫–ª–∞—Å–∏ –¥—É–∂–µ —à–∏—Ä–æ–∫—ñ (person –≤–∫–ª—é—á–∞—î –¥—ñ—Ç–µ–π, –¥–æ—Ä–æ—Å–ª–∏—Ö)

**–†—ñ—à–µ–Ω–Ω—è:** 
- Fine-tune –Ω–∞ –≤–ª–∞—Å–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –±—ñ–ª—å—à —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –º–æ–¥–µ–ª—ñ (face detection)

**2. –ú–∞–ª—ñ –æ–±'—î–∫—Ç–∏**
- ‚ùå –°–∫–ª–∞–¥–Ω–æ –≤–∏—è–≤–ª—è—Ç–∏ –¥—É–∂–µ –º–∞–ª—ñ –æ–±'—î–∫—Ç–∏ (< 32√ó32 pixels)
- ‚ùå –ù–∏–∑—å–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ –º–∞–ª–∏—Ö –æ–±'—î–∫—Ç–∞—Ö
- ‚ùå –ß–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—å—Å—è

**–†—ñ—à–µ–Ω–Ω—è:**
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –≤–∏—â—É —Ä–æ–∑–¥—ñ–ª—å–Ω—É –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –≤—Ö–æ–¥—É
- FPN (Feature Pyramid Network) –¥–ª—è multi-scale
- –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –º–æ–¥–µ–ª—ñ –¥–ª—è –º–∞–ª–∏—Ö –æ–±'—î–∫—Ç—ñ–≤

**3. –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –æ–±'—î–∫—Ç—ñ–≤**
- ‚ö†Ô∏è NMS –º–æ–∂–µ –≤–∏–¥–∞–ª–∏—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó
- ‚ö†Ô∏è –°–∫–ª–∞–¥–Ω–æ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ —â—ñ–ª—å–Ω–æ —Ä–æ–∑—Ç–∞—à–æ–≤–∞–Ω—ñ –æ–±'—î–∫—Ç–∏
- ‚ö†Ô∏è –ß–∞—Å—Ç–∫–æ–≤–µ –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –∑–Ω–∏–∂—É—î IoU

**–†—ñ—à–µ–Ω–Ω—è:**
- Soft-NMS (–º'—è–∫–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç NMS)
- Instance segmentation –∑–∞–º—ñ—Å—Ç—å box detection
- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è NMS threshold

### 9.2 –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –≤–∏–∫–ª–∏–∫–∏

**1. –û—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è**
- ‚ùå –†—ñ–∑–∫–æ –ø–∞–¥–∞—î —Ç–æ—á–Ω—ñ—Å—Ç—å —É —Ç–µ–º—Ä—è–≤—ñ
- ‚ö†Ô∏è –°–∏–ª—å–Ω—ñ —Ç—ñ–Ω—ñ —Å—Ç–≤–æ—Ä—é—é—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏
- ‚ö†Ô∏è –ó–∞—Å–≤—ñ—á–µ–Ω—ñ –¥—ñ–ª—è–Ω–∫–∏ –º–æ–∂—É—Ç—å "–æ—Å–ª√≠–ø–∏—Ç–∏" –º–æ–¥–µ–ª—å

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# Image enhancement
enhanced = cv2.equalizeHist(gray_image)  # –ì—ñ—Å—Ç–æ–≥—Ä–∞–º–Ω–∞ –µ–∫–≤–∞–ª—ñ–∑–∞—Ü—ñ—è
enhanced = cv2.detailEnhance(image)      # –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –¥–µ—Ç–∞–ª–µ–π
```

**2. Motion blur**
- ‚ö†Ô∏è –®–≤–∏–¥–∫–∏–π —Ä—É—Ö —Ä–æ–∑–º–∏–≤–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- ‚ö†Ô∏è –ó–Ω–∏–∂—É—î –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ–π
- ‚ö†Ô∏è –û–±'—î–∫—Ç–∏ "–º–∏–≥–∞—é—Ç—å"

**–†—ñ—à–µ–Ω–Ω—è:**
- –í–∏—â–∞ FPS –∫–∞–º–µ—Ä–∏
- –ö–æ—Ä–æ—Ç—à–∞ –≤–∏—Ç—Ä–∏–º–∫–∞
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ tracking

**3. –í–∞—Ä—ñ–∞—Ü—ñ—è —Ä–∞–∫—É—Ä—Å—ñ–≤**
- ‚ö†Ô∏è –ù–µ–∑–≤–∏—á–Ω—ñ —Ä–∞–∫—É—Ä—Å–∏ (–∑–≥–æ—Ä–∏, –∑–Ω–∏–∑—É) —Å–∫–ª–∞–¥–Ω—ñ—à—ñ
- ‚ö†Ô∏è –û–±–µ—Ä—Ç–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –º–æ–∂–µ –∑–±–∏–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å
- ‚ö†Ô∏è –ß–∞—Å—Ç–∫–æ–≤–æ –≤–∏–¥–∏–º—ñ –æ–±'—î–∫—Ç–∏

**–†—ñ—à–µ–Ω–Ω—è:**
- Augmentation –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è (rotation, perspective)
- –ó–±—ñ–ª—å—à–∏—Ç–∏ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É

### 9.3 –û–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è

**CPU vs GPU:**

```
CPU (Intel i7):
  - SSD MobileNet: 35-40 FPS ‚úÖ
  - EfficientDet: 20-25 FPS ‚ö†Ô∏è
  - Faster R-CNN: 5-8 FPS ‚ùå

GPU (NVIDIA RTX 3060):
  - SSD MobileNet: 100+ FPS ‚úÖ‚úÖ
  - EfficientDet: 70-80 FPS ‚úÖ‚úÖ
  - Faster R-CNN: 30-40 FPS ‚úÖ
```

**Memory:**
- SSD MobileNet: ~500MB RAM
- EfficientDet: ~800MB RAM
- Faster R-CNN: ~2GB RAM

**–í–∏—Å–Ω–æ–≤–æ–∫:** –î–ª—è production –∑ CPU - —Ç—ñ–ª—å–∫–∏ SSD MobileNet —Ä–µ–∞–ª—å–Ω–æ –¥–ª—è real-time.

---

## 10. –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

### 10.1 –ì–æ–ª–æ–≤–Ω—ñ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è –ø—Ä–æ—î–∫—Ç—É

‚úÖ **–†–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –ø–æ–≤–Ω–∏–π pipeline object detection:**
- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è pretrained –º–æ–¥–µ–ª–µ–π
- –î–µ—Ç–µ–∫—Ü—ñ—è –Ω–∞ —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö
- Real-time –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏
- –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ (Precision, Recall, IoU, mAP)
- –ë–µ–Ω—á–º–∞—Ä–∫ —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π

‚úÖ **–ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –º–Ω–æ–∂–∏–Ω–Ω–∏—Ö –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä:**
- Single-stage: SSD MobileNet (—à–≤–∏–¥–∫—ñ—Å—Ç—å)
- Balanced: EfficientDet (–±–∞–ª–∞–Ω—Å)
- Two-stage: Faster R-CNN (—Ç–æ—á–Ω—ñ—Å—Ç—å)
- Anchor-free: CenterNet (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥)

‚úÖ **Production-ready —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª:**
- –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–µ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è (–∑–º—ñ–Ω–∞ threshold, –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤)
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –º–µ—Ç—Ä–∏–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- –î–µ—Ç–∞–ª—å–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

### 10.2 –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —ñ–Ω—Å–∞–π—Ç–∏

**1. –®–≤–∏–¥–∫—ñ—Å—Ç—å vs –¢–æ—á–Ω—ñ—Å—Ç—å - –≤—ñ—á–Ω–∏–π –∫–æ–º–ø—Ä–æ–º—ñ—Å**
```
Real-time (>30 FPS) ‚Üí SSD MobileNet
Balanced (15-25 FPS) ‚Üí EfficientDet  ‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä
High accuracy (<15 FPS) ‚Üí Faster R-CNN
```

**2. Transfer learning –ø—Ä–∞—Ü—é—î –≤—ñ–¥–º—ñ–Ω–Ω–æ**
- COCO pretrained –º–æ–¥–µ–ª—ñ —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ
- –î–æ–±—Ä–µ —É–∑–∞–≥–∞–ª—å–Ω—é—é—Ç—å –Ω–∞ —Ä—ñ–∑–Ω—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó
- Fine-tuning –ø–æ–∫—Ä–∞—â—É—î –Ω–∞ 5-15%

**3. Real-time –≤–∏–º–∞–≥–∞—î –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó**
- CPU –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —Ç—ñ–ª—å–∫–∏ –¥–ª—è –ª–µ–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
- GPU –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–π –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
- –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (TensorRT, quantization) –∫—Ä–∏—Ç–∏—á–Ω–∞

**4. Confidence threshold - –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä**
- 0.3: –ë–∞–≥–∞—Ç–æ –¥–µ—Ç–µ–∫—Ü—ñ–π, –±–∞–≥–∞—Ç–æ –ø–æ–º–∏–ª–æ–∫
- 0.5: –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±–∞–ª–∞–Ω—Å ‚úÖ
- 0.7: –ú–∞–ª–æ –ø–æ–º–∏–ª–æ–∫, –∞–ª–µ –ø—Ä–æ–ø—É—Å–∫–∞—î –æ–±'—î–∫—Ç–∏

### 10.3 –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤

| –°—Ü–µ–Ω–∞—Ä—ñ–π | –ú–æ–¥–µ–ª—å | Threshold | –ü—Ä–∏—Å—Ç—Ä—ñ–π |
|----------|--------|-----------|----------|
| **–ë–µ–∑–ø–µ–∫–∞/–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥** | EfficientDet | 0.6 | GPU ‚úÖ |
| **–ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –ª—é–¥–µ–π** | SSD MobileNet | 0.5 | CPU ‚úÖ |
| **–ê–Ω–∞–ª—ñ–∑ —Ç—Ä–∞—Ñ—Ñ—ñ–∫—É** | EfficientDet | 0.5 | GPU ‚úÖ |
| **–†–æ–∑—É–º–Ω–∏–π –¥—ñ–º** | SSD MobileNet | 0.4 | Edge device ‚úÖ |
| **–Ø–∫—ñ—Å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑** | Faster R-CNN | 0.6 | GPU server ‚úÖ |

### 10.4 –ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ —É—Ä–æ–∫–∏

**1. Pretrained –º–æ–¥–µ–ª—ñ - –≤—ñ–¥–º—ñ–Ω–Ω–∏–π —Å—Ç–∞—Ä—Ç**
- –ù–µ —Ç—Ä–µ–±–∞ –Ω–∞–≤—á–∞—Ç–∏ –∑ –Ω—É–ª—è
- COCO dataset (1.5M –∑–æ–±—Ä–∞–∂–µ–Ω—å) –¥–∞—î –º—ñ—Ü–Ω—É –±–∞–∑—É
- Transfer learning –ø—Ä–∞—Ü—é—î –Ω–∞–≤—ñ—Ç—å –º—ñ–∂ —Ä—ñ–∑–Ω–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏

**2. –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–∂–ª–∏–≤—ñ**
- Precision: —Å–∫—ñ–ª—å–∫–∏ –¥–µ—Ç–µ–∫—Ü—ñ–π –ø—Ä–∞–≤–∏–ª—å–Ω—ñ
- Recall: —Å–∫—ñ–ª—å–∫–∏ –æ–±'—î–∫—Ç—ñ–≤ –∑–Ω–∞–π–¥–µ–Ω–æ
- F1: –±–∞–ª–∞–Ω—Å –æ–±–æ—Ö
- IoU: —è–∫—ñ—Å—Ç—å –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó
- mAP: —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

**3. Real-world —Å–∫–ª–∞–¥–Ω—ñ—à–∏–π –∑–∞ –±–µ–Ω—á–º–∞—Ä–∫–∏**
- –û—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è, motion blur, —Ä–∞–∫—É—Ä—Å–∏
- –ü–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –æ–±'—î–∫—Ç–∏
- –û–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è
- –¢—Ä–µ–±–∞ —Ç–µ—Å—Ç—É–≤–∞—Ç–∏ —É —Ä–µ–∞–ª—å–Ω–∏—Ö —É–º–æ–≤–∞—Ö

**4. –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –Ω–µ–æ–±—Ö—ñ–¥–Ω–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω—É**
- Quantization: —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üë 2-4x
- TensorRT: —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üë 2-5x
- Pruning: —Ä–æ–∑–º—ñ—Ä ‚Üì 50%
- –í–∞—Ä—Ç—ñ—Å—Ç—å: —Ç–æ—á–Ω—ñ—Å—Ç—å ‚Üì 1-3%

---

## 11. –ù–∞–ø—Ä—è–º–∫–∏ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ —Ä–æ–∑–≤–∏—Ç–∫—É

### 11.1 –ö–æ—Ä–æ—Ç–∫–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (1-2 —Ç–∏–∂–Ω—ñ)

**1. –î–æ–¥–∞—Ç–∏ –±—ñ–ª—å—à–µ –º–æ–¥–µ–ª–µ–π**
```python
# YOLO v8
from ultralytics import YOLO
model = YOLO('yolov8n.pt')

# DETR (transformer-based)
from transformers import DetrForObjectDetection
model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50')
```

**2. Object Tracking**
```python
# DeepSORT tracking
from deep_sort import DeepSort
tracker = DeepSort(max_age=30)

# –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–∞–¥—Ä—É
detections = detect_objects(frame)
tracks = tracker.update(detections)
# –¢–µ–ø–µ—Ä –∫–æ–∂–µ–Ω –æ–±'—î–∫—Ç –º–∞—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID
```

**3. Metrics Dashboard**
```python
# Real-time dashboard –∑ Plotly
import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(y=fps_history, name='FPS'))
fig.add_trace(go.Bar(y=detections_history, name='Detections'))
```

**4. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ**
```python
# –ó–∞–ø–∏—Å –≤—ñ–¥–µ–æ –∑ –¥–µ—Ç–µ–∫—Ü—ñ—è–º–∏
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output.mp4', fourcc, 30, (width, height))
```

### 11.2 –°–µ—Ä–µ–¥–Ω—å–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (1-2 –º—ñ—Å—è—Ü—ñ)

**1. Fine-tuning –Ω–∞ –≤–ª–∞—Å–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ**
- –°—Ç–≤–æ—Ä–∏—Ç–∏ –≤–ª–∞—Å–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç (labelImg, CVAT)
- Fine-tune EfficientDet –Ω–∞ –Ω—å–æ–º—É
- –û—Ü—ñ–Ω–∏—Ç–∏ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ

**2. Instance Segmentation**
```python
# Mask R-CNN –¥–ª—è segmentation
model = hub.load('mask_rcnn_resnet50')
results = model(image)
# –¢–µ–ø–µ—Ä –æ—Ç—Ä–∏–º—É—î–º–æ masks –∑–∞–º—ñ—Å—Ç—å boxes
```

**3. Multi-camera system**
- –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –∫—ñ–ª—å–∫–æ—Ö –∫–∞–º–µ—Ä –æ–¥–Ω–æ—á–∞—Å–Ω–æ
- –û–±'—î–¥–Ω–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- Tracking –º—ñ–∂ –∫–∞–º–µ—Ä–∞–º–∏

**4. Web deployment**
```python
# FastAPI backend
from fastapi import FastAPI, File, UploadFile
app = FastAPI()

@app.post("/detect")
async def detect_objects(file: UploadFile):
    image = await file.read()
    results = detector(image)
    return {"detections": results}
```

### 11.3 –î–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (3-6 –º—ñ—Å—è—Ü—ñ–≤)

**1. 3D Object Detection**
- Depth estimation + 2D detection
- Stereo cameras
- 3D bounding boxes

**2. Mobile deployment**
```python
# TensorFlow Lite –¥–ª—è Android/iOS
converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
tflite_model = converter.convert()
# Deploy –Ω–∞ –º–æ–±—ñ–ª—å–Ω–∏–π –¥–æ–¥–∞—Ç–æ–∫
```

**3. Edge deployment**
- NVIDIA Jetson Nano/Xavier
- Google Coral TPU
- Raspberry Pi (–∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é)

**4. –í–ª–∞—Å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞**
- –î–æ—Å–ª—ñ–¥–∏—Ç–∏ –Ω–æ–≤—ñ –ø—ñ–¥—Ö–æ–¥–∏
- –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–≤–∞—Ç–∏ –∑ attention mechanisms
- Vision Transformers –¥–ª—è detection

---

## 12. –§—ñ–Ω–∞–ª—å–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

### –ü—Ä–æ—î–∫—Ç —É—Å–ø—ñ—à–Ω–æ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î:

‚úÖ **–¢–µ—Ö–Ω—ñ—á–Ω—É –º–∞–π—Å—Ç–µ—Ä–Ω—ñ—Å—Ç—å:**
- –†–æ–±–æ—Ç–∞ –∑ —Å—É—á–∞—Å–Ω–∏–º–∏ DL —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ (TensorFlow, TensorFlow Hub)
- –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–≤–Ω–æ–≥–æ pipeline –≤—ñ–¥ –º–æ–¥–µ–ª—ñ –¥–æ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
- –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¥–ª—è real-time performance
- –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ

‚úÖ **–ü—Ä–∞–∫—Ç–∏—á–Ω—É –∑–∞—Å—Ç–æ—Å–æ–≤–Ω—ñ—Å—Ç—å:**
- Real-world —Å—Ü–µ–Ω–∞—Ä—ñ—ó (live –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ –∫–∞–º–µ—Ä–∏)
- Production-ready –∫–æ–¥
- –ì–Ω—É—á–∫—ñ—Å—Ç—å —Ç–∞ —Ä–æ–∑—à–∏—Ä—é–≤–∞–Ω—ñ—Å—Ç—å
- –î–µ—Ç–∞–ª—å–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

‚úÖ **–†–æ–∑—É–º—ñ–Ω–Ω—è Computer Vision:**
- Object detection –º–µ—Ç–æ–¥–∏ —Ç–∞ –º–µ—Ç—Ä–∏–∫–∏
- Trade-offs (—à–≤–∏–¥–∫—ñ—Å—Ç—å vs —Ç–æ—á–Ω—ñ—Å—Ç—å)
- –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –º–æ–¥–µ–ª–µ–π (Single-stage, Two-stage, Anchor-free)
- –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –≤–∏–∫–ª–∏–∫–∏ (–æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è, motion, –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è)

### –ü—Ä–∞–∫—Ç–∏—á–Ω–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å:

–ü—Ä–æ—î–∫—Ç –º–æ–∂–µ –±—É—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π —è–∫:
- üìö **–ù–∞–≤—á–∞–ª—å–Ω–∏–π –º–∞—Ç–µ—Ä—ñ–∞–ª** –¥–ª—è –∫—É—Ä—Å—ñ–≤ –∑ CV
- üõ†Ô∏è **–ë–∞–∑–æ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** –¥–ª—è –≤–ª–∞—Å–Ω–∏—Ö –ø—Ä–æ–µ–∫—Ç—ñ–≤
- üîç **–Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ—Ç–æ—Ç–∏–ø—É–≤–∞–Ω–Ω—è** –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —ñ–¥–µ–π
- üìä **–ë–µ–Ω—á–º–∞—Ä–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞** –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

### –ö–ª—é—á–æ–≤–µ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è:

**–°—Ç–≤–æ—Ä–µ–Ω–æ –ø–æ–≤–Ω–æ—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—É —Å–∏—Å—Ç–µ–º—É object detection**, —è–∫–∞:
- –ü—ñ–¥—Ç—Ä–∏–º—É—î –º–Ω–æ–∂–∏–Ω–Ω—ñ –º–æ–¥–µ–ª—ñ (4 —Ä—ñ–∑–Ω—ñ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏)
- –ü—Ä–∞—Ü—é—î –≤ real-time (30-40 FPS –Ω–∞ CPU)
- –ú–∞—î —ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å (—ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–µ –º–µ–Ω—é)
- –î–æ–±—Ä–µ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤–∞–Ω–∞ (README, EXECUTIVE_SUMMARY, –í–ò–°–ù–û–í–ö–ò)
- –ì–æ—Ç–æ–≤–∞ –¥–æ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è (–º–æ–¥—É–ª—å–Ω–∏–π –∫–æ–¥)

---

**–û—Ü—ñ–Ω–∫–∞ –ø—Ä–æ—î–∫—Ç—É:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å:** Advanced (4/5)

**–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ –∑–∞—Å—Ç–æ—Å–æ–≤–Ω—ñ—Å—Ç—å:** –í–∏—Å–æ–∫–∞ (5/5)

**–ù–∞–≤—á–∞–ª—å–Ω–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å:** –í–∏—Å–æ–∫–∞ (5/5)

---

*–ü—Ä–æ—î–∫—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å—É Deep Learning. –î–µ–º–æ–Ω—Å—Ç—Ä—É—î –≥–ª–∏–±–æ–∫–µ —Ä–æ–∑—É–º—ñ–Ω–Ω—è object detection, –≤—ñ–¥ —Ç–µ–æ—Ä—ñ—ó –¥–æ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ—ó —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó.*

**–ê–≤—Ç–æ—Ä:** Student Deep Learning Course  
**–î–∞—Ç–∞:** December 2025  
**–í–µ—Ä—Å—ñ—è:** 1.0

