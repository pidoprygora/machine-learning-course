"""
Feature Visualization - Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¸ Ñ‚Ğ° ÑˆĞ°Ñ€Ñ–Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¾Ñ— Ğ¼ĞµÑ€ĞµĞ¶Ñ–
Ğ›Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ° Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– 05-Texture-Segmentation

Ğ©Ğ¾ Ñ€ĞµĞ°Ğ»Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾:
1. Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¸ (Convolution Filters) - 50%
   - Ğ’Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ
   - ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ², ÑĞºÑ– ÑˆÑƒĞºĞ°ÑÑ‚ÑŒ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ½Ğ° Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ñ€Ñ–Ğ²Ğ½ÑÑ… Ğ¼ĞµÑ€ĞµĞ¶Ñ–
   
2. Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ ÑˆĞ°Ñ€Ñ–Ğ² (Layer Activations) - 50%
   - Ğ’Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ (feature maps) Ğ½Ğ° ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ¼Ñƒ ÑˆĞ°Ñ€Ñ–
   - ĞĞ½Ğ°Ğ»Ñ–Ğ· Ñ‚Ğ¾Ğ³Ğ¾, ÑĞº Ğ¼ĞµÑ€ĞµĞ¶Ğ° "Ğ±Ğ°Ñ‡Ğ¸Ñ‚ÑŒ" Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ½Ğ° Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ°Ñ…
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Tuple, Optional

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2

# ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ
tf.random.set_seed(42)
np.random.seed(42)

sns.set(style="whitegrid", context="notebook")
plt.rcParams["figure.figsize"] = (14, 10)
plt.rcParams["font.size"] = 10

# Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ñ–Ñ—
OUTPUT_DIR = Path("results")
OUTPUT_DIR.mkdir(exist_ok=True)

MODELS_DIR = Path("models")
MODELS_DIR.mkdir(exist_ok=True)


def print_section(title: str) -> None:
    """ĞšÑ€Ğ°ÑĞ¸Ğ²Ğ¸Ğ¹ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº ÑĞµĞºÑ†Ñ–Ñ— Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»Ñ–."""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


# ---------------------------------------------------------------------------
# 1. ĞŸĞ¾Ğ±ÑƒĞ´Ğ¾Ğ²Ğ° Ñ‚Ğ° Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– (U-Net Ğ· 05-Texture-Segmentation)
# ---------------------------------------------------------------------------

IMG_SIZE = (256, 256)


def build_simple_unet(input_shape=(256, 256, 3)) -> keras.Model:
    """
    ĞĞµĞ²ĞµĞ»Ğ¸ĞºĞ° U-Netâ€‘Ğ¿Ğ¾Ğ´Ñ–Ğ±Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ±Ñ–Ğ½Ğ°Ñ€Ğ½Ğ¾Ñ— ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—.
    Ğ¢Ğ°ĞºĞ° ÑĞ°Ğ¼Ğ° Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑĞº Ñƒ 05-Texture-Segmentation.
    """
    inputs = keras.Input(shape=input_shape)

    # Encoder
    x1 = layers.Conv2D(32, 3, padding="same", activation="relu", name="enc_conv1_1")(inputs)
    x1 = layers.Conv2D(32, 3, padding="same", activation="relu", name="enc_conv1_2")(x1)
    p1 = layers.MaxPool2D(2, name="enc_pool1")(x1)

    x2 = layers.Conv2D(64, 3, padding="same", activation="relu", name="enc_conv2_1")(p1)
    x2 = layers.Conv2D(64, 3, padding="same", activation="relu", name="enc_conv2_2")(x2)
    p2 = layers.MaxPool2D(2, name="enc_pool2")(x2)

    x3 = layers.Conv2D(128, 3, padding="same", activation="relu", name="bottleneck_conv1")(p2)
    x3 = layers.Conv2D(128, 3, padding="same", activation="relu", name="bottleneck_conv2")(x3)

    # Decoder
    u2 = layers.UpSampling2D(2, name="dec_upsample1")(x3)
    u2 = layers.Concatenate(name="dec_concat1")([u2, x2])
    x4 = layers.Conv2D(64, 3, padding="same", activation="relu", name="dec_conv1_1")(u2)
    x4 = layers.Conv2D(64, 3, padding="same", activation="relu", name="dec_conv1_2")(x4)

    u1 = layers.UpSampling2D(2, name="dec_upsample2")(x4)
    u1 = layers.Concatenate(name="dec_concat2")([u1, x1])
    x5 = layers.Conv2D(32, 3, padding="same", activation="relu", name="dec_conv2_1")(u1)
    x5 = layers.Conv2D(32, 3, padding="same", activation="relu", name="dec_conv2_2")(x5)

    outputs = layers.Conv2D(1, 1, activation="sigmoid", name="output_conv")(x5)

    model = keras.Model(inputs, outputs, name="simple_unet_object")
    model.compile(
        optimizer=keras.optimizers.Adam(1e-3),
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    return model


def _generate_synthetic_image_and_mask() -> Tuple[np.ndarray, np.ndarray]:
    """Ğ“ĞµĞ½ĞµÑ€ÑƒÑ” Ğ¿Ñ€Ğ¾ÑÑ‚Ğµ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡Ğ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ñ‚Ğ° Ğ¼Ğ°ÑĞºÑƒ."""
    h, w = IMG_SIZE

    background = np.random.uniform(0.0, 0.4, size=(h, w, 1)).astype(np.float32)
    noise = np.random.normal(loc=0.0, scale=0.05, size=(h, w, 1)).astype(np.float32)
    img = background + noise
    img = np.clip(img, 0.0, 1.0)
    img = np.repeat(img, 3, axis=-1)

    mask = np.zeros((h, w, 1), dtype=np.float32)

    shape_type = np.random.choice(["circle", "square"])
    cy = np.random.randint(h // 4, 3 * h // 4)
    cx = np.random.randint(w // 4, 3 * w // 4)
    r = np.random.randint(min(h, w) // 8, min(h, w) // 4)

    yy, xx = np.ogrid[:h, :w]

    if shape_type == "circle":
        dist_sq = (yy - cy) ** 2 + (xx - cx) ** 2
        obj_region = dist_sq <= r ** 2
    else:
        y_min = max(cy - r, 0)
        y_max = min(cy + r, h)
        x_min = max(cx - r, 0)
        x_max = min(cx + r, w)
        obj_region = np.zeros((h, w), dtype=bool)
        obj_region[y_min:y_max, x_min:x_max] = True

    mask[obj_region, 0] = 1.0

    color = np.random.uniform(0.6, 1.0, size=(1, 1, 3)).astype(np.float32)
    img[obj_region] = color

    img += np.random.normal(0.0, 0.03, size=img.shape).astype(np.float32)
    img = np.clip(img, 0.0, 1.0)

    return img.astype(np.float32), mask.astype(np.float32)


def train_model_for_visualization(epochs: int = 5) -> keras.Model:
    """ĞĞ°Ğ²Ñ‡Ğ°Ñ” Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ°Ğ»ÑŒÑˆĞ¾Ñ— Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ—."""
    print_section("ĞĞĞ’Ğ§ĞĞĞĞ¯ ĞœĞĞ”Ğ•Ğ›Ğ† Ğ”Ğ›Ğ¯ Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ‡")
    
    # Ğ“ĞµĞ½ĞµÑ€ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ°Ğ½Ñ–
    num_train = 40
    num_val = 10
    
    train_images = np.zeros((num_train, *IMG_SIZE, 3), dtype=np.float32)
    train_masks = np.zeros((num_train, *IMG_SIZE, 1), dtype=np.float32)
    
    for i in range(num_train):
        train_images[i], train_masks[i] = _generate_synthetic_image_and_mask()
    
    val_images = np.zeros((num_val, *IMG_SIZE, 3), dtype=np.float32)
    val_masks = np.zeros((num_val, *IMG_SIZE, 1), dtype=np.float32)
    
    for i in range(num_val):
        val_images[i], val_masks[i] = _generate_synthetic_image_and_mask()
    
    print(f"  Ğ—Ğ³ĞµĞ½ĞµÑ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ train: {num_train}, val: {num_val}")
    
    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ñ‚Ğ° Ğ½Ğ°Ğ²Ñ‡Ğ°Ñ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    model = build_simple_unet()
    model.summary()
    
    print("\n  ĞĞ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–...")
    history = model.fit(
        train_images, train_masks,
        validation_data=(val_images, val_masks),
        epochs=epochs,
        batch_size=4,
        verbose=1
    )
    
    # Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    model_path = MODELS_DIR / "unet_for_visualization.h5"
    model.save(model_path)
    print(f"\nâœ“ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ°: {model_path}")
    
    return model


# ---------------------------------------------------------------------------
# 2. Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ Ğ—Ğ“ĞĞ Ğ¢ĞšĞ˜ (50%)
# ---------------------------------------------------------------------------

def get_conv_layers(model: keras.Model) -> List[Tuple[str, layers.Conv2D]]:
    """ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–."""
    conv_layers = []
    for layer in model.layers:
        if isinstance(layer, layers.Conv2D):
            conv_layers.append((layer.name, layer))
    return conv_layers


def visualize_filters(model: keras.Model, max_filters: int = 64) -> None:
    """
    Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ” Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ (Ğ²Ğ°Ğ³Ğ¸) Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ².
    
    Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑÑ‚ÑŒ, ÑĞºÑ– Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ğ¸ ÑˆÑƒĞºĞ°Ñ” ĞºĞ¾Ğ¶ĞµĞ½ ÑˆĞ°Ñ€:
    - ĞŸĞµÑ€ÑˆÑ– ÑˆĞ°Ñ€Ğ¸: Ğ¿Ñ€Ğ¾ÑÑ‚Ñ– ĞºÑ€Ğ°Ñ—, Ğ³Ñ€Ğ°Ğ´Ñ–Ñ”Ğ½Ñ‚Ğ¸, ĞºĞ¾Ğ»ÑŒĞ¾Ñ€Ğ¸
    - Ğ“Ğ»Ğ¸Ğ±ÑˆÑ– ÑˆĞ°Ñ€Ğ¸: ÑĞºĞ»Ğ°Ğ´Ğ½Ñ–ÑˆÑ– Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ¸ Ñ‚Ğ° Ñ„Ğ¾Ñ€Ğ¼Ğ¸
    """
    print_section("Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ Ğ—Ğ“ĞĞ Ğ¢ĞšĞ˜")
    
    conv_layers = get_conv_layers(model)
    print(f"\n  Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(conv_layers)} Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ²:")
    
    for name, layer in conv_layers:
        weights = layer.get_weights()
        if len(weights) > 0:
            filters = weights[0]
            print(f"    {name}: Ñ„Ğ¾Ñ€Ğ¼Ğ° Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² {filters.shape}")
    
    # Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ
    for layer_name, layer in conv_layers:
        weights = layer.get_weights()
        if len(weights) == 0:
            continue
            
        filters = weights[0]  # Ğ’Ğ°Ğ³Ğ¸ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²: (height, width, in_channels, out_channels)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ´Ğ»Ñ Ğ²Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
        f_min, f_max = filters.min(), filters.max()
        filters_normalized = (filters - f_min) / (f_max - f_min + 1e-8)
        
        n_filters = min(filters.shape[-1], max_filters)
        n_cols = 8
        n_rows = (n_filters + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 2 * n_rows))
        fig.suptitle(f"Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ ÑˆĞ°Ñ€Ñƒ: {layer_name}\n"
                     f"Ğ¤Ğ¾Ñ€Ğ¼Ğ°: {filters.shape} (HÃ—WÃ—InÃ—Out)", 
                     fontsize=14, fontweight='bold')
        
        # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° axes Ğ´Ğ»Ñ Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ²Ğ¸Ğ¿Ğ°Ğ´ĞºÑ–Ğ²
        if isinstance(axes, np.ndarray):
            axes = axes.flatten()
        else:
            axes = [axes]
        
        for i in range(n_filters):
            ax = axes[i]
            
            # Ğ”Ğ»Ñ ĞºĞ¾Ğ»ÑŒĞ¾Ñ€Ğ¾Ğ²Ğ¸Ñ… Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² (3 Ğ²Ñ…Ñ–Ğ´Ğ½Ğ¸Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ¸) Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ ÑĞº RGB
            if filters.shape[2] == 3:
                f = filters_normalized[:, :, :, i]
                ax.imshow(f)
            else:
                # Ğ”Ğ»Ñ Ñ–Ğ½ÑˆĞ¸Ñ… - Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ ÑĞµÑ€ĞµĞ´Ğ½Ñ” Ğ¿Ğ¾ Ğ²Ñ…Ñ–Ğ´Ğ½Ğ¸Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ°Ñ…
                f = filters_normalized[:, :, :, i].mean(axis=2)
                ax.imshow(f, cmap='viridis')
            
            ax.set_title(f"F{i}", fontsize=8)
            ax.axis('off')
        
        # ĞŸÑ€Ğ¸Ñ…Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ Ğ¿ÑƒÑÑ‚Ñ– subplot'Ğ¸
        for i in range(n_filters, len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        out_path = OUTPUT_DIR / f"filters_{layer_name}.png"
        plt.savefig(out_path, dpi=150, bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾: {out_path}")


def visualize_filters_comparison(model: keras.Model) -> None:
    """
    ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ² Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ³Ñ€Ğ°Ñ„Ñ–ĞºÑƒ.
    ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ” ĞµĞ²Ğ¾Ğ»ÑÑ†Ñ–Ñ ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¾ÑÑ‚Ñ– Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ² Ğ²Ñ–Ğ´ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ… Ğ´Ğ¾ ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ñ….
    """
    print_section("ĞŸĞĞ Ğ†Ğ’ĞĞ¯ĞĞĞ¯ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ ĞĞ Ğ Ğ†Ğ—ĞĞ˜Ğ¥ Ğ“Ğ›Ğ˜Ğ‘Ğ˜ĞĞĞ¥")
    
    conv_layers = get_conv_layers(model)
    
    # Ğ’Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ Ñ€ĞµĞ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ– ÑˆĞ°Ñ€Ğ¸
    selected_layers = conv_layers[:min(6, len(conv_layers))]
    
    fig, axes = plt.subplots(len(selected_layers), 8, figsize=(18, 3 * len(selected_layers)))
    fig.suptitle("Ğ•Ğ²Ğ¾Ğ»ÑÑ†Ñ–Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²: Ğ²Ñ–Ğ´ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ… Ğ´Ğ¾ ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ñ… Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ²\n"
                 "(Ğ¿ĞµÑ€ÑˆÑ– 8 Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ)", fontsize=14, fontweight='bold')
    
    for row_idx, (layer_name, layer) in enumerate(selected_layers):
        weights = layer.get_weights()
        if len(weights) == 0:
            continue
            
        filters = weights[0]
        f_min, f_max = filters.min(), filters.max()
        filters_normalized = (filters - f_min) / (f_max - f_min + 1e-8)
        
        n_show = min(8, filters.shape[-1])
        
        for col_idx in range(8):
            ax = axes[row_idx, col_idx] if len(selected_layers) > 1 else axes[col_idx]
            
            if col_idx < n_show:
                if filters.shape[2] == 3:
                    f = filters_normalized[:, :, :, col_idx]
                    ax.imshow(f)
                else:
                    f = filters_normalized[:, :, :, col_idx].mean(axis=2)
                    ax.imshow(f, cmap='viridis')
            
            ax.axis('off')
            
            if col_idx == 0:
                ax.set_ylabel(f"{layer_name}\n({filters.shape[-1]} Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²)", 
                            fontsize=9, rotation=0, ha='right', va='center')
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    out_path = OUTPUT_DIR / "filters_comparison.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾: {out_path}")


def visualize_filter_statistics(model: keras.Model) -> None:
    """
    Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²: Ñ€Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ²Ğ°Ğ³, Ğ½Ğ¾Ñ€Ğ¼Ğ¸ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ².
    """
    print_section("Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ Ğ—Ğ“ĞĞ Ğ¢ĞšĞ˜")
    
    conv_layers = get_conv_layers(model)
    
    layer_names = []
    weight_means = []
    weight_stds = []
    filter_norms = []
    
    for layer_name, layer in conv_layers:
        weights = layer.get_weights()
        if len(weights) == 0:
            continue
            
        filters = weights[0]
        
        layer_names.append(layer_name)
        weight_means.append(filters.mean())
        weight_stds.append(filters.std())
        
        # ĞĞ¾Ñ€Ğ¼Ğ° Ğ¤Ñ€Ğ¾Ğ±ĞµĞ½Ñ–ÑƒÑĞ° Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ°
        norms = []
        for i in range(filters.shape[-1]):
            norm = np.linalg.norm(filters[:, :, :, i])
            norms.append(norm)
        filter_norms.append(np.mean(norms))
    
    # Ğ“Ñ€Ğ°Ñ„Ñ–ĞºĞ¸
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¸", fontsize=14, fontweight='bold')
    
    # 1. Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ” Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³
    axes[0, 0].bar(range(len(layer_names)), weight_means, color='steelblue', alpha=0.8)
    axes[0, 0].set_xticks(range(len(layer_names)))
    axes[0, 0].set_xticklabels(layer_names, rotation=45, ha='right', fontsize=8)
    axes[0, 0].set_ylabel("Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ” Ğ²Ğ°Ğ³")
    axes[0, 0].set_title("Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ” Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³ Ğ¿Ğ¾ ÑˆĞ°Ñ€Ğ°Ñ…")
    axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)
    axes[0, 0].grid(alpha=0.3)
    
    # 2. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğµ Ğ²Ñ–Ğ´Ñ…Ğ¸Ğ»ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³
    axes[0, 1].bar(range(len(layer_names)), weight_stds, color='orange', alpha=0.8)
    axes[0, 1].set_xticks(range(len(layer_names)))
    axes[0, 1].set_xticklabels(layer_names, rotation=45, ha='right', fontsize=8)
    axes[0, 1].set_ylabel("Std Ğ²Ğ°Ğ³")
    axes[0, 1].set_title("Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğµ Ğ²Ñ–Ğ´Ñ…Ğ¸Ğ»ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³")
    axes[0, 1].grid(alpha=0.3)
    
    # 3. Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ° Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²
    axes[1, 0].bar(range(len(layer_names)), filter_norms, color='green', alpha=0.8)
    axes[1, 0].set_xticks(range(len(layer_names)))
    axes[1, 0].set_xticklabels(layer_names, rotation=45, ha='right', fontsize=8)
    axes[1, 0].set_ylabel("ĞĞ¾Ñ€Ğ¼Ğ° Ğ¤Ñ€Ğ¾Ğ±ĞµĞ½Ñ–ÑƒÑĞ°")
    axes[1, 0].set_title("Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ° Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²")
    axes[1, 0].grid(alpha=0.3)
    
    # 4. Ğ“Ñ–ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ° Ğ²Ğ°Ğ³ Ğ²ÑÑ–Ñ… Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²
    all_weights = []
    for layer_name, layer in conv_layers:
        weights = layer.get_weights()
        if len(weights) > 0:
            all_weights.extend(weights[0].flatten())
    
    axes[1, 1].hist(all_weights, bins=100, color='purple', alpha=0.7, edgecolor='black')
    axes[1, 1].set_xlabel("Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³Ğ¸")
    axes[1, 1].set_ylabel("Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ°")
    axes[1, 1].set_title("Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ²ÑÑ–Ñ… Ğ²Ğ°Ğ³ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ²")
    axes[1, 1].axvline(x=0, color='red', linestyle='--', alpha=0.7, label='ĞÑƒĞ»ÑŒ')
    axes[1, 1].legend()
    axes[1, 1].grid(alpha=0.3)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    out_path = OUTPUT_DIR / "filter_statistics.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ°: {out_path}")


# ---------------------------------------------------------------------------
# 3. Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¨ĞĞ Ğ†Ğ’ / ĞĞšĞ¢Ğ˜Ğ’ĞĞ¦Ğ†Ğ™ (50%)
# ---------------------------------------------------------------------------

def create_activation_model(model: keras.Model) -> keras.Model:
    """
    Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ Ğ²ÑÑ–Ñ… Ğ¿Ñ€Ğ¾Ğ¼Ñ–Ğ¶Ğ½Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ².
    """
    layer_outputs = [layer.output for layer in model.layers if 'input' not in layer.name.lower()]
    layer_names = [layer.name for layer in model.layers if 'input' not in layer.name.lower()]
    
    activation_model = Model(inputs=model.input, outputs=layer_outputs)
    return activation_model, layer_names


def get_sample_image() -> np.ndarray:
    """ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ” Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ»Ñ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ— Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹."""
    img, _ = _generate_synthetic_image_and_mask()
    return img


def visualize_layer_activations(model: keras.Model, image: Optional[np.ndarray] = None) -> None:
    """
    Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ” Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— (feature maps) Ğ½Ğ° ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ¼Ñƒ ÑˆĞ°Ñ€Ñ– Ğ¼ĞµÑ€ĞµĞ¶Ñ–.
    
    ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”, ÑĞº Ğ¼ĞµÑ€ĞµĞ¶Ğ° "Ğ±Ğ°Ñ‡Ğ¸Ñ‚ÑŒ" Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ½Ğ° Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ°Ñ…:
    - ĞŸĞµÑ€ÑˆÑ– ÑˆĞ°Ñ€Ğ¸: Ğ½Ğ¸Ğ·ÑŒĞºĞ¾Ñ€Ñ–Ğ²Ğ½ĞµĞ²Ñ– Ğ¾Ğ·Ğ½Ğ°ĞºĞ¸ (ĞºÑ€Ğ°Ñ—, ĞºĞ¾Ğ»ÑŒĞ¾Ñ€Ğ¸)
    - Ğ“Ğ»Ğ¸Ğ±ÑˆÑ– ÑˆĞ°Ñ€Ğ¸: Ğ²Ğ¸ÑĞ¾ĞºĞ¾Ñ€Ñ–Ğ²Ğ½ĞµĞ²Ñ– Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ñ–Ñ—
    """
    print_section("Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ ĞĞšĞ¢Ğ˜Ğ’ĞĞ¦Ğ†Ğ™ Ğ¨ĞĞ Ğ†Ğ’")
    
    if image is None:
        image = get_sample_image()
    
    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹
    activation_model, layer_names = create_activation_model(model)
    
    # ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ—
    input_image = np.expand_dims(image, axis=0)
    activations = activation_model.predict(input_image, verbose=0)
    
    print(f"\n  ĞĞ½Ğ°Ğ»Ñ–Ğ· {len(activations)} ÑˆĞ°Ñ€Ñ–Ğ²:")
    
    # Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ”Ğ¼Ğ¾ Ğ²Ñ…Ñ–Ğ´Ğ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    fig_input, ax_input = plt.subplots(1, 1, figsize=(8, 8))
    ax_input.imshow(image)
    ax_input.set_title("Ğ’Ñ…Ñ–Ğ´Ğ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ", fontsize=14, fontweight='bold')
    ax_input.axis('off')
    plt.tight_layout()
    out_path = OUTPUT_DIR / "input_image_for_activations.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig_input)
    print(f"  âœ“ Ğ’Ñ…Ñ–Ğ´Ğ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ: {out_path}")
    
    # Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ
    for idx, (activation, layer_name) in enumerate(zip(activations, layer_names)):
        if len(activation.shape) != 4:  # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾ Ğ½Ğµ 4D Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¸
            continue
            
        n_features = activation.shape[-1]
        
        # ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 64 feature maps
        n_show = min(64, n_features)
        n_cols = 8
        n_rows = (n_show + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 2 * n_rows))
        fig.suptitle(f"ĞĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— ÑˆĞ°Ñ€Ñƒ: {layer_name}\n"
                     f"Ğ¤Ğ¾Ñ€Ğ¼Ğ° Ğ²Ğ¸Ñ…Ğ¾Ğ´Ñƒ: {activation.shape[1:]} (HÃ—WÃ—Channels)", 
                     fontsize=12, fontweight='bold')
        
        # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° axes Ğ´Ğ»Ñ Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ²Ğ¸Ğ¿Ğ°Ğ´ĞºÑ–Ğ²
        if isinstance(axes, np.ndarray):
            axes = axes.flatten()
        else:
            axes = [axes]
        
        for i in range(n_show):
            ax = axes[i]
            feature_map = activation[0, :, :, i]
            
            # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ»Ñ Ğ²Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
            if feature_map.max() != feature_map.min():
                feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())
            
            ax.imshow(feature_map, cmap='viridis')
            ax.set_title(f"Ch{i}", fontsize=7)
            ax.axis('off')
        
        for i in range(n_show, len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        out_path = OUTPUT_DIR / f"activations_{idx:02d}_{layer_name}.png"
        plt.savefig(out_path, dpi=150, bbox_inches='tight')
        plt.close(fig)
        
        print(f"    {layer_name}: {activation.shape[1:]} -> {out_path.name}")


def visualize_activation_heatmaps(model: keras.Model, image: Optional[np.ndarray] = None) -> None:
    """
    Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” Ñ‚ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸ ÑĞµÑ€ĞµĞ´Ğ½ÑŒĞ¾Ñ— Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— Ğ¿Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ°Ñ… Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ.
    ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”, ÑĞºÑ– Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ñ– Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ½Ğ°Ğ¹Ğ±Ñ–Ğ»ÑŒÑˆĞµ Ğ°ĞºÑ‚Ğ¸Ğ²ÑƒÑÑ‚ÑŒ ĞºĞ¾Ğ¶ĞµĞ½ ÑˆĞ°Ñ€.
    """
    print_section("Ğ¢Ğ•ĞŸĞ›ĞĞ’Ğ† ĞšĞĞ Ğ¢Ğ˜ ĞĞšĞ¢Ğ˜Ğ’ĞĞ¦Ğ†Ğ™")
    
    if image is None:
        image = get_sample_image()
    
    activation_model, layer_names = create_activation_model(model)
    input_image = np.expand_dims(image, axis=0)
    activations = activation_model.predict(input_image, verbose=0)
    
    # Ğ’Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ñ– ÑˆĞ°Ñ€Ğ¸
    conv_activations = []
    conv_names = []
    
    for activation, name in zip(activations, layer_names):
        if len(activation.shape) == 4 and 'conv' in name.lower():
            conv_activations.append(activation)
            conv_names.append(name)
    
    n_layers = len(conv_activations)
    if n_layers == 0:
        print("  ĞĞµĞ¼Ğ°Ñ” Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ² Ğ´Ğ»Ñ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ—")
        return
    
    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ ÑÑ–Ñ‚ĞºÑƒ
    n_cols = 4
    n_rows = (n_layers + 1 + n_cols - 1) // n_cols  # +1 Ğ´Ğ»Ñ Ğ¾Ñ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))
    fig.suptitle("Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸: ÑĞµÑ€ĞµĞ´Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ Ğ¿Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ°Ñ…\n"
                 "(ÑÑĞºÑ€Ğ°Ğ²Ñ–ÑˆÑ– Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ñ– = ÑĞ¸Ğ»ÑŒĞ½Ñ–ÑˆĞ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ)", fontsize=14, fontweight='bold')
    
    # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° axes
    if isinstance(axes, np.ndarray):
        axes = axes.flatten()
    else:
        axes = [axes]
    
    # ĞÑ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    axes[0].imshow(image)
    axes[0].set_title("ĞÑ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»", fontsize=10, fontweight='bold')
    axes[0].axis('off')
    
    # Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸ Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ
    for idx, (activation, name) in enumerate(zip(conv_activations, conv_names)):
        ax = axes[idx + 1]
        
        # Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ Ğ¿Ğ¾ Ğ²ÑÑ–Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ°Ñ…
        heatmap = activation[0].mean(axis=-1)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ
        if heatmap.max() != heatmap.min():
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
        
        # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ¾ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€Ñƒ Ğ¾Ñ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
        import cv2
        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
        
        # ĞĞ°ĞºĞ»Ğ°Ğ´Ğ°Ñ”Ğ¼Ğ¾ Ğ½Ğ° Ğ¾Ñ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
        ax.imshow(image, alpha=0.6)
        im = ax.imshow(heatmap_resized, cmap='jet', alpha=0.5)
        ax.set_title(f"{name}\n{activation.shape[1:3]}", fontsize=9)
        ax.axis('off')
    
    # ĞŸÑ€Ğ¸Ñ…Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ Ğ·Ğ°Ğ¹Ğ²Ñ– axes
    for i in range(len(conv_activations) + 1, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    out_path = OUTPUT_DIR / "activation_heatmaps.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ñ–: {out_path}")


def visualize_activation_statistics(model: keras.Model, image: Optional[np.ndarray] = None) -> None:
    """
    Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹: Ñ€Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ğ½Ğ°Ñ‡ĞµĞ½ÑŒ, ÑĞ¿Ğ°Ñ€ÑĞ½Ñ–ÑÑ‚ÑŒ.
    """
    print_section("Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ ĞĞšĞ¢Ğ˜Ğ’ĞĞ¦Ğ†Ğ™ Ğ¨ĞĞ Ğ†Ğ’")
    
    if image is None:
        image = get_sample_image()
    
    activation_model, layer_names = create_activation_model(model)
    input_image = np.expand_dims(image, axis=0)
    activations = activation_model.predict(input_image, verbose=0)
    
    # Ğ—Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
    layer_stats = []
    
    for activation, name in zip(activations, layer_names):
        if len(activation.shape) == 4:
            stats = {
                'name': name,
                'shape': str(activation.shape[1:]),
                'mean': activation.mean(),
                'std': activation.std(),
                'min': activation.min(),
                'max': activation.max(),
                'sparsity': (activation == 0).sum() / activation.size * 100,  # % Ğ½ÑƒĞ»Ñ–Ğ²
                'dead_channels': (activation.mean(axis=(0, 1, 2)) == 0).sum()
            }
            layer_stats.append(stats)
    
    # Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ ÑˆĞ°Ñ€Ñ–Ğ²", fontsize=14, fontweight='bold')
    
    names = [s['name'] for s in layer_stats]
    means = [s['mean'] for s in layer_stats]
    stds = [s['std'] for s in layer_stats]
    sparsities = [s['sparsity'] for s in layer_stats]
    maxs = [s['max'] for s in layer_stats]
    
    x = range(len(names))
    
    # 1. Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ” Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹
    axes[0, 0].bar(x, means, color='steelblue', alpha=0.8)
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(names, rotation=45, ha='right', fontsize=7)
    axes[0, 0].set_ylabel("Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ”")
    axes[0, 0].set_title("Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ” Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹")
    axes[0, 0].grid(alpha=0.3)
    
    # 2. ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ
    axes[0, 1].bar(x, maxs, color='orange', alpha=0.8)
    axes[0, 1].set_xticks(x)
    axes[0, 1].set_xticklabels(names, rotation=45, ha='right', fontsize=7)
    axes[0, 1].set_ylabel("ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼")
    axes[0, 1].set_title("ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹")
    axes[0, 1].grid(alpha=0.3)
    
    # 3. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğµ Ğ²Ñ–Ğ´Ñ…Ğ¸Ğ»ĞµĞ½Ğ½Ñ
    axes[1, 0].bar(x, stds, color='green', alpha=0.8)
    axes[1, 0].set_xticks(x)
    axes[1, 0].set_xticklabels(names, rotation=45, ha='right', fontsize=7)
    axes[1, 0].set_ylabel("Std")
    axes[1, 0].set_title("Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğµ Ğ²Ñ–Ğ´Ñ…Ğ¸Ğ»ĞµĞ½Ğ½Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹")
    axes[1, 0].grid(alpha=0.3)
    
    # 4. Ğ¡Ğ¿Ğ°Ñ€ÑĞ½Ñ–ÑÑ‚ÑŒ (% Ğ½ÑƒĞ»ÑŒĞ¾Ğ²Ğ¸Ñ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹)
    axes[1, 1].bar(x, sparsities, color='red', alpha=0.8)
    axes[1, 1].set_xticks(x)
    axes[1, 1].set_xticklabels(names, rotation=45, ha='right', fontsize=7)
    axes[1, 1].set_ylabel("% Ğ½ÑƒĞ»ÑŒĞ¾Ğ²Ğ¸Ñ…")
    axes[1, 1].set_title("Ğ¡Ğ¿Ğ°Ñ€ÑĞ½Ñ–ÑÑ‚ÑŒ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ (ReLU ĞµÑ„ĞµĞºÑ‚)")
    axes[1, 1].grid(alpha=0.3)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    out_path = OUTPUT_DIR / "activation_statistics.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ°: {out_path}")
    
    # Ğ’Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ
    print("\nğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ° ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ ÑˆĞ°Ñ€Ğ°Ñ…:")
    print("-" * 90)
    print(f"{'Ğ¨Ğ°Ñ€':<25} {'Ğ¤Ğ¾Ñ€Ğ¼Ğ°':<18} {'Mean':>8} {'Std':>8} {'Max':>8} {'Sparsity':>10}")
    print("-" * 90)
    for s in layer_stats:
        print(f"{s['name']:<25} {s['shape']:<18} {s['mean']:>8.4f} {s['std']:>8.4f} "
              f"{s['max']:>8.4f} {s['sparsity']:>9.2f}%")


def visualize_layer_progression(model: keras.Model, image: Optional[np.ndarray] = None) -> None:
    """
    ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ” Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ–Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ²ÑÑ– ÑˆĞ°Ñ€Ğ¸ Ğ¼ĞµÑ€ĞµĞ¶Ñ–.
    """
    print_section("ĞŸĞ ĞĞ“Ğ Ğ•Ğ¡Ğ†Ğ¯ ĞĞ‘Ğ ĞĞ‘ĞšĞ˜ Ğ§Ğ•Ğ Ğ•Ğ— Ğ¨ĞĞ Ğ˜")
    
    if image is None:
        image = get_sample_image()
    
    activation_model, layer_names = create_activation_model(model)
    input_image = np.expand_dims(image, axis=0)
    activations = activation_model.predict(input_image, verbose=0)
    
    # Ğ’Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ»ÑÑ‡Ğ¾Ğ²Ñ– ÑˆĞ°Ñ€Ğ¸ Ğ´Ğ»Ñ Ğ²Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    key_activations = []
    key_names = []
    
    for activation, name in zip(activations, layer_names):
        if len(activation.shape) == 4:
            key_activations.append(activation)
            key_names.append(name)
    
    # ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ¾ 12 ÑˆĞ°Ñ€Ñ–Ğ²
    n_show = min(12, len(key_activations))
    step = max(1, len(key_activations) // n_show)
    
    selected_idx = list(range(0, len(key_activations), step))[:n_show]
    
    n_cols = 4
    n_rows = (len(selected_idx) + 1 + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))
    fig.suptitle("ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ–Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸: Ğ²Ñ–Ğ´ Ğ²Ñ…Ñ–Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ¾ Ğ²Ğ¸Ñ…Ğ¾Ğ´Ñƒ\n"
                 "(Ğ¿ĞµÑ€ÑˆĞ¸Ğ¹ feature map ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ)", fontsize=14, fontweight='bold')
    
    # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ° Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° axes
    if isinstance(axes, np.ndarray):
        axes = axes.flatten()
    else:
        axes = [axes]
    
    # Ğ’Ñ…Ñ–Ğ´Ğ½Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    axes[0].imshow(image)
    axes[0].set_title("Ğ’Ñ…Ñ–Ğ´\n256Ã—256Ã—3", fontsize=10, fontweight='bold')
    axes[0].axis('off')
    
    # ĞĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ—
    for plot_idx, act_idx in enumerate(selected_idx):
        ax = axes[plot_idx + 1]
        activation = key_activations[act_idx]
        name = key_names[act_idx]
        
        # ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ¿ĞµÑ€ÑˆĞ¸Ğ¹ feature map
        feature_map = activation[0, :, :, 0]
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ
        if feature_map.max() != feature_map.min():
            feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())
        
        ax.imshow(feature_map, cmap='viridis')
        ax.set_title(f"{name}\n{activation.shape[1:-1]}", fontsize=9)
        ax.axis('off')
    
    for i in range(len(selected_idx) + 1, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    out_path = OUTPUT_DIR / "layer_progression.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ–Ñ Ñ‡ĞµÑ€ĞµĞ· ÑˆĞ°Ñ€Ğ¸ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ°: {out_path}")


# ---------------------------------------------------------------------------
# 4. Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ PRE-TRAINED ĞœĞĞ”Ğ•Ğ›Ğ† (VGG16)
# ---------------------------------------------------------------------------

def visualize_pretrained_filters(max_filters: int = 64) -> None:
    """
    Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ” Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ¿Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½ÑŒĞ¾ Ğ½Ğ°Ğ²Ñ‡ĞµĞ½Ğ¾Ñ— Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– VGG16.
    ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”, ÑĞºĞ¸Ñ… Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ² Ğ½Ğ°Ğ²Ñ‡Ğ¸Ğ»Ğ°ÑÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° ImageNet.
    """
    print_section("Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ˜ PRE-TRAINED ĞœĞĞ”Ğ•Ğ›Ğ† (VGG16)")
    
    print("  Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ VGG16...")
    vgg = VGG16(weights='imagenet', include_top=False)
    
    # ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ñ– ÑˆĞ°Ñ€Ğ¸
    conv_layers = [(layer.name, layer) for layer in vgg.layers 
                   if isinstance(layer, layers.Conv2D)]
    
    print(f"  Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(conv_layers)} Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ²")
    
    # Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ¿ĞµÑ€ÑˆÑ– Ñ‚Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ½Ñ– ÑˆĞ°Ñ€Ğ¸
    layers_to_show = [conv_layers[0], conv_layers[len(conv_layers)//2], conv_layers[-1]]
    
    for layer_name, layer in layers_to_show:
        weights = layer.get_weights()
        if len(weights) == 0:
            continue
            
        filters = weights[0]
        f_min, f_max = filters.min(), filters.max()
        filters_normalized = (filters - f_min) / (f_max - f_min + 1e-8)
        
        n_filters = min(filters.shape[-1], max_filters)
        n_cols = 8
        n_rows = (n_filters + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 2 * n_rows))
        fig.suptitle(f"VGG16: Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ ÑˆĞ°Ñ€Ñƒ {layer_name}\n"
                     f"Ğ¤Ğ¾Ñ€Ğ¼Ğ°: {filters.shape}", fontsize=14, fontweight='bold')
        
        axes = axes.flatten()
        
        for i in range(n_filters):
            ax = axes[i]
            
            if filters.shape[2] == 3:
                f = filters_normalized[:, :, :, i]
                ax.imshow(f)
            else:
                f = filters_normalized[:, :, :, i].mean(axis=2)
                ax.imshow(f, cmap='viridis')
            
            ax.axis('off')
        
        for i in range(n_filters, len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        out_path = OUTPUT_DIR / f"vgg16_filters_{layer_name}.png"
        plt.savefig(out_path, dpi=150, bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾: {out_path}")


def visualize_pretrained_activations(image: Optional[np.ndarray] = None) -> None:
    """
    Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·ÑƒÑ” Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— VGG16 Ğ½Ğ° Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´Ñ– Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ.
    """
    print_section("ĞĞšĞ¢Ğ˜Ğ’ĞĞ¦Ğ†Ğ‡ PRE-TRAINED ĞœĞĞ”Ğ•Ğ›Ğ† (VGG16)")
    
    if image is None:
        image = get_sample_image()
    
    # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±ÑƒÑ”Ğ¼Ğ¾ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ¾ 224x224 (Ğ²Ñ…Ñ–Ğ´ VGG16)
    import cv2
    image_resized = cv2.resize(image, (224, 224))
    
    print("  Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ VGG16...")
    vgg = VGG16(weights='imagenet', include_top=False)
    
    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹
    layer_outputs = [layer.output for layer in vgg.layers if 'conv' in layer.name]
    layer_names = [layer.name for layer in vgg.layers if 'conv' in layer.name]
    
    activation_model = Model(inputs=vgg.input, outputs=layer_outputs)
    
    # ĞŸÑ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑĞ¸Ğ½Ğ³ Ğ´Ğ»Ñ VGG
    from tensorflow.keras.applications.vgg16 import preprocess_input
    input_image = np.expand_dims(image_resized * 255, axis=0)
    input_image = preprocess_input(input_image)
    
    activations = activation_model.predict(input_image, verbose=0)
    
    # Ğ’Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ»ÑÑ‡Ğ¾Ğ²Ñ– ÑˆĞ°Ñ€Ğ¸
    key_indices = [0, len(activations)//3, 2*len(activations)//3, len(activations)-1]
    
    fig, axes = plt.subplots(2, 4, figsize=(18, 8))
    fig.suptitle("VGG16: ĞĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— Ğ½Ğ° Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ°Ñ… Ğ¼ĞµÑ€ĞµĞ¶Ñ–\n"
                 "(ImageNet pre-trained)", fontsize=14, fontweight='bold')
    
    # ĞŸĞµÑ€ÑˆĞ¸Ğ¹ Ñ€ÑĞ´ - Ğ¾Ñ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ» Ñ‚Ğ° Ñ‚ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸
    axes[0, 0].imshow(image_resized)
    axes[0, 0].set_title("Ğ’Ñ…Ñ–Ğ´ (224Ã—224)", fontsize=10)
    axes[0, 0].axis('off')
    
    for i, idx in enumerate(key_indices[:-1]):
        activation = activations[idx]
        heatmap = activation[0].mean(axis=-1)
        
        if heatmap.max() != heatmap.min():
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
        
        heatmap_resized = cv2.resize(heatmap, (224, 224))
        
        axes[0, i+1].imshow(image_resized, alpha=0.6)
        axes[0, i+1].imshow(heatmap_resized, cmap='jet', alpha=0.5)
        axes[0, i+1].set_title(f"{layer_names[idx]}\n{activation.shape[1:3]}", fontsize=9)
        axes[0, i+1].axis('off')
    
    # Ğ”Ñ€ÑƒĞ³Ğ¸Ğ¹ Ñ€ÑĞ´ - Ğ¾ĞºÑ€ĞµĞ¼Ñ– feature maps
    for i, idx in enumerate(key_indices):
        activation = activations[idx]
        # ĞŸĞ¾ĞºĞ°Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ·Ğ°Ñ—ĞºÑƒ Ğ· Ğ¿ĞµÑ€ÑˆĞ¸Ñ… 9 feature maps
        n_show = min(9, activation.shape[-1])
        
        # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ·Ğ°Ñ—ĞºÑƒ 3x3
        grid_size = 3
        mosaic = np.zeros((activation.shape[1] * grid_size, activation.shape[2] * grid_size))
        
        for j in range(n_show):
            row = j // grid_size
            col = j % grid_size
            fm = activation[0, :, :, j]
            if fm.max() != fm.min():
                fm = (fm - fm.min()) / (fm.max() - fm.min())
            mosaic[row*activation.shape[1]:(row+1)*activation.shape[1],
                   col*activation.shape[2]:(col+1)*activation.shape[2]] = fm
        
        axes[1, i].imshow(mosaic, cmap='viridis')
        axes[1, i].set_title(f"{layer_names[idx]}\n{activation.shape[-1]} ĞºĞ°Ğ½Ğ°Ğ»Ñ–Ğ²", fontsize=9)
        axes[1, i].axis('off')
    
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    out_path = OUTPUT_DIR / "vgg16_activations.png"
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"\nâœ“ ĞĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ñ— VGG16 Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ñ–: {out_path}")


# ---------------------------------------------------------------------------
# 5. Ğ“ĞĞ›ĞĞ’ĞĞ• ĞœĞ•ĞĞ®
# ---------------------------------------------------------------------------

def create_summary_report(model: keras.Model) -> None:
    """Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” Ğ¿Ñ–Ğ´ÑÑƒĞ¼ĞºĞ¾Ğ²Ğ¸Ğ¹ Ğ·Ğ²Ñ–Ñ‚ Ğ¿Ñ€Ğ¾ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ."""
    print_section("ĞŸĞ†Ğ”Ğ¡Ğ£ĞœĞšĞĞ’Ğ˜Ğ™ Ğ—Ğ’Ğ†Ğ¢")
    
    conv_layers = get_conv_layers(model)
    
    total_params = model.count_params()
    conv_params = sum(np.prod(layer.get_weights()[0].shape) + 
                      (layer.get_weights()[1].shape[0] if len(layer.get_weights()) > 1 else 0)
                      for _, layer in conv_layers if len(layer.get_weights()) > 0)
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    FEATURE VISUALIZATION - ĞŸĞ†Ğ”Ğ¡Ğ£ĞœĞĞš                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ĞœĞĞ”Ğ•Ğ›Ğ¬: U-Net Ğ´Ğ»Ñ Ğ±Ñ–Ğ½Ğ°Ñ€Ğ½Ğ¾Ñ— ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ—                                      â•‘
â•‘  Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ° ĞºÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ–Ğ²: {total_params:,}                             
â•‘  ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ²: {conv_params:,}                                 
â•‘  ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¾Ğ²Ğ¸Ñ… ÑˆĞ°Ñ€Ñ–Ğ²: {len(conv_layers)}                              
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ (50%):                                                â•‘
â•‘  âœ“ Ğ’Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ²Ğ°Ğ³ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ                                    â•‘
â•‘  âœ“ ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ² Ğ½Ğ° Ñ€Ñ–Ğ·Ğ½Ğ¸Ñ… Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ°Ñ…                                    â•‘
â•‘  âœ“ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ²Ğ°Ğ³                                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¨ĞĞ Ğ†Ğ’ (50%):                                                   â•‘
â•‘  âœ“ Feature maps Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ°Ñ€Ñƒ                                             â•‘
â•‘  âœ“ Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹                                                   â•‘
â•‘  âœ“ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ (ÑĞ¿Ğ°Ñ€ÑĞ½Ñ–ÑÑ‚ÑŒ, Ñ€Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ»)                               â•‘
â•‘  âœ“ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ–Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¼ĞµÑ€ĞµĞ¶Ñƒ                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ğ”ĞĞ”ĞĞ¢ĞšĞĞ’Ğ:                                                                  â•‘
â•‘  âœ“ Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ pre-trained VGG16                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nğŸ“ Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ñ– Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ğ² 'results/':")
    for f in sorted(OUTPUT_DIR.glob("*.png")):
        print(f"    - {f.name}")


def main():
    print("\n" + "=" * 80)
    print("  FEATURE VISUALIZATION")
    print("  Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–Ğ² Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¸ Ñ‚Ğ° ÑˆĞ°Ñ€Ñ–Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¾Ñ— Ğ¼ĞµÑ€ĞµĞ¶Ñ–")
    print("=" * 80)
    
    print("\nğŸ“‹ ĞœĞµĞ½Ñ:")
    print("  1. Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ Ğ·Ğ³Ğ¾Ñ€Ñ‚ĞºĞ¸ (Ğ²Ğ»Ğ°ÑĞ½Ğ° U-Net)")
    print("  2. Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ğ¨ĞĞ Ğ†Ğ’ / Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ñ–Ğ¹ (Ğ²Ğ»Ğ°ÑĞ½Ğ° U-Net)")
    print("  3. Ğ’Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ pre-trained VGG16")
    print("  4. Ğ’Ğ¸ĞºĞ¾Ğ½Ğ°Ñ‚Ğ¸ Ğ²ÑĞµ Ğ¿Ğ¾ÑĞ»Ñ–Ğ´Ğ¾Ğ²Ğ½Ğ¾ (Ğ¿Ğ¾Ğ²Ğ½Ğ° Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ°)")
    
    choice = input("\n  Ğ’Ğ¸Ğ±ĞµÑ€Ñ–Ñ‚ÑŒ Ğ¾Ğ¿Ñ†Ñ–Ñ (1-4): ").strip()
    
    model = None
    
    # Ğ”Ğ»Ñ Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚Ñ–Ğ² 1, 2, 4 Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ° Ğ½Ğ°Ğ²Ñ‡ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    if choice in {"1", "2", "4"}:
        model_path = MODELS_DIR / "unet_for_visualization.h5"
        
        if model_path.exists():
            print(f"\n  Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Ğ· {model_path}...")
            model = keras.models.load_model(model_path)
        else:
            model = train_model_for_visualization(epochs=5)
    
    # Ğ“ĞµĞ½ĞµÑ€ÑƒÑ”Ğ¼Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğµ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    test_image = get_sample_image()
    
    if choice == "1" or choice == "4":
        # === Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’ (50%) ===
        visualize_filters(model)
        visualize_filters_comparison(model)
        visualize_filter_statistics(model)
    
    if choice == "2" or choice == "4":
        # === Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ Ğ¨ĞĞ Ğ†Ğ’ (50%) ===
        visualize_layer_activations(model, test_image)
        visualize_activation_heatmaps(model, test_image)
        visualize_activation_statistics(model, test_image)
        visualize_layer_progression(model, test_image)
    
    if choice == "3" or choice == "4":
        # === PRE-TRAINED VGG16 ===
        visualize_pretrained_filters()
        visualize_pretrained_activations(test_image)
    
    if choice in {"1", "2", "4"} and model is not None:
        create_summary_report(model)
    
    print("\n" + "=" * 80)
    print("  âœ… Ğ›Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ° Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
    print("=" * 80)


if __name__ == "__main__":
    main()

