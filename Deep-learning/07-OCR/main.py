"""
Optical Character Recognition (OCR) - –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
–§–æ–∫—É—Å: Confusion Matrix + Accuracy Trend + –¢–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏

–©–æ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ:
- –ù–∞–≤—á–∞–Ω–Ω—è CNN –º–æ–¥–µ–ª—ñ –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä—É–∫–æ–ø–∏—Å–Ω–∏—Ö —Ü–∏—Ñ—Ä (MNIST)
- –ü–æ–±—É–¥–æ–≤–∞ Confusion Matrix –¥–ª—è –≤—Å—ñ—Ö –∫–ª–∞—Å—ñ–≤ (60%)
- –ì—Ä–∞—Ñ—ñ–∫ —Ç—Ä–µ–Ω–¥—É —Ç–æ—á–Ω–æ—Å—Ç—ñ (Accuracy Trend) –ø–æ –µ–ø–æ—Ö–∞—Ö (20%)
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ —Ç–∏–ø–æ–≤–∏—Ö –ø–æ–º–∏–ª–æ–∫ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (20%)
- Live-—Ä–µ–∂–∏–º: —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ü–∏—Ñ—Ä –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏
"""

import time
from pathlib import Path
from typing import Tuple, List, Optional

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

import cv2

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
tf.random.set_seed(42)
np.random.seed(42)

sns.set(style="whitegrid", context="notebook")
plt.rcParams["figure.figsize"] = (12, 8)
plt.rcParams["font.size"] = 10

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
OUTPUT_DIR = Path("results")
OUTPUT_DIR.mkdir(exist_ok=True)

DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

MODELS_DIR = Path("models")
MODELS_DIR.mkdir(exist_ok=True)


def print_section(title: str) -> None:
    """–ö—Ä–∞—Å–∏–≤–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü—ñ—ó –≤ –∫–æ–Ω—Å–æ–ª—ñ."""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


# ---------------------------------------------------------------------------
# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö MNIST
# ---------------------------------------------------------------------------

IMG_SIZE = (28, 28)
NUM_CLASSES = 10
BATCH_SIZE = 64


def load_mnist_dataset() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É MNIST.
    –ü–æ–≤–µ—Ä—Ç–∞—î: (x_train, y_train, x_test, y_test)
    """
    print_section("–ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–¢–ê–°–ï–¢–£ MNIST")
    
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è [0, 255] -> [0, 1]
    x_train = x_train.astype(np.float32) / 255.0
    x_test = x_test.astype(np.float32) / 255.0
    
    # –î–æ–¥–∞—î–º–æ –∫–∞–Ω–∞–ª (28, 28) -> (28, 28, 1)
    x_train = np.expand_dims(x_train, axis=-1)
    x_test = np.expand_dims(x_test, axis=-1)
    
    print(f"\n‚úì Train set: {x_train.shape[0]} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
    print(f"‚úì Test set:  {x_test.shape[0]} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
    print(f"‚úì –†–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {IMG_SIZE[0]}x{IMG_SIZE[1]}")
    print(f"‚úì –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤: {NUM_CLASSES} (—Ü–∏—Ñ—Ä–∏ 0-9)")
    
    # –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤
    unique, counts = np.unique(y_train, return_counts=True)
    print("\nüìä –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ —É train set:")
    for u, c in zip(unique, counts):
        print(f"   –¶–∏—Ñ—Ä–∞ {u}: {c} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ ({100*c/len(y_train):.1f}%)")
    
    return x_train, y_train, x_test, y_test


def visualize_dataset_samples(x_data: np.ndarray, y_data: np.ndarray, num_samples: int = 20) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É."""
    print_section("–í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –ü–†–ò–ö–õ–ê–î–Ü–í –ó –î–ê–¢–ê–°–ï–¢–£")
    
    fig, axes = plt.subplots(2, 10, figsize=(15, 4))
    
    indices = np.random.choice(len(x_data), num_samples, replace=False)
    
    for idx, ax in enumerate(axes.flatten()):
        i = indices[idx]
        ax.imshow(x_data[i, :, :, 0], cmap='gray')
        ax.set_title(f"{y_data[i]}", fontsize=12)
        ax.axis('off')
    
    plt.suptitle("–ü—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É MNIST", fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "dataset_samples.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–∏–∫–ª–∞–¥–∏ –¥–∞—Ç–∞—Å–µ—Ç—É: {out_path}")
    plt.close(fig)


def plot_class_distribution(y_train: np.ndarray, y_test: np.ndarray) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∫–ª–∞—Å—ñ–≤."""
    print_section("–†–û–ó–ü–û–î–Ü–õ –ö–õ–ê–°–Ü–í")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Train distribution
    unique_train, counts_train = np.unique(y_train, return_counts=True)
    colors = plt.cm.tab10(np.linspace(0, 1, 10))
    
    axes[0].bar(unique_train, counts_train, color=colors, edgecolor='black')
    axes[0].set_xlabel("–¶–∏—Ñ—Ä–∞", fontsize=12)
    axes[0].set_ylabel("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", fontsize=12)
    axes[0].set_title("–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ (Train)", fontsize=14)
    axes[0].set_xticks(range(10))
    
    # Test distribution  
    unique_test, counts_test = np.unique(y_test, return_counts=True)
    
    axes[1].bar(unique_test, counts_test, color=colors, edgecolor='black')
    axes[1].set_xlabel("–¶–∏—Ñ—Ä–∞", fontsize=12)
    axes[1].set_ylabel("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", fontsize=12)
    axes[1].set_title("–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ (Test)", fontsize=14)
    axes[1].set_xticks(range(10))
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "class_distribution.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ —Ä–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤: {out_path}")
    plt.close(fig)


# ---------------------------------------------------------------------------
# 2. –ü–æ–±—É–¥–æ–≤–∞ CNN –º–æ–¥–µ–ª—ñ –¥–ª—è OCR
# ---------------------------------------------------------------------------


def build_ocr_model(input_shape: Tuple[int, int, int] = (28, 28, 1)) -> keras.Model:
    """
    –ü–æ–±—É–¥–æ–≤–∞ CNN –º–æ–¥–µ–ª—ñ –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ü–∏—Ñ—Ä.
    –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> Dense -> Output
    """
    model = keras.Sequential([
        # –ü–µ—Ä—à–∏–π –±–ª–æ–∫
        layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # –î—Ä—É–≥–∏–π –±–ª–æ–∫
        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # –¢—Ä–µ—Ç—ñ–π –±–ª–æ–∫
        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.25),
        
        # Fully connected
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(NUM_CLASSES, activation='softmax')
    ], name="OCR_CNN")
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-3),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


def train_ocr_model(
    x_train: np.ndarray,
    y_train: np.ndarray,
    x_test: np.ndarray,
    y_test: np.ndarray,
    epochs: int = 15,
    batch_size: int = 64
) -> Tuple[keras.Model, pd.DataFrame]:
    """
    –ù–∞–≤—á–∞–Ω–Ω—è OCR –º–æ–¥–µ–ª—ñ.
    –ü–æ–≤–µ—Ä—Ç–∞—î: (model, history_df)
    """
    print_section("–ù–ê–í–ß–ê–ù–ù–Ø OCR –ú–û–î–ï–õ–Ü")
    
    model_path = MODELS_DIR / "ocr_cnn.h5"
    
    print("\n  –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ...")
    model = build_ocr_model(input_shape=(*IMG_SIZE, 1))
    model.summary()
    
    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-6,
            verbose=1
        )
    ]
    
    print("\n  –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
    history = model.fit(
        x_train, y_train,
        validation_data=(x_test, y_test),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=callbacks,
        verbose=1
    )
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é
    hist_df = pd.DataFrame(history.history)
    hist_df['epoch'] = range(1, len(hist_df) + 1)
    hist_df.to_csv(OUTPUT_DIR / "training_history.csv", index=False)
    print(f"\n‚úì –Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞: results/training_history.csv")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
    model.save(model_path)
    print(f"‚úì –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞: {model_path}")
    
    return model, hist_df


# ---------------------------------------------------------------------------
# 3. Accuracy Trend - –ì—Ä–∞—Ñ—ñ–∫ —Ç—Ä–µ–Ω–¥—É —Ç–æ—á–Ω–æ—Å—Ç—ñ (20%)
# ---------------------------------------------------------------------------


def plot_accuracy_trend(hist_df: pd.DataFrame) -> None:
    """
    –ü–æ–±—É–¥–æ–≤–∞ –≥—Ä–∞—Ñ—ñ–∫—É —Ç—Ä–µ–Ω–¥—É —Ç–æ—á–Ω–æ—Å—Ç—ñ –ø–æ –µ–ø–æ—Ö–∞—Ö.
    –¶–µ –æ—Å–Ω–æ–≤–Ω–∞ –≤–∏–º–æ–≥–∞ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó (20%).
    """
    print_section("ACCURACY TREND - –¢–†–ï–ù–î –¢–û–ß–ù–û–°–¢–Ü (20%)")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    epochs = hist_df['epoch'] if 'epoch' in hist_df.columns else range(1, len(hist_df) + 1)
    
    # –ì—Ä–∞—Ñ—ñ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ
    axes[0].plot(epochs, hist_df['accuracy'], 'b-o', label='Train Accuracy', linewidth=2, markersize=6)
    axes[0].plot(epochs, hist_df['val_accuracy'], 'r-s', label='Validation Accuracy', linewidth=2, markersize=6)
    axes[0].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=12)
    axes[0].set_ylabel('Accuracy', fontsize=12)
    axes[0].set_title('–¢—Ä–µ–Ω–¥ —Ç–æ—á–Ω–æ—Å—Ç—ñ (Accuracy Trend)', fontsize=14, fontweight='bold')
    axes[0].legend(loc='lower right', fontsize=10)
    axes[0].grid(alpha=0.3)
    axes[0].set_ylim([0.9, 1.01])
    
    # –î–æ–¥–∞—î–º–æ –∞–Ω–æ—Ç–∞—Ü—ñ—ó –¥–ª—è –∫—ñ–Ω—Ü–µ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    final_train_acc = hist_df['accuracy'].iloc[-1]
    final_val_acc = hist_df['val_accuracy'].iloc[-1]
    axes[0].annotate(f'{final_train_acc:.4f}', 
                     xy=(len(epochs), final_train_acc), 
                     xytext=(5, 0), textcoords='offset points',
                     fontsize=10, color='blue')
    axes[0].annotate(f'{final_val_acc:.4f}', 
                     xy=(len(epochs), final_val_acc), 
                     xytext=(5, 0), textcoords='offset points',
                     fontsize=10, color='red')
    
    # –ì—Ä–∞—Ñ—ñ–∫ –≤—Ç—Ä–∞—Ç
    axes[1].plot(epochs, hist_df['loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)
    axes[1].plot(epochs, hist_df['val_loss'], 'r-s', label='Validation Loss', linewidth=2, markersize=6)
    axes[1].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=12)
    axes[1].set_ylabel('Loss', fontsize=12)
    axes[1].set_title('–¢—Ä–µ–Ω–¥ —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç (Loss Trend)', fontsize=14, fontweight='bold')
    axes[1].legend(loc='upper right', fontsize=10)
    axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "accuracy_trend.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ —Ç—Ä–µ–Ω–¥—É —Ç–æ—á–Ω–æ—Å—Ç—ñ: {out_path}")
    plt.close(fig)
    
    # –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –¥–µ—Ç–∞–ª—å–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫
    plot_detailed_accuracy_analysis(hist_df)


def plot_detailed_accuracy_analysis(hist_df: pd.DataFrame) -> None:
    """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç—Ä–µ–Ω–¥—É —Ç–æ—á–Ω–æ—Å—Ç—ñ."""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    epochs = range(1, len(hist_df) + 1)
    
    # 1. Accuracy –∑ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è–º –æ–±–ª–∞—Å—Ç—ñ
    axes[0, 0].fill_between(epochs, hist_df['accuracy'], alpha=0.3, color='blue')
    axes[0, 0].fill_between(epochs, hist_df['val_accuracy'], alpha=0.3, color='red')
    axes[0, 0].plot(epochs, hist_df['accuracy'], 'b-', label='Train', linewidth=2)
    axes[0, 0].plot(epochs, hist_df['val_accuracy'], 'r-', label='Validation', linewidth=2)
    axes[0, 0].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=11)
    axes[0, 0].set_ylabel('Accuracy', fontsize=11)
    axes[0, 0].set_title('–î–∏–Ω–∞–º—ñ–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ', fontsize=12)
    axes[0, 0].legend()
    axes[0, 0].grid(alpha=0.3)
    
    # 2. –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ train —ñ val accuracy (overfitting indicator)
    acc_diff = np.array(hist_df['accuracy']) - np.array(hist_df['val_accuracy'])
    colors = ['green' if d < 0.01 else 'orange' if d < 0.03 else 'red' for d in acc_diff]
    axes[0, 1].bar(epochs, acc_diff, color=colors, edgecolor='black', alpha=0.7)
    axes[0, 1].axhline(y=0.01, color='orange', linestyle='--', label='–ü–æ—Ä—ñ–≥ —É–≤–∞–≥–∏ (1%)')
    axes[0, 1].axhline(y=0.03, color='red', linestyle='--', label='–ü–æ—Ä—ñ–≥ overfitting (3%)')
    axes[0, 1].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=11)
    axes[0, 1].set_ylabel('Train Acc - Val Acc', fontsize=11)
    axes[0, 1].set_title('–Ü–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è', fontsize=12)
    axes[0, 1].legend(fontsize=9)
    axes[0, 1].grid(alpha=0.3)
    
    # 3. –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è accuracy –ø–æ –µ–ø–æ—Ö–∞—Ö
    val_acc_improvement = np.diff(hist_df['val_accuracy'], prepend=hist_df['val_accuracy'].iloc[0])
    colors = ['green' if i > 0 else 'red' for i in val_acc_improvement]
    axes[1, 0].bar(epochs, val_acc_improvement, color=colors, edgecolor='black', alpha=0.7)
    axes[1, 0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    axes[1, 0].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=11)
    axes[1, 0].set_ylabel('Œî Validation Accuracy', fontsize=11)
    axes[1, 0].set_title('–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –ø–æ –µ–ø–æ—Ö–∞—Ö', fontsize=12)
    axes[1, 0].grid(alpha=0.3)
    
    # 4. Learning rate (—è–∫—â–æ —î) –∞–±–æ –∫—É–º—É–ª—è—Ç–∏–≤–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è
    cumulative_improvement = np.cumsum(val_acc_improvement)
    axes[1, 1].plot(epochs, cumulative_improvement, 'g-o', linewidth=2, markersize=6)
    axes[1, 1].fill_between(epochs, cumulative_improvement, alpha=0.3, color='green')
    axes[1, 1].set_xlabel('–ï–ø–æ—Ö–∞', fontsize=11)
    axes[1, 1].set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è', fontsize=11)
    axes[1, 1].set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å –Ω–∞–≤—á–∞–Ω–Ω—è', fontsize=12)
    axes[1, 1].grid(alpha=0.3)
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "accuracy_trend_detailed.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–æ—á–Ω–æ—Å—Ç—ñ: {out_path}")
    plt.close(fig)


# ---------------------------------------------------------------------------
# 4. Confusion Matrix - –ú–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫ (60%)
# ---------------------------------------------------------------------------


def build_confusion_matrices(
    model: keras.Model,
    x_test: np.ndarray,
    y_test: np.ndarray
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    –ü–æ–±—É–¥–æ–≤–∞ Confusion Matrix –¥–ª—è –≤—Å—ñ—Ö –∫–ª–∞—Å—ñ–≤.
    –¶–µ –≥–æ–ª–æ–≤–Ω–∞ –≤–∏–º–æ–≥–∞ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó (60%).
    
    –ü–æ–≤–µ—Ä—Ç–∞—î: (y_true, y_pred, y_probs)
    """
    print_section("CONFUSION MATRIX - –ú–ê–¢–†–ò–¶–Ø –ü–û–ú–ò–õ–û–ö (60%)")
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    print("\n  –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å –Ω–∞ —Ç–µ—Å—Ç-—Å–µ—Ç—ñ...")
    y_probs = model.predict(x_test, verbose=1)
    y_pred = np.argmax(y_probs, axis=1)
    
    # –û–±—á–∏—Å–ª—é—î–º–æ confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —á–∏—Å–ª–æ–≤—ñ –¥–∞–Ω—ñ
    cm_df = pd.DataFrame(
        cm,
        index=[f"True_{i}" for i in range(10)],
        columns=[f"Pred_{i}" for i in range(10)]
    )
    cm_df.to_csv(OUTPUT_DIR / "confusion_matrix.csv")
    print(f"\n‚úì Confusion matrix –∑–±–µ—Ä–µ–∂–µ–Ω–∞: results/confusion_matrix.csv")
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –æ—Å–Ω–æ–≤–Ω–æ—ó confusion matrix
    plot_confusion_matrix_main(cm, y_test, y_pred)
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ confusion matrix
    plot_confusion_matrix_normalized(cm)
    
    # Per-class analysis
    plot_per_class_metrics(y_test, y_pred, y_probs)
    
    # Classification report
    print("\nüìä Classification Report:")
    print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ classification report
    report = classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)], output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    report_df.to_csv(OUTPUT_DIR / "classification_report.csv")
    print(f"‚úì Classification report –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/classification_report.csv")
    
    return y_test, y_pred, y_probs


def plot_confusion_matrix_main(cm: np.ndarray, y_test: np.ndarray, y_pred: np.ndarray) -> None:
    """–û—Å–Ω–æ–≤–Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è confusion matrix."""
    
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # Heatmap
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=range(10),
        yticklabels=range(10),
        ax=ax,
        cbar_kws={'label': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å'}
    )
    
    ax.set_xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ —Ü–∏—Ñ—Ä–∞', fontsize=14)
    ax.set_ylabel('–°–ø—Ä–∞–≤–∂–Ω—è —Ü–∏—Ñ—Ä–∞', fontsize=14)
    ax.set_title('Confusion Matrix (–ú–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫)\nOCR –º–æ–¥–µ–ª—å –Ω–∞ MNIST', fontsize=16, fontweight='bold')
    
    # –î–æ–¥–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    accuracy = accuracy_score(y_test, y_pred)
    total_correct = np.trace(cm)
    total_samples = np.sum(cm)
    
    stats_text = f"Accuracy: {accuracy:.4f} ({total_correct}/{total_samples})"
    ax.text(0.5, -0.1, stats_text, transform=ax.transAxes, fontsize=12,
            ha='center', va='top', fontweight='bold')
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "confusion_matrix.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ confusion matrix: {out_path}")
    plt.close(fig)


def plot_confusion_matrix_normalized(cm: np.ndarray) -> None:
    """–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ confusion matrix (—É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö)."""
    
    fig, axes = plt.subplots(1, 2, figsize=(18, 7))
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ —Ä—è–¥–∫–∞—Ö (precision-oriented)
    cm_row_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    sns.heatmap(
        cm_row_norm,
        annot=True,
        fmt='.2%',
        cmap='Greens',
        xticklabels=range(10),
        yticklabels=range(10),
        ax=axes[0],
        vmin=0, vmax=1
    )
    axes[0].set_xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ —Ü–∏—Ñ—Ä–∞', fontsize=12)
    axes[0].set_ylabel('–°–ø—Ä–∞–≤–∂–Ω—è —Ü–∏—Ñ—Ä–∞', fontsize=12)
    axes[0].set_title('–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –ø–æ —Ä—è–¥–∫–∞—Ö (Recall)', fontsize=14, fontweight='bold')
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ —Å—Ç–æ–≤–ø—Ü—è—Ö (recall-oriented)
    cm_col_norm = cm.astype('float') / cm.sum(axis=0)[np.newaxis, :]
    
    sns.heatmap(
        cm_col_norm,
        annot=True,
        fmt='.2%',
        cmap='Oranges',
        xticklabels=range(10),
        yticklabels=range(10),
        ax=axes[1],
        vmin=0, vmax=1
    )
    axes[1].set_xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ —Ü–∏—Ñ—Ä–∞', fontsize=12)
    axes[1].set_ylabel('–°–ø—Ä–∞–≤–∂–Ω—è —Ü–∏—Ñ—Ä–∞', fontsize=12)
    axes[1].set_title('–ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –ø–æ —Å—Ç–æ–≤–ø—Ü—è—Ö (Precision)', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "confusion_matrix_normalized.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—É confusion matrix: {out_path}")
    plt.close(fig)


def plot_per_class_metrics(y_test: np.ndarray, y_pred: np.ndarray, y_probs: np.ndarray) -> None:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É –æ–∫—Ä–µ–º–æ."""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # –û–±—á–∏—Å–ª—é—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    precisions = []
    recalls = []
    f1_scores = []
    
    for i in range(10):
        y_true_binary = (y_test == i).astype(int)
        y_pred_binary = (y_pred == i).astype(int)
        
        precisions.append(precision_score(y_true_binary, y_pred_binary, zero_division=0))
        recalls.append(recall_score(y_true_binary, y_pred_binary, zero_division=0))
        f1_scores.append(f1_score(y_true_binary, y_pred_binary, zero_division=0))
    
    x = np.arange(10)
    width = 0.25
    
    # 1. Precision, Recall, F1 –ø–æ –∫–ª–∞—Å–∞—Ö
    axes[0, 0].bar(x - width, precisions, width, label='Precision', color='#3498db')
    axes[0, 0].bar(x, recalls, width, label='Recall', color='#2ecc71')
    axes[0, 0].bar(x + width, f1_scores, width, label='F1-Score', color='#e74c3c')
    axes[0, 0].set_xlabel('–¶–∏—Ñ—Ä–∞', fontsize=11)
    axes[0, 0].set_ylabel('Score', fontsize=11)
    axes[0, 0].set_title('–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å–∞—Ö', fontsize=12, fontweight='bold')
    axes[0, 0].set_xticks(x)
    axes[0, 0].legend()
    axes[0, 0].set_ylim([0.95, 1.01])
    axes[0, 0].grid(alpha=0.3, axis='y')
    
    # 2. –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫ –ø–æ –∫–ª–∞—Å–∞—Ö
    errors_per_class = []
    for i in range(10):
        mask = y_test == i
        errors = np.sum(y_pred[mask] != i)
        errors_per_class.append(errors)
    
    colors = plt.cm.Reds(np.array(errors_per_class) / max(errors_per_class))
    axes[0, 1].bar(x, errors_per_class, color=colors, edgecolor='black')
    axes[0, 1].set_xlabel('–¶–∏—Ñ—Ä–∞', fontsize=11)
    axes[0, 1].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫', fontsize=11)
    axes[0, 1].set_title('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫ –ø–æ –∫–ª–∞—Å–∞—Ö', fontsize=12, fontweight='bold')
    axes[0, 1].set_xticks(x)
    axes[0, 1].grid(alpha=0.3, axis='y')
    
    # –î–æ–¥–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–¥ —Å—Ç–æ–≤–ø—Ü—è–º–∏
    for i, v in enumerate(errors_per_class):
        axes[0, 1].text(i, v + 0.5, str(v), ha='center', fontsize=10)
    
    # 3. –ù–∞–π—á–∞—Å—Ç—ñ—à—ñ –ø–æ–º–∏–ª–∫–∏ (confusion pairs)
    cm = confusion_matrix(y_test, y_pred)
    np.fill_diagonal(cm, 0)  # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—å
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ç–æ–ø-10 –ø–∞—Ä –ø–æ–º–∏–ª–æ–∫
    flat_indices = np.argsort(cm.ravel())[::-1][:10]
    top_pairs = []
    top_counts = []
    
    for idx in flat_indices:
        true_digit = idx // 10
        pred_digit = idx % 10
        count = cm[true_digit, pred_digit]
        if count > 0:
            top_pairs.append(f"{true_digit}‚Üí{pred_digit}")
            top_counts.append(count)
    
    axes[1, 0].barh(range(len(top_pairs)), top_counts, color='#e74c3c', edgecolor='black')
    axes[1, 0].set_yticks(range(len(top_pairs)))
    axes[1, 0].set_yticklabels(top_pairs)
    axes[1, 0].set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫', fontsize=11)
    axes[1, 0].set_title('–¢–æ–ø-10 –Ω–∞–π—á–∞—Å—Ç—ñ—à–∏—Ö –ø–æ–º–∏–ª–æ–∫', fontsize=12, fontweight='bold')
    axes[1, 0].invert_yaxis()
    axes[1, 0].grid(alpha=0.3, axis='x')
    
    # –î–æ–¥–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è
    for i, v in enumerate(top_counts):
        axes[1, 0].text(v + 0.5, i, str(v), va='center', fontsize=10)
    
    # 4. –†–æ–∑–ø–æ–¥—ñ–ª confidence –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö —ñ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
    max_probs = np.max(y_probs, axis=1)
    correct_mask = y_test == y_pred
    
    axes[1, 1].hist(max_probs[correct_mask], bins=50, alpha=0.7, label=f'–ü—Ä–∞–≤–∏–ª—å–Ω—ñ (n={np.sum(correct_mask)})', color='green', density=True)
    axes[1, 1].hist(max_probs[~correct_mask], bins=50, alpha=0.7, label=f'–ü–æ–º–∏–ª–∫–æ–≤—ñ (n={np.sum(~correct_mask)})', color='red', density=True)
    axes[1, 1].set_xlabel('Confidence (max probability)', fontsize=11)
    axes[1, 1].set_ylabel('–©—ñ–ª—å–Ω—ñ—Å—Ç—å', fontsize=11)
    axes[1, 1].set_title('–†–æ–∑–ø–æ–¥—ñ–ª –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ', fontsize=12, fontweight='bold')
    axes[1, 1].legend()
    axes[1, 1].grid(alpha=0.3)
    
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "per_class_metrics.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å–∞—Ö: {out_path}")
    plt.close(fig)


# ---------------------------------------------------------------------------
# 5. –¢–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏ - –Ü–ª—é—Å—Ç—Ä–∞—Ü—ñ—è (20%)
# ---------------------------------------------------------------------------


def illustrate_typical_errors(
    model: keras.Model,
    x_test: np.ndarray,
    y_test: np.ndarray,
    y_pred: np.ndarray,
    y_probs: np.ndarray,
    num_examples: int = 25
) -> None:
    """
    –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑ —Ç–∏–ø–æ–≤–∏—Ö –ø–æ–º–∏–ª–æ–∫ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è.
    –¶–µ –≤–∞–∂–ª–∏–≤–∞ –≤–∏–º–æ–≥–∞ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó (20%).
    """
    print_section("–¢–ò–ü–û–í–Ü –ü–û–ú–ò–õ–ö–ò - –Ü–õ–Æ–°–¢–†–ê–¶–Ü–Ø (20%)")
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–æ–º–∏–ª–∫–∏
    error_mask = y_test != y_pred
    error_indices = np.where(error_mask)[0]
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–º–∏–ª–æ–∫:")
    print(f"   –í—Å—å–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤: {len(y_test)}")
    print(f"   –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {len(error_indices)}")
    print(f"   Accuracy: {(1 - len(error_indices)/len(y_test))*100:.2f}%")
    
    if len(error_indices) == 0:
        print("\n‚úì –ü–æ–º–∏–ª–æ–∫ –Ω–µ–º–∞—î! –ú–æ–¥–µ–ª—å —ñ–¥–µ–∞–ª—å–Ω–∞.")
        return
    
    # –°–æ—Ä—Ç—É—î–º–æ –ø–æ–º–∏–ª–∫–∏ –∑–∞ confidence (–Ω–∞–π–≤–ø–µ–≤–Ω–µ–Ω—ñ—à—ñ –ø–æ–º–∏–ª–∫–∏ —Ü—ñ–∫–∞–≤—ñ—à—ñ)
    error_confidences = np.max(y_probs[error_indices], axis=1)
    sorted_indices = error_indices[np.argsort(error_confidences)[::-1]]
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–π–≤–ø–µ–≤–Ω–µ–Ω—ñ—à–∏—Ö –ø–æ–º–∏–ª–æ–∫
    plot_confident_errors(x_test, y_test, y_pred, y_probs, sorted_indices, num_examples)
    
    # –ê–Ω–∞–ª—ñ–∑ —Ç–∏–ø—ñ–≤ –ø–æ–º–∏–ª–æ–∫
    analyze_error_patterns(y_test, y_pred, x_test, error_indices)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–º–∏–ª–æ–∫ –ø–æ –ø–∞—Ä–∞—Ö —Ü–∏—Ñ—Ä
    plot_error_pairs(x_test, y_test, y_pred, y_probs, error_indices)


def plot_confident_errors(
    x_test: np.ndarray,
    y_test: np.ndarray,
    y_pred: np.ndarray,
    y_probs: np.ndarray,
    sorted_error_indices: np.ndarray,
    num_examples: int = 25
) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–π–≤–ø–µ–≤–Ω–µ–Ω—ñ—à–∏—Ö –ø–æ–º–∏–ª–æ–∫ –º–æ–¥–µ–ª—ñ."""
    
    n = min(num_examples, len(sorted_error_indices))
    cols = 5
    rows = (n + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))
    axes = axes.flatten() if rows > 1 else [axes] if cols == 1 else axes.flatten()
    
    for idx, ax in enumerate(axes[:n]):
        i = sorted_error_indices[idx]
        
        img = x_test[i, :, :, 0]
        true_label = y_test[i]
        pred_label = y_pred[i]
        confidence = y_probs[i, pred_label]
        true_prob = y_probs[i, true_label]
        
        ax.imshow(img, cmap='gray')
        ax.set_title(f"True: {true_label} ({true_prob:.1%})\nPred: {pred_label} ({confidence:.1%})", 
                     fontsize=10, color='red')
        ax.axis('off')
    
    # –ü—Ä–∏—Ö–æ–≤—É—î–º–æ –∑–∞–π–≤—ñ –æ—Å—ñ
    for ax in axes[n:]:
        ax.axis('off')
    
    plt.suptitle('–¢–æ–ø –ø–æ–º–∏–ª–æ–∫ –∑ –Ω–∞–π–≤–∏—â–æ—é –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—é –º–æ–¥–µ–ª—ñ', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "typical_errors_confident.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –Ω–∞–π–≤–ø–µ–≤–Ω–µ–Ω—ñ—à—ñ –ø–æ–º–∏–ª–∫–∏: {out_path}")
    plt.close(fig)


def analyze_error_patterns(
    y_test: np.ndarray,
    y_pred: np.ndarray,
    x_test: np.ndarray,
    error_indices: np.ndarray
) -> None:
    """–ê–Ω–∞–ª—ñ–∑ –ø–∞—Ç–µ—Ä–Ω—ñ–≤ –ø–æ–º–∏–ª–æ–∫."""
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π—á–∞—Å—Ç—ñ—à—ñ –ø–∞—Ä–∏ –ø–æ–º–∏–ª–æ–∫
    error_pairs = {}
    for i in error_indices:
        pair = (y_test[i], y_pred[i])
        if pair not in error_pairs:
            error_pairs[pair] = []
        error_pairs[pair].append(i)
    
    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —á–∞—Å—Ç–æ—Ç–æ—é
    sorted_pairs = sorted(error_pairs.items(), key=lambda x: len(x[1]), reverse=True)
    
    print("\nüìä –ù–∞–π—á–∞—Å—Ç—ñ—à—ñ –ø–∞—Ä–∏ –ø–æ–º–∏–ª–æ–∫:")
    for pair, indices in sorted_pairs[:10]:
        print(f"   {pair[0]} ‚Üí {pair[1]}: {len(indices)} –ø–æ–º–∏–ª–æ–∫")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    error_stats = []
    for pair, indices in sorted_pairs:
        error_stats.append({
            'true_digit': pair[0],
            'predicted_digit': pair[1],
            'count': len(indices),
            'percentage': 100 * len(indices) / len(error_indices)
        })
    
    error_df = pd.DataFrame(error_stats)
    error_df.to_csv(OUTPUT_DIR / "error_patterns.csv", index=False)
    print(f"\n‚úì –ü–∞—Ç–µ—Ä–Ω–∏ –ø–æ–º–∏–ª–æ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/error_patterns.csv")


def plot_error_pairs(
    x_test: np.ndarray,
    y_test: np.ndarray,
    y_pred: np.ndarray,
    y_probs: np.ndarray,
    error_indices: np.ndarray
) -> None:
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–º–∏–ª–æ–∫ –¥–ª—è –Ω–∞–π–ø—Ä–æ–±–ª–µ–º–Ω—ñ—à–∏—Ö –ø–∞—Ä —Ü–∏—Ñ—Ä."""
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ç–æ–ø-6 –ø–∞—Ä –ø–æ–º–∏–ª–æ–∫
    error_pairs = {}
    for i in error_indices:
        pair = (y_test[i], y_pred[i])
        if pair not in error_pairs:
            error_pairs[pair] = []
        error_pairs[pair].append(i)
    
    sorted_pairs = sorted(error_pairs.items(), key=lambda x: len(x[1]), reverse=True)[:6]
    
    fig, axes = plt.subplots(6, 5, figsize=(15, 18))
    
    for row, (pair, indices) in enumerate(sorted_pairs):
        true_digit, pred_digit = pair
        
        # –ë–µ—Ä–µ–º–æ –¥–æ 5 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
        examples = indices[:5]
        
        for col, idx in enumerate(examples):
            img = x_test[idx, :, :, 0]
            confidence = y_probs[idx, pred_digit]
            
            axes[row, col].imshow(img, cmap='gray')
            axes[row, col].set_title(f"Conf: {confidence:.1%}", fontsize=9)
            axes[row, col].axis('off')
            
            if col == 0:
                axes[row, col].set_ylabel(f"{true_digit}‚Üí{pred_digit}\n({len(indices)} –ø–æ–º.)", 
                                          fontsize=11, rotation=0, labelpad=50)
        
        # –ü—Ä–∏—Ö–æ–≤—É—î–º–æ –∑–∞–π–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
        for col in range(len(examples), 5):
            axes[row, col].axis('off')
    
    plt.suptitle('–ü—Ä–∏–∫–ª–∞–¥–∏ –ø–æ–º–∏–ª–æ–∫ –¥–ª—è –Ω–∞–π–ø—Ä–æ–±–ª–µ–º–Ω—ñ—à–∏—Ö –ø–∞—Ä —Ü–∏—Ñ—Ä', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    out_path = OUTPUT_DIR / "error_pairs_examples.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–∏–∫–ª–∞–¥–∏ –ø–∞—Ä –ø–æ–º–∏–ª–æ–∫: {out_path}")
    plt.close(fig)


def create_error_analysis_summary(
    y_test: np.ndarray,
    y_pred: np.ndarray,
    y_probs: np.ndarray
) -> None:
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏."""
    
    print_section("–ü–Ü–î–°–£–ú–û–ö –ê–ù–ê–õ–Ü–ó–£ –ü–û–ú–ò–õ–û–ö")
    
    error_mask = y_test != y_pred
    correct_mask = ~error_mask
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ
    correct_conf = np.max(y_probs[correct_mask], axis=1)
    error_conf = np.max(y_probs[error_mask], axis=1)
    
    print("\nüìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ:")
    print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:")
    print(f"      –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {np.mean(correct_conf):.4f}")
    print(f"      –ú—ñ–Ω/–ú–∞–∫—Å: {np.min(correct_conf):.4f} / {np.max(correct_conf):.4f}")
    
    if len(error_conf) > 0:
        print(f"   –ü–æ–º–∏–ª–∫–æ–≤—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:")
        print(f"      –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {np.mean(error_conf):.4f}")
        print(f"      –ú—ñ–Ω/–ú–∞–∫—Å: {np.min(error_conf):.4f} / {np.max(error_conf):.4f}")
    
    # Threshold analysis
    thresholds = [0.5, 0.7, 0.8, 0.9, 0.95, 0.99]
    print("\nüìä –ê–Ω–∞–ª—ñ–∑ –ø–æ—Ä–æ–≥—É –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ:")
    print(f"   {'–ü–æ—Ä—ñ–≥':<10} {'–í—ñ–¥—Ö–∏–ª–µ–Ω–æ':<15} {'Accuracy –∑–∞–ª–∏—à–∫—É':<20}")
    
    for thr in thresholds:
        max_probs = np.max(y_probs, axis=1)
        accepted_mask = max_probs >= thr
        
        if np.sum(accepted_mask) > 0:
            acc = accuracy_score(y_test[accepted_mask], y_pred[accepted_mask])
            rejected_pct = 100 * (1 - np.mean(accepted_mask))
            print(f"   {thr:<10.2f} {rejected_pct:<15.1f}% {acc:<20.4f}")


# ---------------------------------------------------------------------------
# 6. Live-—Ä–µ–∂–∏–º: OCR –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏
# ---------------------------------------------------------------------------


def preprocess_for_ocr(frame: np.ndarray) -> np.ndarray:
    """–ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ –∫–∞–¥—Ä—É –¥–ª—è OCR."""
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ grayscale
    if len(frame.shape) == 3:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    else:
        gray = frame
    
    # –ì–∞—É—Å–æ–≤–µ —Ä–æ–∑–º–∏—Ç—Ç—è –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è —à—É–º—É
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # –ê–¥–∞–ø—Ç–∏–≤–Ω–µ –ø–æ—Ä–æ–≥—É–≤–∞–Ω–Ω—è
    thresh = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    return thresh


def find_digit_contours(thresh: np.ndarray) -> List[Tuple[int, int, int, int]]:
    """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å –∫–æ–Ω—Ç—É—Ä–∏ —Ü–∏—Ñ—Ä –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ."""
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    digit_boxes = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞ —Ä–æ–∑–º—ñ—Ä–æ–º
        area = w * h
        aspect_ratio = h / w if w > 0 else 0
        
        if area > 100 and 0.5 < aspect_ratio < 3:
            digit_boxes.append((x, y, w, h))
    
    # –°–æ—Ä—Ç—É—î–º–æ –∑–ª—ñ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
    digit_boxes.sort(key=lambda b: b[0])
    
    return digit_boxes


def extract_digit(thresh: np.ndarray, box: Tuple[int, int, int, int]) -> np.ndarray:
    """–í–∏—Ç—è–≥—É—î —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ü–∏—Ñ—Ä–∏."""
    x, y, w, h = box
    
    # –í–∏—Ç—è–≥—É—î–º–æ —Ä–µ–≥—ñ–æ–Ω –∑ padding
    pad = 5
    x1 = max(0, x - pad)
    y1 = max(0, y - pad)
    x2 = min(thresh.shape[1], x + w + pad)
    y2 = min(thresh.shape[0], y + h + pad)
    
    digit_img = thresh[y1:y2, x1:x2]
    
    # –†–µ—Å–∞–π–∑ –¥–æ 28x28 –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º –ø—Ä–æ–ø–æ—Ä—Ü—ñ–π
    h, w = digit_img.shape
    
    if h > w:
        new_h = 20
        new_w = int(w * 20 / h)
    else:
        new_w = 20
        new_h = int(h * 20 / w)
    
    if new_w > 0 and new_h > 0:
        digit_img = cv2.resize(digit_img, (new_w, new_h))
    
    # –¶–µ–Ω—Ç—Ä—É—î–º–æ –Ω–∞ 28x28
    final_img = np.zeros((28, 28), dtype=np.uint8)
    x_offset = (28 - new_w) // 2
    y_offset = (28 - new_h) // 2
    
    if new_w > 0 and new_h > 0:
        final_img[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = digit_img
    
    return final_img


def live_ocr(model: keras.Model, confidence_threshold: float = 0.7):
    """
    Live-—Ä–µ–∂–∏–º: —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ü–∏—Ñ—Ä –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏.
    """
    print_section("LIVE OCR –ó –í–ï–ë-–ö–ê–ú–ï–†–ò")
    
    print("\n  –í—ñ–¥–∫—Ä–∏—Ç—Ç—è –≤–µ–±-–∫–∞–º–µ—Ä–∏...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤–µ–±-–∫–∞–º–µ—Ä—É")
        return
    
    print("\n‚úì Live OCR –∑–∞–ø—É—â–µ–Ω–æ!")
    print("\n  –ö–µ—Ä—É–≤–∞–Ω–Ω—è:")
    print("    - 'q' –∞–±–æ 'ESC' ‚Äî –≤–∏—Ö—ñ–¥")
    print("    - '+' ‚Äî –∑–±—ñ–ª—å—à–∏—Ç–∏ –ø–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ")
    print("    - '-' ‚Äî –∑–º–µ–Ω—à–∏—Ç–∏ –ø–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ")
    print("    - 's' ‚Äî –∑–±–µ—Ä–µ–≥—Ç–∏ –∫–∞–¥—Ä")
    print("    - 'r' ‚Äî –ø–æ–∫–∞–∑–∞—Ç–∏ ROI (region of interest)")
    
    fps_history = []
    saved_frames = 0
    show_roi = True
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("  ‚ö† –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∫–∞–¥—Ä")
                break
            
            start_time = time.time()
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ ROI (—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –∫–∞–¥—Ä—É)
            h, w = frame.shape[:2]
            roi_size = min(h, w) // 2
            roi_x = (w - roi_size) // 2
            roi_y = (h - roi_size) // 2
            
            roi = frame[roi_y:roi_y+roi_size, roi_x:roi_x+roi_size]
            
            # –ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞
            thresh = preprocess_for_ocr(roi)
            
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ü–∏—Ñ—Ä–∏
            boxes = find_digit_contours(thresh)
            
            recognized_text = ""
            
            for box in boxes:
                x, y, bw, bh = box
                
                # –í–∏—Ç—è–≥—É—î–º–æ —Ü–∏—Ñ—Ä—É
                digit_img = extract_digit(thresh, box)
                
                # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –ø–µ—Ä–µ–¥–±–∞—á–∞—î–º–æ
                digit_normalized = digit_img.astype(np.float32) / 255.0
                digit_input = np.expand_dims(np.expand_dims(digit_normalized, axis=-1), axis=0)
                
                probs = model.predict(digit_input, verbose=0)[0]
                pred_digit = np.argmax(probs)
                confidence = probs[pred_digit]
                
                if confidence >= confidence_threshold:
                    recognized_text += str(pred_digit)
                    
                    # –ú–∞–ª—é—î–º–æ box –Ω–∞ ROI
                    color = (0, 255, 0)
                    cv2.rectangle(roi, (x, y), (x+bw, y+bh), color, 2)
                    cv2.putText(roi, f"{pred_digit} ({confidence:.0%})", 
                               (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # –ö–æ–ø—ñ—é—î–º–æ ROI –Ω–∞–∑–∞–¥ —É frame
            frame[roi_y:roi_y+roi_size, roi_x:roi_x+roi_size] = roi
            
            # –ú–∞–ª—é—î–º–æ —Ä–∞–º–∫—É ROI
            if show_roi:
                cv2.rectangle(frame, (roi_x, roi_y), (roi_x+roi_size, roi_y+roi_size), (255, 0, 0), 2)
            
            # FPS
            dt = time.time() - start_time
            fps = 1.0 / dt if dt > 0 else 0.0
            fps_history.append(fps)
            if len(fps_history) > 30:
                fps_history.pop(0)
            avg_fps = np.mean(fps_history)
            
            # Info overlay
            info_lines = [
                f"FPS: {avg_fps:.1f}",
                f"Threshold: {confidence_threshold:.0%}",
                f"Recognized: {recognized_text if recognized_text else 'None'}",
            ]
            
            y_text = 30
            for line in info_lines:
                cv2.putText(frame, line, (10, y_text),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                y_text += 30
            
            cv2.imshow("Live OCR - Digit Recognition", frame)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ threshold image
            if show_roi:
                cv2.imshow("Threshold", thresh)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord("q") or key == 27:
                print("\n  –ó—É–ø–∏–Ω–∫–∞...")
                break
            elif key == ord("+") or key == ord("="):
                confidence_threshold = min(0.99, confidence_threshold + 0.05)
                print(f"  Threshold: {confidence_threshold:.0%}")
            elif key == ord("-") or key == ord("_"):
                confidence_threshold = max(0.1, confidence_threshold - 0.05)
                print(f"  Threshold: {confidence_threshold:.0%}")
            elif key == ord("s"):
                saved_frames += 1
                out_path = OUTPUT_DIR / f"live_ocr_{saved_frames}.jpg"
                cv2.imwrite(str(out_path), frame)
                print(f"  ‚úì –ö–∞–¥—Ä –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {out_path}")
            elif key == ord("r"):
                show_roi = not show_roi
                if not show_roi:
                    cv2.destroyWindow("Threshold")
                print(f"  Show ROI: {show_roi}")
    
    except KeyboardInterrupt:
        print("\n  –ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        print("\n‚úì Live OCR –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        if fps_history:
            print(f"  –°–µ—Ä–µ–¥–Ω—ñ–π FPS: {np.mean(fps_history):.1f}")
        print(f"  –ó–±–µ—Ä–µ–∂–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤: {saved_frames}")


# ---------------------------------------------------------------------------
# 7. –ì–æ–ª–æ–≤–Ω–µ –º–µ–Ω—é
# ---------------------------------------------------------------------------


def main():
    print("\n" + "=" * 80)
    print("  OPTICAL CHARACTER RECOGNITION (OCR)")
    print("  Confusion Matrix (60%) + Accuracy Trend (20%) + Typical Errors (20%)")
    print("=" * 80)
    
    print("\nüìã –ú–µ–Ω—é:")
    print("  1. –ù–∞–≤—á–∏—Ç–∏ OCR –º–æ–¥–µ–ª—å —Ç–∞ –ø–æ–±—É–¥—É–≤–∞—Ç–∏ Accuracy Trend (20%)")
    print("  2. –ü–æ–±—É–¥—É–≤–∞—Ç–∏ Confusion Matrix (60%)")
    print("  3. –Ü–ª—é—Å—Ç—Ä—É–≤–∞—Ç–∏ —Ç–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏ (20%)")
    print("  4. Live OCR –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏")
    print("  5. –í–∏–∫–æ–Ω–∞—Ç–∏ –≤—Å–µ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ (1‚Üí2‚Üí3)")
    
    choice = input("\n  –í–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é (1-5): ").strip()
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
    x_train, y_train, x_test, y_test = load_mnist_dataset()
    
    model = None
    hist_df = None
    y_pred = None
    y_probs = None
    
    if choice in {"1", "5"}:
        # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
        visualize_dataset_samples(x_train, y_train)
        plot_class_distribution(y_train, y_test)
        
        # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        model, hist_df = train_ocr_model(x_train, y_train, x_test, y_test, epochs=15)
        
        # Accuracy Trend (20%)
        plot_accuracy_trend(hist_df)
    
    if choice in {"2", "5"}:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å —è–∫—â–æ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞
        if model is None:
            model_path = MODELS_DIR / "ocr_cnn.h5"
            if model_path.exists():
                print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ {model_path}...")
                model = keras.models.load_model(model_path)
            else:
                print("\n‚ö† –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø—É–Ω–∫—Ç 1 –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.")
                return
        
        # Confusion Matrix (60%)
        y_test_cm, y_pred, y_probs = build_confusion_matrices(model, x_test, y_test)
    
    if choice in {"3", "5"}:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å —è–∫—â–æ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞
        if model is None:
            model_path = MODELS_DIR / "ocr_cnn.h5"
            if model_path.exists():
                print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ {model_path}...")
                model = keras.models.load_model(model_path)
            else:
                print("\n‚ö† –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø—É–Ω–∫—Ç 1 –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.")
                return
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è —è–∫—â–æ —â–µ –Ω–µ –æ—Ç—Ä–∏–º–∞–Ω—ñ
        if y_pred is None:
            y_probs = model.predict(x_test, verbose=1)
            y_pred = np.argmax(y_probs, axis=1)
        
        # Typical Errors (20%)
        illustrate_typical_errors(model, x_test, y_test, y_pred, y_probs)
        create_error_analysis_summary(y_test, y_pred, y_probs)
    
    if choice == "4":
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
        model_path = MODELS_DIR / "ocr_cnn.h5"
        if model_path.exists():
            print(f"\n  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ {model_path}...")
            model = keras.models.load_model(model_path)
            live_ocr(model, confidence_threshold=0.7)
        else:
            print("\n‚ö† –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –ø—É–Ω–∫—Ç 1 –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.")
            return
    
    print_section("–ü–Ü–î–°–£–ú–û–ö")
    print("\n‚úÖ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ ¬´Optical Character Recognition (OCR)¬ª –≤–∏–∫–æ–Ω–∞–Ω–∞.")
    print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ 'results':")
    print("  - dataset_samples.png ‚Äî –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç—É")
    print("  - class_distribution.png ‚Äî —Ä–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤")
    print("  - training_history.csv ‚Äî —á–∏—Å–ª–æ–≤—ñ –¥–∞–Ω—ñ –Ω–∞–≤—á–∞–Ω–Ω—è")
    print("  - accuracy_trend.png ‚Äî —Ç—Ä–µ–Ω–¥ —Ç–æ—á–Ω–æ—Å—Ç—ñ (20%)")
    print("  - accuracy_trend_detailed.png ‚Äî –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç—Ä–µ–Ω–¥—É")
    print("  - confusion_matrix.png ‚Äî –º–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫ (60%)")
    print("  - confusion_matrix_normalized.png ‚Äî –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è")
    print("  - per_class_metrics.png ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å–∞—Ö")
    print("  - classification_report.csv ‚Äî –∑–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó")
    print("  - typical_errors_confident.png ‚Äî —Ç–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏ (20%)")
    print("  - error_pairs_examples.png ‚Äî –ø—Ä–∏–∫–ª–∞–¥–∏ –ø–∞—Ä –ø–æ–º–∏–ª–æ–∫")
    print("  - error_patterns.csv ‚Äî –ø–∞—Ç–µ—Ä–Ω–∏ –ø–æ–º–∏–ª–æ–∫")
    print("  - live_ocr_*.jpg ‚Äî –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –∫–∞–¥—Ä–∏ –∑ live-—Ä–µ–∂–∏–º—É")
    
    print("\nüìä –í—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –≤–∏–º–æ–≥–∞–º:")
    print("  ‚úÖ Confusion Matrix ‚Äî 60%")
    print("  ‚úÖ Accuracy Trend ‚Äî 20%")
    print("  ‚úÖ Typical Errors ‚Äî 20%")


if __name__ == "__main__":
    main()

