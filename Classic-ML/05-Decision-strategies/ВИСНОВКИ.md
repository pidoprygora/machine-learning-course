# –í–∏—Å–Ω–æ–≤–∫–∏ –∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è Decision Strategies –¥–ª—è MountainCar

## –ó–º—ñ—Å—Ç
1. [–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö —Ç–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É](#1-–∞–Ω–∞–ª—ñ–∑-–¥–∞–Ω–∏—Ö-—Ç–∞-—Ä–æ–∑–ø–æ–¥—ñ–ª—É)
2. [–Ü–Ω–∂–µ–Ω–µ—Ä—ñ—è —Ç–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫](#2-—ñ–Ω–∂–µ–Ω–µ—Ä—ñ—è-—Ç–∞-–≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å-–æ–∑–Ω–∞–∫)
3. [–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó](#3-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏-–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó)
4. [–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å](#4-–ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è-—Å—Ç—Ä–∞—Ç–µ–≥—ñ–π-–ø—Ä–∏–π–Ω—è—Ç—Ç—è-—Ä—ñ—à–µ–Ω—å)
5. [–ê–Ω–∞–ª—ñ–∑ –Ω–∞–≤—á–∞–Ω–Ω—è Q-Learning](#5-–∞–Ω–∞–ª—ñ–∑-–Ω–∞–≤—á–∞–Ω–Ω—è-q-learning)
6. [–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏](#6-–∑–∞–≥–∞–ª—å–Ω—ñ-–≤–∏—Å–Ω–æ–≤–∫–∏)

---

## 1. –ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö —Ç–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É

### 1.1 –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤
![–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤](plots/class_distribution.png)

**–í–∏—Å–Ω–æ–≤–∫–∏:**
- –î–∞—Ç–∞—Å–µ—Ç –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π –∑–∞–≤–¥—è–∫–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—é –∑–º—ñ—à–∞–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –∑–±–æ—Ä—É –¥–∞–Ω–∏—Ö (70% —Ä–æ–∑—É–º–Ω–æ—ó + 30% –≤–∏–ø–∞–¥–∫–æ–≤–æ—ó)
- –°–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–∏—Ö/–Ω–µ–≤–¥–∞–ª–∏—Ö –µ–ø—ñ–∑–æ–¥—ñ–≤ –±–ª–∏–∑—å–∫–µ –¥–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤
- –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–Ω–∞—á–Ω–æ–≥–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É –∫–ª–∞—Å—ñ–≤ –¥–æ–∑–≤–æ–ª—è—î —É–Ω–∏–∫–Ω—É—Ç–∏ bias —É –º–æ–¥–µ–ª—è—Ö
- –¶–µ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂—É—î –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è `AdvancedVelocityStrategy` –¥–ª—è –∑–±–æ—Ä—É –¥–∞–Ω–∏—Ö

**–ü—Ä–∞–∫—Ç–∏—á–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è:**
–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤, —â–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—é—Ç—å —É—Å–ø—ñ—à–Ω—ñ—Å—Ç—å. –ë–µ–∑ —Ä–æ–∑—É–º–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –∑–±–æ—Ä—É (–ª–∏—à–µ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –¥—ñ—ó) success rate –±—É–≤ –±–∏ –±–ª–∏–∑—å–∫–æ 0%, —â–æ —É–Ω–µ–º–æ–∂–ª–∏–≤–∏–ª–æ –± –Ω–∞–≤—á–∞–Ω–Ω—è.

---

### 1.2 –†–æ–∑–ø–æ–¥—ñ–ª –æ–∑–Ω–∞–∫ –∑–∞ –∫–ª–∞—Å–∞–º–∏
![–†–æ–∑–ø–æ–¥—ñ–ª –æ–∑–Ω–∞–∫](plots/features_distribution.png)

**–í–∏—Å–Ω–æ–≤–∫–∏:**

**–ü–æ—á–∞—Ç–∫–æ–≤–∞ –ø–æ–∑–∏—Ü—ñ—è:**
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏ –º–æ–∂—É—Ç—å —Å—Ç–∞—Ä—Ç—É–≤–∞—Ç–∏ –∑ –±—É–¥—å-—è–∫–æ—ó –ø–æ–∑–∏—Ü—ñ—ó
- –†–æ–∑–ø–æ–¥—ñ–ª–∏ –¥–ª—è –æ–±–æ—Ö –∫–ª–∞—Å—ñ–≤ –º–∞–π–∂–µ —ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –ø–æ—á–∞—Ç–∫–æ–≤–∞ –ø–æ–∑–∏—Ü—ñ—è –ù–ï —î –≤–∏–∑–Ω–∞—á–∞–ª—å–Ω–∏–º —Ñ–∞–∫—Ç–æ—Ä–æ–º —É—Å–ø—ñ—Ö—É

**–ü–æ—á–∞—Ç–∫–æ–≤–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å:**
- –¢–∞–∫–æ–∂ –Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –∑–Ω–∞—á–Ω–æ—ó —Ä—ñ–∑–Ω–∏—Ü—ñ –º—ñ–∂ –∫–ª–∞—Å–∞–º–∏
- –†–æ–∑–ø–æ–¥—ñ–ª–∏ —Å–∏–ª—å–Ω–æ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—Ç—å—Å—è
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞–Ω (–ø–æ–∑–∏—Ü—ñ—è, —à–≤–∏–¥–∫—ñ—Å—Ç—å) –º–∞—î –Ω–∏–∑—å–∫—É –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—É —Å–∏–ª—É

**–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ—Å—è–≥–Ω—É—Ç–∞ –ø–æ–∑–∏—Ü—ñ—è:**
- **–ö–†–ò–¢–ò–ß–ù–ê –û–ó–ù–ê–ö–ê!** –ß—ñ—Ç–∫–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∫–ª–∞—Å—ñ–≤
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏ –¥–æ—Å—è–≥–∞—é—Ç—å –ø–æ–∑–∏—Ü—ñ–π > 0.3
- –ù–µ–≤–¥–∞–ª—ñ –µ–ø—ñ–∑–æ–¥–∏ —Ä—ñ–¥–∫–æ –ø–µ—Ä–µ–≤–∏—â—É—é—Ç—å 0.0
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –ø–æ–∑–∏—Ü—ñ—è - –Ω–∞–π—Å–∏–ª—å–Ω—ñ—à–∏–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä —É—Å–ø—ñ—Ö—É

**–°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å:**
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏ –º–∞—é—Ç—å —Ç—Ä–æ—Ö–∏ –≤–∏—â—É —Å–µ—Ä–µ–¥–Ω—é —à–≤–∏–¥–∫—ñ—Å—Ç—å
- –†–æ–∑–ø–æ–¥—ñ–ª–∏ —á–∞—Å—Ç–∫–æ–≤–æ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—Ç—å—Å—è
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –ø–æ–º—ñ—Ä–Ω–∞ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞ —Å–∏–ª–∞

**–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è:**
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—Ç—å—Å—è –≤–∏—â–æ—é –µ–Ω–µ—Ä–≥—ñ—î—é
- –ß—ñ—Ç–∫–µ –∑–º—ñ—â–µ–Ω–Ω—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É –≤–ø—Ä–∞–≤–æ –¥–ª—è —É—Å–ø—ñ—à–Ω–∏—Ö –µ–ø—ñ–∑–æ–¥—ñ–≤
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –µ–Ω–µ—Ä–≥—ñ—è —Å–∏—Å—Ç–µ–º–∏ - –≤–∞–∂–ª–∏–≤–∏–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ–≥–æ —É—Å–ø—ñ—Ö—É

**–ß–∞—Å—Ç–∫–∞ —Ä—É—Ö—É –≤–ø—Ä–∞–≤–æ:**
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—é—Ç—å –±—ñ–ª—å—à—É —á–∞—Å—Ç–∫—É —Ä—É—Ö—É –≤ –Ω–∞–ø—Ä—è–º–∫—É –º–µ—Ç–∏
- –†–æ–∑–ø–æ–¥—ñ–ª–∏ –¥–æ–±—Ä–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –Ω–∞–ø—Ä—è–º–æ–∫ —Ä—É—Ö—É –º–∞—î –≤–∏—Å–æ–∫—É –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—É —Å–∏–ª—É

**–ó–∞–≥–∞–ª—å–Ω–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ —Ä–æ–∑–¥—ñ–ª—É:**
–ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ –æ–∑–Ω–∞–∫–∏ - —Ü–µ **—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó** (–¥–æ—Å—è–≥–Ω—É—Ç–∞ –ø–æ–∑–∏—Ü—ñ—è, –µ–Ω–µ—Ä–≥—ñ—è, –Ω–∞–ø—Ä—è–º–æ–∫), –∞ –Ω–µ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞–Ω. –¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ —É—Å–ø—ñ—Ö –≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è **–ø–æ–≤–µ–¥—ñ–Ω–∫–æ—é –∞–≥–µ–Ω—Ç–∞**, –∞ –Ω–µ —Å—Ç–∞—Ä—Ç–æ–≤–∏–º–∏ —É–º–æ–≤–∞–º–∏.

---

### 1.3 –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
![–ö–æ—Ä–µ–ª—è—Ü—ñ—è –æ–∑–Ω–∞–∫](plots/correlation_matrix.png)

**–í–∏—Å–Ω–æ–≤–∫–∏:**

**–°–∏–ª—å–Ω—ñ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑ success:**
- `max_position_reached` (–Ω–∞–π—Å–∏–ª—å–Ω—ñ—à–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è ~0.95)
- `energy_max` (—Å–∏–ª—å–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è)
- `positive_velocity_ratio` (–ø–æ–º—ñ—Ä–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è)
- `velocity_abs_mean` (—Å–ª–∞–±–∫–∞-–ø–æ–º—ñ—Ä–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è)

**–ú—ñ–∂–æ–∑–Ω–∞–∫–æ–≤—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó:**
- `position_range` ‚Üî `max_position_reached`: —Å–∏–ª—å–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è (~0.8-0.9)
  - –õ–æ–≥—ñ—á–Ω–æ: –±—ñ–ª—å—à–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω —Ä—É—Ö—É ‚Üí –≤–∏—â–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –ø–æ–∑–∏—Ü—ñ—è
- `velocity_abs_mean` ‚Üî `high_velocity_ratio`: –ø–æ–º—ñ—Ä–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è
  - –í–∏—â—ñ —à–≤–∏–¥–∫–æ—Å—Ç—ñ –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ –±—ñ–ª—å—à–æ—é —á–∞—Å—Ç–∫–æ—é –≤–∏—Å–æ–∫–∏—Ö —à–≤–∏–¥–∫–æ—Å—Ç–µ–π
- `initial_position` ‚Üî `initial_velocity`: –ø—Ä–∞–∫—Ç–∏—á–Ω–æ –Ω–µ–º–∞—î –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
  - –ü–æ—á–∞—Ç–∫–æ–≤—ñ —É–º–æ–≤–∏ –Ω–µ–∑–∞–ª–µ–∂–Ω—ñ (–≤–∏–ø–∞–¥–∫–æ–≤–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞)

**–†–µ–¥—É–Ω–¥–∞–Ω—Ç–Ω—ñ—Å—Ç—å –æ–∑–Ω–∞–∫:**
- –î–µ—è–∫—ñ –æ–∑–Ω–∞–∫–∏ —Å–∏–ª—å–Ω–æ –∫–æ—Ä–µ–ª—é—é—Ç—å –º—ñ–∂ —Å–æ–±–æ—é (multicollinearity)
- –î–ª—è –ª—ñ–Ω—ñ–π–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (LDA, Logistic Regression) —Ü–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º–æ—é
- Tree-based –º–æ–¥–µ–ª—ñ (Random Forest, Gradient Boosting) —Å—Ç—ñ–π–∫—ñ –¥–æ –º—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω–æ—Å—Ç—ñ

**–ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
1. –î–ª—è LDA/Logistic Regression - —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ PCA –∞–±–æ –≤—ñ–¥–±—ñ—Ä –æ–∑–Ω–∞–∫
2. –î–ª—è Random Forest/Gradient Boosting - –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –≤—Å—ñ –æ–∑–Ω–∞–∫–∏
3. Feature engineering –±—É–≤ —É—Å–ø—ñ—à–Ω–∏–º - —Å—Ç–≤–æ—Ä–µ–Ω—ñ –æ–∑–Ω–∞–∫–∏ –º–∞—é—Ç—å —Å–∏–ª—å–Ω—ñ –∑–≤'—è–∑–∫–∏ –∑ —Ü—ñ–ª—å–æ–≤–æ—é –∑–º—ñ–Ω–Ω–æ—é

---

## 2. –Ü–Ω–∂–µ–Ω–µ—Ä—ñ—è —Ç–∞ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫

### 2.1 –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (Random Forest)
![Feature Importance](plots/feature_importance.png)

**–¢–æ–ø-5 –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏—Ö –æ–∑–Ω–∞–∫:**

1. **max_position_reached / rightmost_position** (~0.25-0.30)
   - –î–æ–º—ñ–Ω—É—é—á–∞ –æ–∑–Ω–∞–∫–∞
   - –§—ñ–∑–∏—á–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è: —è–∫—â–æ –∞–≥–µ–Ω—Ç –¥—ñ—Å—Ç–∞–≤—Å—è –¥–æ –ø–æ–∑–∏—Ü—ñ—ó 0.5, –≤—ñ–Ω —É—Å–ø—ñ—à–Ω–∏–π –∑–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º
   - **–Ü–Ω—Å–∞–π—Ç:** —Ü—è –æ–∑–Ω–∞–∫–∞ –º–∞–π–∂–µ —ñ–¥–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç

2. **positive_velocity_ratio** (~0.10-0.15)
   - –ß–∞—Å—Ç–∫–∞ —Ä—É—Ö—É –≤–ø—Ä–∞–≤–æ (–¥–æ –º–µ—Ç–∏)
   - –£—Å–ø—ñ—à–Ω—ñ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –º–∞–∫—Å–∏–º—ñ–∑—É—é—Ç—å —Ä—É—Ö –≤ –ø–æ—Ç—Ä—ñ–±–Ω–æ–º—É –Ω–∞–ø—Ä—è–º–∫—É
   - **–Ü–Ω—Å–∞–π—Ç:** –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ –∞–≥–µ–Ω—Ç–∏ –Ω–µ "—Ä–æ–∑–≥–æ–π–¥—É—é—Ç—å—Å—è" –±–µ–∑—Ü—ñ–ª—å–Ω–æ

3. **velocity_abs_mean** (~0.08-0.12)
   - –°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å
   - –ë—ñ–ª—å—à–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å ‚Üí –±—ñ–ª—å—à–∞ –∫—ñ–Ω–µ—Ç–∏—á–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è ‚Üí –∫—Ä–∞—â–µ –ø–æ–¥–æ–ª–∞–Ω–Ω—è —Å—Ö–∏–ª—É
   - **–Ü–Ω—Å–∞–π—Ç:** –∞–≥—Ä–µ—Å–∏–≤–Ω—ñ –¥—ñ—ó –∫—Ä–∞—â–µ –∑–∞ –ø–∞—Å–∏–≤–Ω—ñ—Å—Ç—å

4. **energy_max** (~0.06-0.10)
   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –ø–æ–≤–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è (–ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª—å–Ω–∞ + –∫—ñ–Ω–µ—Ç–∏—á–Ω–∞)
   - –§—ñ–∑–∏—á–Ω–∏–π –∑–∞–∫–æ–Ω: –ø–æ—Ç—Ä—ñ–±–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è –¥–ª—è –ø–æ–¥–æ–ª–∞–Ω–Ω—è –ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª—å–Ω–æ–≥–æ –±–∞—Ä'—î—Ä—É
   - **–Ü–Ω—Å–∞–π—Ç:** –µ–Ω–µ—Ä–≥–µ—Ç–∏—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–æ –∞–Ω–∞–ª—ñ–∑—É RL –∑–∞–¥–∞—á –º–∞—î —Å–µ–Ω—Å

5. **high_velocity_ratio** (~0.05-0.08)
   - –ß–∞—Å—Ç–∫–∞ –∫—Ä–æ–∫—ñ–≤ –∑ –≤–∏—Å–æ–∫–æ—é —à–≤–∏–¥–∫—ñ—Å—Ç—é
   - –ü–æ–≤'—è–∑–∞–Ω–æ –∑ –∞–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—é —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó
   - **–Ü–Ω—Å–∞–π—Ç:** –ø–æ—Ç—Ä—ñ–±–Ω—ñ —Å–ø–ª–µ—Å–∫–∏ –≤–∏—Å–æ–∫–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ, –∞ –Ω–µ –ø–æ—Å—Ç—ñ–π–Ω–∞ –ø–æ–º—ñ—Ä–Ω–∞

**–ù–∞–π–º–µ–Ω—à –≤–∞–∂–ª–∏–≤—ñ –æ–∑–Ω–∞–∫–∏:**
- `initial_position`, `initial_velocity` (< 0.02)
- **–ü—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è:** –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞–Ω –º–∞–π–∂–µ –Ω–µ –≤–ø–ª–∏–≤–∞—î –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –∑–∞–¥–∞—á–∞ MountainCar –º–∞—î –≤–ª–∞—Å—Ç–∏–≤—ñ—Å—Ç—å **Markov property**: –º–∞–π–±—É—Ç–Ω—î –Ω–µ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –¥–∞–ª–µ–∫–æ–≥–æ –º–∏–Ω—É–ª–æ–≥–æ

**–Ü–Ω–∂–µ–Ω–µ—Ä—ñ—è –æ–∑–Ω–∞–∫ - —É—Å–ø—ñ—Ö:**
‚úÖ –°—Ç–≤–æ—Ä–µ–Ω—ñ –æ–∑–Ω–∞–∫–∏ (energy_max, positive_velocity_ratio) —Å–µ—Ä–µ–¥ —Ç–æ–ø-5  
‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –≤–∏—è–≤–∏–ª–∏—Å—å –≤–∞–∂–ª–∏–≤—ñ—à–∏–º–∏ –∑–∞ raw states  
‚úÖ –ê–≥—Ä–µ–≥–∞—Ü—ñ—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø–æ –µ–ø—ñ–∑–æ–¥—É –¥–∞–ª–∞ –∫—Ä–∞—â–µ —Ä–æ–∑—É–º—ñ–Ω–Ω—è –¥–∏–Ω–∞–º—ñ–∫–∏  

**–ú–æ–∂–ª–∏–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:**
- –î–æ–¥–∞—Ç–∏ –æ–∑–Ω–∞–∫–∏ –∑ —Ñ—ñ–∑–∏–∫–∏: —Å–µ—Ä–µ–¥–Ω—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è, —à–≤–∏–¥–∫—ñ—Å—Ç—å –∑–º—ñ–Ω–∏ –µ–Ω–µ—Ä–≥—ñ—ó
- –¢–µ–º–ø–æ—Ä–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏: —è–∫ —à–≤–∏–¥–∫–æ –¥–æ—Å—è–≥–∞—î—Ç—å—Å—è max_position
- –ü–∞—Ç—Ç–µ—Ä–Ω–∏ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ—Å—Ü–∏–ª—è—Ü—ñ–π

---

## 3. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó

### 3.1 –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤
![–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤](plots/classifiers_comparison.png)

**–†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∑–∞ ROC-AUC:**

**–õ—ñ–¥–µ—Ä–∏ (ROC-AUC > 0.95):**
1. **Gradient Boosting** - –Ω–∞–π–∫—Ä–∞—â–∏–π (AUC ~0.98)
   - –ü–µ—Ä–µ–≤–∞–≥–∏: ensemble –º–µ—Ç–æ–¥, —ñ—Ç–µ—Ä–∞—Ç–∏–≤–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è
   - –ó–∞—Ö–æ–ø–ª—é—î —Å–∫–ª–∞–¥–Ω—ñ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó
   - –°—Ç—ñ–π–∫–∏–π –¥–æ multicollinearity

2. **Random Forest** - –¥—Ä—É–≥–∏–π (AUC ~0.97)
   - –ü–µ—Ä–µ–≤–∞–≥–∏: robust, –Ω–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞—î—Ç—å—Å—è, –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–æ–≤–∞–Ω–∏–π
   - Feature importance "–±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ"
   - –ü—Ä–∞—Ü—é—î –∑ –±—É–¥—å-—è–∫–∏–º–∏ –æ–∑–Ω–∞–∫–∞–º–∏

3. **RBF SVM** - —Ç—Ä–µ—Ç—ñ–π (AUC ~0.95)
   - –ü–µ—Ä–µ–≤–∞–≥–∏: kernel trick –¥–æ–∑–≤–æ–ª—è—î –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ boundaries
   - –°—Ç—ñ–π–∫–∏–π –¥–æ outliers
   - –ü—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö decision boundaries

**–°–µ—Ä–µ–¥–Ω—è–∫–∏ (ROC-AUC 0.90-0.95):**
4. **Logistic Regression** (AUC ~0.93)
   - –®–≤–∏–¥–∫–∏–π, —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–∏–π
   - –õ—ñ–Ω—ñ–π–Ω–∞ –º–æ–¥–µ–ª—å, –∞–ª–µ –ø—Ä–∞—Ü—é—î –∑–∞–≤–¥—è–∫–∏ –ª—ñ–Ω—ñ–π–Ω—ñ–π —Ä–æ–∑–¥—ñ–ª—é–≤–∞–Ω–æ—Å—Ç—ñ

5. **Linear SVM** (AUC ~0.92)
   - –°—Ö–æ–∂–∏–π –Ω–∞ Logistic Regression
   - Maximum-margin classifier

**–ê—É—Ç—Å–∞–π–¥–µ—Ä–∏ (ROC-AUC < 0.90):**
6. **LDA** (AUC ~0.88)
   - –ü—Ä–∏–ø—É—â–µ–Ω–Ω—è –ø—Ä–æ Gaussian —Ä–æ–∑–ø–æ–¥—ñ–ª–∏ –ø–æ—Ä—É—à–µ–Ω—ñ
   - –ú—É–ª—å—Ç–∏–∫–æ–ª—ñ–Ω–µ–∞—Ä–Ω—ñ—Å—Ç—å –≤–ø–ª–∏–≤–∞—î –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ

7. **Naive Bayes** (AUC ~0.85)
   - –ü—Ä–∏–ø—É—â–µ–Ω–Ω—è –ø—Ä–æ –Ω–µ–∑–∞–ª–µ–∂–Ω—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—É—à–µ–Ω–µ
   - –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –ø–æ–∫–∞–∑–∞–ª–∞ –±–∞–≥–∞—Ç–æ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π

**–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö:**

**Accuracy (0.90-0.95 –¥–ª—è –≤—Å—ñ—Ö):**
- –í—Å—ñ –º–æ–¥–µ–ª—ñ –¥–æ–±—Ä–µ –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—é—Ç—å
- –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–æ–∑–≤–æ–ª—è—î –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ accuracy

**Balanced Accuracy (0.88-0.94):**
- –°—Ö–æ–∂–∞ –¥–æ accuracy - –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –±–∞–ª–∞–Ω—Å—É –∫–ª–∞—Å—ñ–≤
- Gradient Boosting –ª—ñ–¥–∏—Ä—É—î (0.94)

**Precision (0.88-0.95):**
- Gradient Boosting: ~0.95 - –Ω–∞–π–º–µ–Ω—à–µ false positives
- Naive Bayes: ~0.88 - –±—ñ–ª—å—à–µ –ø–æ–º–∏–ª–æ–∫

**Recall (0.85-0.93):**
- Random Forest: ~0.93 - –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –±—ñ–ª—å—à—ñ—Å—Ç—å —É—Å–ø—ñ—à–Ω–∏—Ö –µ–ø—ñ–∑–æ–¥—ñ–≤
- LDA: ~0.85 - –ø—Ä–æ–ø—É—Å–∫–∞—î –±—ñ–ª—å—à–µ —É—Å–ø—ñ—à–Ω–∏—Ö

**F1-Score (0.87-0.93):**
- –ë–∞–ª–∞–Ω—Å precision/recall
- Gradient Boosting –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π

**–ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
- **–î–ª—è production:** Gradient Boosting –∞–±–æ Random Forest
- **–î–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø—É–≤–∞–Ω–Ω—è:** Logistic Regression
- **–î–ª—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—ó:** Linear SVM –∞–±–æ Logistic Regression
- **–£–Ω–∏–∫–∞—Ç–∏:** Naive Bayes (–ø–æ—Ä—É—à–µ–Ω—ñ –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è)

---

### 3.2 ROC-–∫—Ä–∏–≤—ñ
![ROC-–∫—Ä–∏–≤—ñ](plots/roc_curves_all.png)

**–ê–Ω–∞–ª—ñ–∑ –∫—Ä–∏–≤–∏—Ö:**

**Gradient Boosting (—Ç–µ–º–Ω–æ-—Å–∏–Ω—ñ–π):**
- –ö—Ä–∏–≤–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∞–±–ª–∏–∂–µ–Ω–∞ –¥–æ –ª—ñ–≤–æ–≥–æ –≤–µ—Ä—Ö–Ω—å–æ–≥–æ –∫—É—Ç–∞
- –ü–ª–æ—â–∞ –ø—ñ–¥ –∫—Ä–∏–≤–æ—é (AUC) ~0.98 - –º–∞–π–∂–µ —ñ–¥–µ–∞–ª—å–Ω–æ
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:** –º–æ–¥–µ–ª—å –¥–æ—Å—è–≥–∞—î –≤–∏—Å–æ–∫–æ–≥–æ TPR –ø—Ä–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ–º—É FPR
- –ü—Ä–∏ –ø–æ—Ä–æ–∑—ñ 0.5: ~95% sensitivity –ø—Ä–∏ ~5% false positive rate

**Random Forest (–æ—Ä–∞–Ω–∂–µ–≤–∏–π):**
- –î—É–∂–µ –±–ª–∏–∑—å–∫–æ –¥–æ Gradient Boosting
- AUC ~0.97 - –≤—ñ–¥–º—ñ–Ω–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- –¢—Ä–æ—Ö–∏ –±—ñ–ª—å—à–µ trade-off –º—ñ–∂ TPR —ñ FPR –≤ —Å–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å—Ç–∏–Ω—ñ

**RBF SVM (–∑–µ–ª–µ–Ω–∏–π):**
- AUC ~0.95 - –≤—Å–µ —â–µ –≤—ñ–¥–º—ñ–Ω–Ω–æ
- –ö—Ä–∏–≤–∞ —Ç—Ä–æ—Ö–∏ –Ω–∏–∂—á–µ tree-based –º–µ—Ç–æ–¥—ñ–≤
- Kernel trick –ø—Ä–∞—Ü—é—î –¥–æ–±—Ä–µ –¥–ª—è —Ü—ñ—î—ó –∑–∞–¥–∞—á—ñ

**–õ—ñ–Ω—ñ–π–Ω—ñ –º–µ—Ç–æ–¥–∏ (Logistic, Linear SVM):**
- AUC 0.92-0.93 - –¥–æ–±—Ä–µ
- –õ—ñ–Ω—ñ–π–Ω–∞ separability –ø—Ä–∏—Å—É—Ç–Ω—è
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∫–æ–º–ø–µ–Ω—Å—É—î—Ç—å—Å—è –Ω–µ–≤–µ–ª–∏–∫–æ—é –≤—Ç—Ä–∞—Ç–æ—é —è–∫–æ—Å—Ç—ñ

**LDA (—Ä–æ–∂–µ–≤–∏–π):**
- AUC ~0.88 - –ø—Ä–∏–π–Ω—è—Ç–Ω–æ
- –ì–∞—É—Å—ñ–≤—Å—å–∫—ñ –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è —á–∞—Å—Ç–∫–æ–≤–æ –ø–æ—Ä—É—à–µ–Ω—ñ
- –ö—Ä–∏–≤–∞ –ø–æ–∫–∞–∑—É—î trade-off –Ω–∞ –≤—Å—å–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ –ø–æ—Ä–æ–≥—ñ–≤

**Naive Bayes (–∫–æ—Ä–∏—á–Ω–µ–≤–∏–π):**
- AUC ~0.85 - –Ω–∞–π–≥—ñ—Ä—à–∏–π, –∞–ª–µ –≤—Å–µ —â–µ –∑–Ω–∞—á–Ω–æ –∫—Ä–∞—â–∏–π –∑–∞ random (0.5)
- –ü—Ä–∏–ø—É—â–µ–Ω–Ω—è –Ω–µ–∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—É—à–µ–Ω—ñ
- –ö—Ä–∏–≤–∞ –Ω–∞–π–±–ª–∏–∂—á–∞ –¥–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ

**–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ –≤–∏–ø–∞–¥–∫–æ–≤–∏–º –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–æ–º:**
- –î—ñ–∞–≥–æ–Ω–∞–ª—å (AUC = 0.5) - baseline
- –í—Å—ñ –º–æ–¥–µ–ª—ñ **–∑–Ω–∞—á–Ω–æ** –∫—Ä–∞—â—ñ –∑–∞ –≤–∏–ø–∞–¥–∫–æ–≤–µ –≥–∞–¥–∞–Ω–Ω—è
- –ù–∞–≤—ñ—Ç—å Naive Bayes –Ω–∞ 70% –∫—Ä–∞—â–∏–π –∑–∞ random

**–í–∏–±—ñ—Ä –ø–æ—Ä–æ–≥–∞:**
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –ø–æ—Ä—ñ–≥ 0.5 –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –¥–ª—è –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É
- –î–ª—è —Ä—ñ–∑–Ω–∏—Ö –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω—å –º–æ–∂–Ω–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏:
  - –í–∏—Å–æ–∫–∏–π recall (–∑–Ω–∞–π—Ç–∏ –≤—Å—ñ —É—Å–ø—ñ—à–Ω—ñ) ‚Üí –∑–Ω–∏–∑–∏—Ç–∏ –ø–æ—Ä—ñ–≥
  - –í–∏—Å–æ–∫–∞ precision (–º—ñ–Ω—ñ–º—É–º false alarms) ‚Üí –ø—ñ–¥–≤–∏—â–∏—Ç–∏ –ø–æ—Ä—ñ–≥
- ROC-–∫—Ä–∏–≤–∞ –¥–æ–∑–≤–æ–ª—è—î –≤–∏–±—Ä–∞—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π trade-off

**–ó–∞–≥–∞–ª—å–Ω–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫:**
Tree-based –∞–Ω—Å–∞–º–±–ª—ñ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—é—Ç—å –Ω–∞–π–∫—Ä–∞—â—É —è–∫—ñ—Å—Ç—å –∑–∞–≤–¥—è–∫–∏ –∑–¥–∞—Ç–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—é–≤–∞—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ –Ω–µ–ª—ñ–Ω—ñ–π–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó –º—ñ–∂ –æ–∑–Ω–∞–∫–∞–º–∏ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó.

---

### 3.3 –ú–∞—Ç—Ä–∏—Ü—ñ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–µ–π
![Confusion Matrices](plots/confusion_matrices_all.png)

**–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø–æ–º–∏–ª–æ–∫:**

**Gradient Boosting:**
```
              Predicted
           –ù–µ–≤–¥–∞—á–∞  –£—Å–ø—ñ—Ö
Actual     
–ù–µ–≤–¥–∞—á–∞      TN      FP (–º–∞–ª–æ)
–£—Å–ø—ñ—Ö        FN      TP (–±–∞–≥–∞—Ç–æ)
```
- **True Negatives:** –≤–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –Ω–µ–≤–¥–∞—á
- **True Positives:** –≤–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —É—Å–ø—ñ—Ö—ñ–≤
- **False Positives:** –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ (~3-5%)
- **False Negatives:** –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ (~5-7%)
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–º–∏ –ø–æ–º–∏–ª–∫–∞–º–∏ –æ–±–æ—Ö —Ç–∏–ø—ñ–≤

**Random Forest:**
- –°—Ö–æ–∂–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–æ Gradient Boosting
- –¢—Ä–æ—Ö–∏ –±—ñ–ª—å—à–µ FN (–ø—Ä–æ–ø—É—â–µ–Ω—ñ —É—Å–ø—ñ—Ö–∏)
- –î—É–∂–µ –º–∞–ª–æ FP
- **Trade-off:** –≤–∏—Å–æ–∫–∞ precision, —Ç—Ä–æ—Ö–∏ –Ω–∏–∂—á–∏–π recall

**RBF SVM:**
- –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –ø–æ–º–∏–ª–∫–∏
- FP —ñ FN –ø—Ä–∏–±–ª–∏–∑–Ω–æ —Ä—ñ–≤–Ω—ñ
- –î–æ–±—Ä–∏–π –±–∞–ª–∞–Ω—Å –¥–ª—è —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è

**Linear Models (Logistic, Linear SVM):**
- –ë—ñ–ª—å—à–µ –ø–æ–º–∏–ª–æ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ tree-based
- FP —ñ FN –∑–±—ñ–ª—å—à—É—é—Ç—å—Å—è –¥–æ ~10-12%
- –í—Å–µ —â–µ –ø—Ä–∏–π–Ω—è—Ç–Ω—ñ –¥–ª—è –±–∞–≥–∞—Ç—å–æ—Ö –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω—å

**LDA:**
- –ü–æ–º—ñ—Ç–Ω–æ –±—ñ–ª—å—à–µ FN (~15%)
- –°—Ö–∏–ª—å–Ω—ñ—Å—Ç—å –¥–æ underprediction —É—Å–ø—ñ—Ö—ñ–≤
- –ú–æ–∂–µ –±—É—Ç–∏ –∫–æ–º–ø–µ–Ω—Å–æ–≤–∞–Ω–æ –∑–Ω–∏–∂–µ–Ω–Ω—è–º –ø–æ—Ä–æ–≥–∞

**Naive Bayes:**
- –ù–∞–π–±—ñ–ª—å—à–µ –ø–æ–º–∏–ª–æ–∫ (~20% FN, ~15% FP)
- –ù–µ—Å–∏–º–µ—Ç—Ä–∏—á–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ–º–∏–ª–æ–∫
- –ü—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –Ω–µ–ø—Ä–∏–¥–∞—Ç–Ω–æ—Å—Ç—ñ –¥–ª—è —Ü—ñ—î—ó –∑–∞–¥–∞—á—ñ

**–¢–∏–ø–∏ –ø–æ–º–∏–ª–æ–∫ —Ç–∞ —ó—Ö –Ω–∞—Å–ª—ñ–¥–∫–∏:**

**False Positives (–ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ —É—Å–ø—ñ—Ö, –∞–ª–µ –±—É–ª–∞ –Ω–µ–≤–¥–∞—á–∞):**
- –ú–µ–Ω—à –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
- –í –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–º—É RL: –∞–≥–µ–Ω—Ç —Å–ø—Ä–æ–±—É—î "–Ω–µ–≤–¥–∞–ª—É" —Å—Ç—Ä–∞—Ç–µ–≥—ñ—é
- –®–≤–∏–¥–∫–æ –≤–∏—è–≤–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ feedback

**False Negatives (–ø–µ—Ä–µ–¥–±–∞—á–∏–ª–∏ –Ω–µ–≤–¥–∞—á—É, –∞–ª–µ –±—É–≤ —É—Å–ø—ñ—Ö):**
- –ë—ñ–ª—å—à –∫—Ä–∏—Ç–∏—á–Ω–æ
- –ü—Ä–æ–ø—É—Å–∫ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ —Ö–æ—Ä–æ—à–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π
- –í RL: –Ω–µ–¥–æ–æ—Ü—ñ–Ω–∫–∞ promising policies

**–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ:**
- –Ø–∫—â–æ –≤–∞–∂–ª–∏–≤–æ –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —É—Å–ø—ñ—Ö–∏ ‚Üí Random Forest (–≤–∏—Å–æ–∫–∏–π recall)
- –Ø–∫—â–æ –≤–∞–∂–ª–∏–≤–æ —É–Ω–∏–∫–Ω—É—Ç–∏ false alarms ‚Üí Gradient Boosting (–≤–∏—Å–æ–∫–∞ precision)
- –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–µ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è ‚Üí Gradient Boosting (–±–∞–ª–∞–Ω—Å)

---

## 4. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å

### 4.1 –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–ª—é—á–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
![–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π](plots/strategy_comparison.png)

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞ Success Rate:**

1. **Q-Learning (bins=20)** - ~85-90%
   - –ù–∞–π–∫—Ä–∞—â–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –ø—ñ—Å–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
   - –ù–∞–≤—á–∏–ª–∞—Å—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ–π –ø–æ–ª—ñ—Ç–∏—Ü—ñ –∑ –¥–æ—Å–≤—ñ–¥—É
   - –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—è 20x20 –≤–∏—è–≤–∏–ª–∞—Å—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—é

2. **–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è (–ø–æ–∑–∏—Ü—ñ—è + —à–≤–∏–¥–∫—ñ—Å—Ç—å)** - ~35-45%
   - –ù–∞–π–∫—Ä–∞—â–∞ –µ–≤—Ä–∏—Å—Ç–∏—á–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è
   - –í—Ä–∞—Ö–æ–≤—É—î —ñ –ø–æ–∑–∏—Ü—ñ—é, —ñ —à–≤–∏–¥–∫—ñ—Å—Ç—å
   - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —Ç–µ—Ö–Ω—ñ–∫—É —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è

3. **Epsilon-Greedy (Œµ=0.2)** - ~25-35%
   - –ë–∞–ª–∞–Ω—Å exploration/exploitation
   - –í–∏–ø–∞–¥–∫–æ–≤—ñ –¥—ñ—ó —ñ–Ω–æ–¥—ñ –¥–æ–ø–æ–º–∞–≥–∞—é—Ç—å
   - 20% exploration –¥–æ—Å—Ç–∞—Ç–Ω—å–æ

4. **–°—Ç—Ä–∞—Ç–µ–≥—ñ—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —à–≤–∏–¥–∫–æ—Å—Ç—ñ** - ~15-25%
   - –ü—Ä–æ—Å—Ç–∞ –µ–≤—Ä–∏—Å—Ç–∏–∫–∞
   - –ü—Ä–∞—Ü—é—î, –∞–ª–µ —Å—É–±–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞
   - –ù–µ –≤—Ä–∞—Ö–æ–≤—É—î –ø–æ–∑–∏—Ü—ñ—é

5. **–í–∏–ø–∞–¥–∫–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è** - ~1-2%
   - Baseline
   - –ü–æ–∫–∞–∑—É—î —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–¥–∞—á—ñ
   - –ë–µ–∑ —Ä–æ–∑—É–º–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó —É—Å–ø—ñ—Ö –º–∞–π–∂–µ –Ω–µ–º–æ–∂–ª–∏–≤–∏–π

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞ Average Reward:**

**Q-Learning:** ~-110 –¥–æ -120
- –ù–∞–π–≤–∏—â–∞ —Å–µ—Ä–µ–¥–Ω—è –Ω–∞–≥–æ—Ä–æ–¥–∞
- –®–≤–∏–¥—à–µ –¥–æ—Å—è–≥–∞—î –º–µ—Ç–∏ (–º–µ–Ω—à–µ —à—Ç—Ä–∞—Ñ—ñ–≤ –∑–∞ –∫—Ä–æ–∫–∏)
- –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –ø–æ–ª—ñ—Ç–∏–∫–∞ –º—ñ–Ω—ñ–º—ñ–∑—É—î –∫—Ä–æ–∫–∏

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:** ~-140 –¥–æ -150
- –î—Ä—É–≥–∞ –∑–∞ –Ω–∞–≥–æ—Ä–æ–¥–æ—é
- –ë—ñ–ª—å—à–µ –∫—Ä–æ–∫—ñ–≤, –∞–ª–µ —á–∞—Å—Ç–æ —É—Å–ø—ñ—à–Ω–∞

**Epsilon-Greedy:** ~-150 –¥–æ -160
- Exploration –¥–æ–¥–∞—î extra –∫—Ä–æ–∫–∏
- Trade-off –∑–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—É robustness

**Velocity-based:** ~-160 –¥–æ -170
- –ù–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è
- –ë–∞–≥–∞—Ç–æ –Ω–µ–≤–¥–∞–ª–∏—Ö —Å–ø—Ä–æ–±

**–í–∏–ø–∞–¥–∫–æ–≤–∞:** ~-190 –¥–æ -200
- –ú–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ –¥–æ—Å—è–≥–∞—î max_steps=200
- –ü—Ä–∞–∫—Ç–∏—á–Ω–æ –Ω–µ –¥–æ—Å—è–≥–∞—î –º–µ—Ç–∏

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞ Average Steps:**

**Q-Learning:** ~110-120 –∫—Ä–æ–∫—ñ–≤
- –ù–∞–π–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è
- –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –±–∞–ª–∞–Ω—Å —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è/–ø—ñ–¥–π–æ–º—É

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:** ~140-150 –∫—Ä–æ–∫—ñ–≤
- –î–æ–≤—à–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è
- –ë—ñ–ª—å—à–µ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω—å –¥–ª—è –Ω–∞–±–æ—Ä—É —ñ–Ω–µ—Ä—Ü—ñ—ó

**Epsilon-Greedy:** ~150-160 –∫—Ä–æ–∫—ñ–≤
- –í–∏–ø–∞–¥–∫–æ–≤—ñ –¥—ñ—ó –ø–æ–¥–æ–≤–∂—É—é—Ç—å –µ–ø—ñ–∑–æ–¥

**Velocity-based:** ~170-180 –∫—Ä–æ–∫—ñ–≤
- –ù–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è
- –ë–∞–≥–∞—Ç–æ –∑–∞–π–≤–∏—Ö —Ä—É—Ö—ñ–≤

**–í–∏–ø–∞–¥–∫–æ–≤–∞:** ~195-200 –∫—Ä–æ–∫—ñ–≤
- –ü—Ä–∞–∫—Ç–∏—á–Ω–æ –∑–∞–≤–∂–¥–∏ timeout

**–ö–ª—é—á–æ–≤—ñ —ñ–Ω—Å–∞–π—Ç–∏:**

1. **Q-Learning >> –ï–≤—Ä–∏—Å—Ç–∏–∫–∏**
   - 2-3x –∫—Ä–∞—â–∏–π success rate
   - –ë—ñ–ª—å—à –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó
   - –î–æ–≤–µ–¥–µ–Ω–∞ –ø–µ—Ä–µ–≤–∞–≥–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –¥–æ—Å–≤—ñ–¥—É

2. **–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–¥–∞—á—ñ**
   - 1-2% –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —É—Å–ø—ñ—Ö –ø–æ–∫–∞–∑—É—î –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ—Å—Ç—å —Ä–æ–∑—É–º–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó
   - –ù–µ–º–æ–∂–ª–∏–≤–æ "–≤–∏–ø–∞–¥–∫–æ–≤–æ" –≤–∏—Ä—ñ—à–∏—Ç–∏ MountainCar

3. **Value of exploration**
   - Epsilon-Greedy –ø—Ä–∞—Ü—é—î –∫—Ä–∞—â–µ –∑–∞ —á–∏—Å—Ç—É Velocity
   - –í–∏–ø–∞–¥–∫–æ–≤—ñ—Å—Ç—å –¥–æ–ø–æ–º–∞–≥–∞—î —É–Ω–∏–∫–∞—Ç–∏ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –æ–ø—Ç–∏–º—É–º—ñ–≤

4. **–Ü–Ω–∂–µ–Ω–µ—Ä—ñ—è –µ–≤—Ä–∏—Å—Ç–∏–∫**
   - –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –≤ 2x –∫—Ä–∞—â–∞ –∑–∞ –ø—Ä–æ—Å—Ç—É Velocity
   - Domain knowledge –º–∞—î –∑–Ω–∞—á–µ–Ω–Ω—è

5. **–ù–∞–≤—á–∞–Ω–Ω—è vs –ï–≤—Ä–∏—Å—Ç–∏–∫–∏**
   - Q-Learning –ø–æ—Ç—Ä–µ–±—É—î 1000 –µ–ø—ñ–∑–æ–¥—ñ–≤ –Ω–∞–≤—á–∞–Ω–Ω—è
   - –ï–≤—Ä–∏—Å—Ç–∏–∫–∏ –ø—Ä–∞—Ü—é—é—Ç—å –æ–¥—Ä–∞–∑—É, –∞–ª–µ –≥—ñ—Ä—à–µ
   - Trade-off: —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è vs —è–∫—ñ—Å—Ç—å

---

### 4.2 –†–æ–∑–ø–æ–¥—ñ–ª –Ω–∞–≥–æ—Ä–æ–¥
![–†–æ–∑–ø–æ–¥—ñ–ª –Ω–∞–≥–æ—Ä–æ–¥](plots/reward_distributions.png)

**–ê–Ω–∞–ª—ñ–∑ box plots:**

**Q-Learning:**
- **Median:** ~-110
- **IQR (25-75%):** –≤—É–∑—å–∫–∏–π (~-105 –¥–æ -115)
- **–í–∏–∫–∏–¥–∏:** –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** —Å—Ç–∞–±—ñ–ª—å–Ω–∞, –ø–µ—Ä–µ–¥–±–∞—á—É–≤–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:**
- **Median:** ~-140
- **IQR:** —à–∏—Ä—à–∏–π (~-120 –¥–æ -160)
- **–í–∏–∫–∏–¥–∏:** –ø—Ä–∏—Å—É—Ç–Ω—ñ –¥–æ -200
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –±—ñ–ª—å—à–∞ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å, —ñ–Ω–æ–¥—ñ –Ω–µ–≤–¥–∞—á—ñ

**Epsilon-Greedy:**
- **Median:** ~-155
- **IQR:** —à–∏—Ä–æ–∫–∏–π (~-130 –¥–æ -180)
- **–í–∏–∫–∏–¥–∏:** –±–∞–≥–∞—Ç–æ –¥–æ -200
- **–í–∏—Å–Ω–æ–≤–æ–∫:** exploration –¥–æ–¥–∞—î –Ω–µ–ø–µ—Ä–µ–¥–±–∞—á—É–≤–∞–Ω—ñ—Å—Ç—å

**Velocity-based:**
- **Median:** ~-165
- **IQR:** –¥—É–∂–µ —à–∏—Ä–æ–∫–∏–π (~-140 –¥–æ -195)
- **–í–∏–∫–∏–¥–∏:** —á–∏—Å–ª–µ–Ω–Ω—ñ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è

**–í–∏–ø–∞–¥–∫–æ–≤–∞:**
- **Median:** ~-200
- **IQR:** –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π (~-195 –¥–æ -200)
- **–í–∏–∫–∏–¥–∏:** –ø—Ä–∞–∫—Ç–∏—á–Ω–æ –Ω–µ–º–∞—î
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –ø–µ—Ä–µ–¥–±–∞—á—É–≤–∞–Ω–æ –ø–æ–≥–∞–Ω–∞

**Stability vs Performance:**
- Q-Learning: –≤–∏—Å–æ–∫–∞ performance + –≤–∏—Å–æ–∫–∞ stability ‚úÖ‚úÖ
- –ü–æ–∫—Ä–∞—â–µ–Ω–∞: —Å–µ—Ä–µ–¥–Ω—è performance + —Å–µ—Ä–µ–¥–Ω—è stability ‚úÖ
- Epsilon-Greedy: —Å–µ—Ä–µ–¥–Ω—è performance + –Ω–∏–∑—å–∫–∞ stability ‚ö†Ô∏è
- Velocity: –Ω–∏–∑—å–∫–∞ performance + –Ω–∏–∑—å–∫–∞ stability ‚ùå
- –í–∏–ø–∞–¥–∫–æ–≤–∞: –Ω–∞–π–≥—ñ—Ä—à–∞ performance + –≤–∏—Å–æ–∫–∞ stability (—Å—Ç–∞–±—ñ–ª—å–Ω–æ –ø–æ–≥–∞–Ω–∞) ‚ùå

**–ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏:**
- –î–ª—è production: Q-Learning (predictable + effective)
- –î–ª—è exploration: Epsilon-Greedy (unpredictable but sometimes lucky)
- –î–ª—è baseline: –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è (good middle ground)

---

### 4.3 –†–æ–∑–ø–æ–¥—ñ–ª –¥–æ–≤–∂–∏–Ω–∏ –µ–ø—ñ–∑–æ–¥—ñ–≤
![–î–æ–≤–∂–∏–Ω–∞ –µ–ø—ñ–∑–æ–¥—ñ–≤](plots/episode_lengths.png)

**–ê–Ω–∞–ª—ñ–∑ –≥—ñ—Å—Ç–æ–≥—Ä–∞–º:**

**Q-Learning (—Å–∏–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ):**
- **–†–æ–∑–ø–æ–¥—ñ–ª:** centered around 110-120 –∫—Ä–æ–∫—ñ–≤
- **Peak:** –≥–æ—Å—Ç—Ä–∏–π –ø—ñ–∫ –Ω–∞ 110-115
- **Spread:** –≤—É–∑—å–∫–∏–π (¬±10 –∫—Ä–æ–∫—ñ–≤)
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –¥—É–∂–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –µ–ø—ñ–∑–æ–¥—ñ–≤
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:** –Ω–∞–≤—á–µ–Ω–∞ –ø–æ–ª—ñ—Ç–∏–∫–∞ —Å—Ç–∞–±—ñ–ª—å–Ω–∞ —Ç–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è (–ø–æ–º–∞—Ä–∞–Ω—á–µ–≤—ñ):**
- **–†–æ–∑–ø–æ–¥—ñ–ª:** bimodal - –¥–≤–∞ –ø—ñ–∫–∏
  - –ü–µ—Ä—à–∏–π –ø—ñ–∫: ~130-140 (—É—Å–ø—ñ—à–Ω—ñ)
  - –î—Ä—É–≥–∏–π –ø—ñ–∫: ~180-200 (–Ω–µ–≤–¥–∞–ª—ñ, timeout)
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –∞–±–æ —à–≤–∏–¥–∫–æ —É—Å–ø—ñ—à–Ω–∞, –∞–±–æ –Ω–µ–≤–¥–∞—á–∞

**Epsilon-Greedy (–∑–µ–ª–µ–Ω—ñ):**
- **–†–æ–∑–ø–æ–¥—ñ–ª:** —à–∏—Ä–æ–∫–∏–π, —Ä–æ–∑–º–∏—Ç–∏–π
- **Span:** 100-200 –∫—Ä–æ–∫—ñ–≤
- **Peaks:** –º–µ–Ω—à –≤–∏—Ä–∞–∂–µ–Ω—ñ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –≤–∏—Å–æ–∫–µ variance —á–µ—Ä–µ–∑ exploration

**Velocity-based (—á–µ—Ä–≤–æ–Ω—ñ):**
- **–†–æ–∑–ø–æ–¥—ñ–ª:** heavy tail –¥–æ 200
- **Peak:** –±—ñ–ª—è 170-180
- **–í–∏—Å–Ω–æ–≤–æ–∫:** —á–∞—Å—Ç–æ –Ω–µ –≤–∏—Å—Ç–∞—á–∞—î —á–∞—Å—É

**–í–∏–ø–∞–¥–∫–æ–≤–∞ (—Ñ—ñ–æ–ª–µ—Ç–æ–≤—ñ):**
- **–†–æ–∑–ø–æ–¥—ñ–ª:** –ø—Ä–∞–∫—Ç–∏—á–Ω–æ –≤–µ—Å—å –≤–∞–≥–∞ –Ω–∞ 200
- **Peak:** sharp spike –Ω–∞ 200
- **–í–∏—Å–Ω–æ–≤–æ–∫:** –º–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ timeout

**Episode length —è–∫ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ:**
- **< 120:** excellent (—Ç—ñ–ª—å–∫–∏ Q-Learning)
- **120-150:** good (–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –ø—Ä–∏ —É—Å–ø—ñ—Ö—É)
- **150-180:** acceptable (Epsilon-Greedy, —ñ–Ω–æ–¥—ñ Velocity)
- **180-200:** poor (–Ω–µ–≤–¥–∞—á—ñ)
- **200:** failure (timeout)

**–ó–≤'—è–∑–æ–∫ –∑ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—î—é:**
`episode_length` –≤–∏—è–≤–∏–≤—Å—è –≤–∞–∂–ª–∏–≤–æ—é –æ–∑–Ω–∞–∫–æ—é:
- –£—Å–ø—ñ—à–Ω—ñ –µ–ø—ñ–∑–æ–¥–∏: 100-150 –∫—Ä–æ–∫—ñ–≤
- –ù–µ–≤–¥–∞–ª—ñ: 180-200 –∫—Ä–æ–∫—ñ–≤
- –ß—ñ—Ç–∫–µ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂—É—î –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—É —Å–∏–ª—É

---

## 5. –ê–Ω–∞–ª—ñ–∑ –Ω–∞–≤—á–∞–Ω–Ω—è Q-Learning

### 5.1 –ö—Ä–∏–≤–∞ –Ω–∞–≤—á–∞–Ω–Ω—è
![Q-Learning Learning Curve](plots/qlearning_learning_curve.png)

**–î–∏–Ω–∞–º—ñ–∫–∞ –Ω–∞–≥–æ—Ä–æ–¥–∏ (–ª—ñ–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫):**

**–§–∞–∑–∞ 1: –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è (–µ–ø—ñ–∑–æ–¥–∏ 1-200)**
- –ù–∞–≥–æ—Ä–æ–¥–∞: ~-200 (–º–∞–π–∂–µ —è–∫ –≤–∏–ø–∞–¥–∫–æ–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è)
- Q-—Ç–∞–±–ª–∏—Ü—è —â–µ –ø–æ—Ä–æ–∂–Ω—è
- Epsilon-greedy –¥—ñ—î –º–∞–π–∂–µ –≤–∏–ø–∞–¥–∫–æ–≤–æ
- **–í–∏—Å–Ω–æ–≤–æ–∫:** —Ö–æ–ª–æ–¥–Ω–∏–π —Å—Ç–∞—Ä—Ç, exploration phase

**–§–∞–∑–∞ 2: –®–≤–∏–¥–∫–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (–µ–ø—ñ–∑–æ–¥–∏ 200-500)**
- –†—ñ–∑–∫–µ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è –Ω–∞–≥–æ—Ä–æ–¥–∏: -200 ‚Üí -140
- Q-values –ø–æ—á–∏–Ω–∞—é—Ç—å convergence
- –ê–≥–µ–Ω—Ç –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –ø–µ—Ä—à—ñ —É—Å–ø—ñ—à–Ω—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó
- **–ö—Ä–∏—Ç–∏—á–Ω–∏–π –º–æ–º–µ–Ω—Ç:** discovery of momentum technique

**–§–∞–∑–∞ 3: –¢–æ–Ω–∫–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è (–µ–ø—ñ–∑–æ–¥–∏ 500-800)**
- –ü–æ—Å—Ç—É–ø–æ–≤–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è: -140 ‚Üí -120
- –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –≤–∂–µ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π
- –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è "–±—ñ–ª–∏—Ö –ø–ª—è–º" Q-—Ç–∞–±–ª–∏—Ü—ñ
- **Convergence** –¥–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó –ø–æ–ª—ñ—Ç–∏–∫–∏

**–§–∞–∑–∞ 4: –°—Ç–∞–±—ñ–ª—ñ–∑–∞—Ü—ñ—è (–µ–ø—ñ–∑–æ–¥–∏ 800-1000)**
- –°—Ç–∞–±—ñ–ª—å–Ω–∞ –Ω–∞–≥–æ—Ä–æ–¥–∞: ~-110 –¥–æ -120
- –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –∫–æ–ª–∏–≤–∞–Ω–Ω—è
- Q-Learning converged
- **Optimal policy** –∑–Ω–∞–π–¥–µ–Ω–æ

**–î–∏–Ω–∞–º—ñ–∫–∞ —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ (–ø—Ä–∞–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫):**

**–§–∞–∑–∞ 1 (0-200):** Success rate ~0%
- Exploration, –Ω–µ–º–∞—î –∑–Ω–∞–Ω—å

**–§–∞–∑–∞ 2 (200-500):** –†—ñ–∑–∫–∏–π —Ä—ñ—Å—Ç –¥–æ ~60-70%
- Breakthrough –º–æ–º–µ–Ω—Ç
- –ó–Ω–∞–π–¥–µ–Ω–æ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è

**–§–∞–∑–∞ 3 (500-800):** –†—ñ—Å—Ç –¥–æ ~80-85%
- Fine-tuning –ø–æ–ª—ñ—Ç–∏–∫–∏

**–§–∞–∑–∞ 4 (800-1000):** –ü–ª–∞—Ç–æ –Ω–∞ ~85-90%
- –î–æ—Å—è–≥–Ω–µ–Ω–Ω—è –º–∞–π–∂–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó –ø–æ–ª—ñ—Ç–∏–∫–∏

**–ö–ª—é—á–æ–≤—ñ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**

1. **Sample efficiency:**
   - ~500 –µ–ø—ñ–∑–æ–¥—ñ–≤ –¥–ª—è –ø—Ä–∏–π–Ω—è—Ç–Ω–æ—ó –ø–æ–ª—ñ—Ç–∏–∫–∏
   - ~800 –µ–ø—ñ–∑–æ–¥—ñ–≤ –¥–ª—è –º–∞–π–∂–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó
   - –í—ñ–¥–Ω–æ—Å–Ω–æ —à–≤–∏–¥–∫–∏–π convergence

2. **Exploration-exploitation trade-off:**
   - –ü–æ—á–∞—Ç–∫–æ–≤–∏–π exploration –∫—Ä–∏—Ç–∏—á–Ω–∏–π
   - –ü—ñ—Å–ª—è 500 –µ–ø—ñ–∑–æ–¥—ñ–≤ –±—ñ–ª—å—à–µ exploitation
   - Epsilon=0.1 –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π

3. **Variance:**
   - –í–∏—Å–æ–∫–µ variance –Ω–∞ –ø–æ—á–∞—Ç–∫—É (exploration)
   - –ó–Ω–∏–∂–µ–Ω–Ω—è variance –∑ —á–∞—Å–æ–º (convergence)
   - –ó–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è (window=100) –ø–æ–∫–∞–∑—É—î —Ç—Ä–µ–Ω–¥

4. **Plateau –µ—Ñ–µ–∫—Ç:**
   - Success rate —Å—Ç–∞–±—ñ–ª—ñ–∑—É—î—Ç—å—Å—è –Ω–∞ 85-90%, –Ω–µ 100%
   - –ü—Ä–∏—á–∏–Ω–∏:
     - Epsilon=0.1 ‚Üí 10% random actions
     - –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—è 20x20 ‚Üí –≤—Ç—Ä–∞—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ
     - –°—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω—ñ—Å—Ç—å —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞

**–ú–æ–∂–ª–∏–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:**
- –î–µ–∫–∞—é—á–∏–π epsilon (–≤—ñ–¥ 1.0 –¥–æ 0.01)
- –ë—ñ–ª—å—à —Ç–æ–Ω–∫–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—è (30x30)
- Adaptive learning rate
- Experience replay (–∞–ª–µ –¥–ª—è offline Q-learning)

---

### 5.2 –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–ª—ñ—Ç–∏–∫–∏
![Q-Learning Policy](plots/qlearning_policy_visualization.png)

**–û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –¥—ñ—ó (–ª—ñ–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫):**

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–ª—ñ—Ç–∏–∫–∏:**
–ö–æ–ª—ñ—Ä –∫–æ–¥—É—î –¥—ñ—é: —Ç–µ–º–Ω–æ-—Ñ—ñ–æ–ª–µ—Ç–æ–≤–∏–π (0=–ª—ñ–≤–æ—Ä—É—á), –∂–æ–≤—Ç–æ-–∑–µ–ª–µ–Ω–∏–π (2=–ø—Ä–∞–≤–æ—Ä—É—á)

**–ó–æ–Ω–∞ 1: –õ—ñ–≤–∞ —Å—Ç–æ—Ä–æ–Ω–∞ (position < -0.6)**
- **–î—ñ—è:** –ø–µ—Ä–µ–≤–∞–∂–Ω–æ –ü–†–ê–í–û–†–£–ß (2)
- **–õ–æ–≥—ñ–∫–∞:** —è–∫—â–æ –¥–∞–ª–µ–∫–æ –∑–ª—ñ–≤–∞, –ø–æ—á–Ω–∏ —Ä—É—Ö –¥–æ –º–µ—Ç–∏
- **–®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–µ –≤–∞–∂–ª–∏–≤–∞:** –Ω–∞–≤—ñ—Ç—å –ø—Ä–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ–π —à–≤–∏–¥–∫–æ—Å—Ç—ñ ‚Üí –ø—Ä–∞–≤–æ—Ä—É—á

**–ó–æ–Ω–∞ 2: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞ –Ω–∏–∂–Ω—è (position -0.6 –¥–æ -0.2, velocity ‚âà 0)**
- **–î—ñ—è:** –õ–Ü–í–û–†–£–ß (0)
- **–õ–æ–≥—ñ–∫–∞:** –ö–õ–Æ–ß–û–í–ê –¢–ï–•–ù–Ü–ö–ê - —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è!
- **–§—ñ–∑–∏–∫–∞:** –π–¥–∏ –ª—ñ–≤–æ—Ä—É—á-–≤–Ω–∏–∑ –¥–ª—è –Ω–∞–±–æ—Ä—É —ñ–Ω–µ—Ä—Ü—ñ—ó
- **–¶–µ —Ç–µ, —á–æ–≥–æ –Ω–µ –≤–º—ñ—î –ø—Ä–æ—Å—Ç–∞ velocity —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è!**

**–ó–æ–Ω–∞ 3: –†—É—Ö –≤–ª—ñ–≤–æ –∑ —à–≤–∏–¥–∫—ñ—Å—Ç—é (velocity < 0)**
- **–î—ñ—è:** –õ–Ü–í–û–†–£–ß (0)
- **–õ–æ–≥—ñ–∫–∞:** –ø—ñ–¥—Å–∏–ª—é–π —Ä—É—Ö –≤–ª—ñ–∑ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–≥–æ–Ω—É

**–ó–æ–Ω–∞ 4: –†–æ–∑–≤–æ—Ä–æ—Ç (position < 0, velocity –ø–æ—á–∏–Ω–∞—î —Ä–æ—Å—Ç–∏)**
- **–î—ñ—è:** –ü–†–ê–í–û–†–£–ß (2)
- **–õ–æ–≥—ñ–∫–∞:** –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π –Ω–∞–±—Ä–∞–Ω—É —ñ–Ω–µ—Ä—Ü—ñ—é –¥–ª—è –ø—ñ–¥–π–æ–º—É

**–ó–æ–Ω–∞ 5: –§—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–∏–≤–æ–∫ (position > 0, velocity > 0)**
- **–î—ñ—è:** –ü–†–ê–í–û–†–£–ß (2)
- **–õ–æ–≥—ñ–∫–∞:** –º–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –¥–æ –º–µ—Ç–∏
- **–ö—Ä–∏—Ç–∏—á–Ω–æ:** –Ω–µ –∑—É–ø–∏–Ω—è—Ç–∏—Å—å!

**–ó–æ–Ω–∞ 6: –ë—ñ–ª—è –º–µ—Ç–∏ (position > 0.3)**
- **–î—ñ—è:** —Å—Ç–∞–±—ñ–ª—å–Ω–æ –ü–†–ê–í–û–†–£–ß (2)
- **–õ–æ–≥—ñ–∫–∞:** –¥–æ–ø–æ–≤–∑—Ç–∏ –¥–æ —Ñ—ñ–Ω—ñ—à—É

**Q-–∑–Ω–∞—á–µ–Ω–Ω—è (–ø—Ä–∞–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫):**

**–†–æ–∑–ø–æ–¥—ñ–ª —Ü—ñ–Ω–Ω–æ—Å—Ç—ñ —Å—Ç–∞–Ω—ñ–≤:**

**–í–∏—Å–æ–∫—ñ Q-values (—á–µ—Ä–≤–æ–Ω—ñ –∑–æ–Ω–∏):**
- **Position > 0.3, velocity > 0:** –Ω–∞–π—Ü—ñ–Ω–Ω—ñ—à—ñ —Å—Ç–∞–Ω–∏
- **–ü–æ—è—Å–Ω–µ–Ω–Ω—è:** –±–ª–∏–∑—å–∫–æ –¥–æ –º–µ—Ç–∏ –∑ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ—é —à–≤–∏–¥–∫—ñ—Å—Ç—é
- **Q-value:** –±–ª–∏–∑—å–∫–æ –¥–æ 0 (—à–≤–∏–¥–∫–∏–π —É—Å–ø—ñ—Ö, –º–∞–ª–æ —à—Ç—Ä–∞—Ñ—ñ–≤)

**–°–µ—Ä–µ–¥–Ω—ñ Q-values (–∂–æ–≤—Ç—ñ):**
- **Position 0 –¥–æ 0.3, velocity > 0.03:** promising states
- **–ù–∞ —à–ª—è—Ö—É –¥–æ —É—Å–ø—ñ—Ö—É**
- **Q-value:** -50 –¥–æ -100

**–ù–∏–∑—å–∫—ñ Q-values (—Å–∏–Ω—ñ –∑–æ–Ω–∏):**
- **Position < -0.6, velocity ‚âà 0:** –¥–∞–ª–µ–∫–æ –≤—ñ–¥ –º–µ—Ç–∏, –±–µ–∑ —à–≤–∏–¥–∫–æ—Å—Ç—ñ
- **–ü–æ—Ç—Ä—ñ–±–Ω–æ –±–∞–≥–∞—Ç–æ –∫—Ä–æ–∫—ñ–≤:** –¥–æ–≤–≥–∏–π —à–ª—è—Ö –¥–æ –º–µ—Ç–∏
- **Q-value:** -150 –¥–æ -200

**–ù–∞–π–≥—ñ—Ä—à—ñ Q-values (—Ç–µ–º–Ω–æ-—Å–∏–Ω—ñ):**
- **Position < -1.0, velocity < 0:** —Ä—É—Ö –≤ –ø—Ä–æ—Ç–∏–ª–µ–∂–Ω–∏–π –±—ñ–∫
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–∞–ª–µ–∫–æ –≤—ñ–¥ –º–µ—Ç–∏**

**Value function gradient:**
- –ü–ª–∞–≤–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç –≤—ñ–¥ —Å–∏–Ω—å–æ–≥–æ –¥–æ —á–µ—Ä–≤–æ–Ω–æ–≥–æ
- –ù–∞–ø—Ä—è–º –≥—Ä–∞–¥—ñ—î–Ω—Ç—É: –ª—ñ–≤–æ-–Ω–∏–∑ ‚Üí –ø—Ä–∞–≤–æ-–≤–µ—Ä—Ö
- **–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:** —á—ñ—Ç–∫–∏–π –Ω–∞–ø—Ä—è–º–æ–∫ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è

**–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ –µ–≤—Ä–∏—Å—Ç–∏–∫–∞–º–∏:**

**Q-Learning –Ω–∞–≤—á–∏–≤—Å—è:**
‚úÖ –†–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—é (–∑–æ–Ω–∞ 2) - —Ü–µ –Ω–µ –æ—á–µ–≤–∏–¥–Ω–æ!  
‚úÖ –ö–æ–ª–∏ –ø–æ—á–∏–Ω–∞—Ç–∏ —Ä—É—Ö –ø—Ä–∞–≤–æ—Ä—É—á (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –º–æ–º–µ–Ω—Ç)  
‚úÖ –ê–≥—Ä–µ—Å–∏–≤–Ω–æ–º—É –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—é –±—ñ–ª—è –º–µ—Ç–∏  

**–ü—Ä–æ—Å—Ç–∞ Velocity —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:**
‚ùå –ù–µ —Ä–æ–∑—É–º—ñ—î —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è  
‚ùå –õ—ñ–Ω—ñ–π–Ω–æ —Ä–µ–∞–≥—É—î –Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å  
‚ùå –ù–µ–º–∞—î —Ä–æ–∑—É–º—ñ–Ω–Ω—è "—Ü—ñ–Ω–Ω–æ—Å—Ç—ñ" —Å—Ç–∞–Ω—ñ–≤  

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:**
‚ö†Ô∏è –ó–∞–∫–æ–¥–æ–≤–∞–Ω–æ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è –≤—Ä—É—á–Ω—É  
‚ö†Ô∏è –ü—Ä–∞—Ü—é—î, –∞–ª–µ –Ω–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞  
‚ö†Ô∏è –ù–µ –∞–¥–∞–ø—Ç—É—î—Ç—å—Å—è –¥–æ –∑–º—ñ–Ω —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞  

**–§—ñ–∑–∏—á–Ω–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:**
Q-Learning –≤—ñ–¥–∫—Ä–∏–≤ –ø—Ä–∏–Ω—Ü–∏–ø **–∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –µ–Ω–µ—Ä–≥—ñ—ó**:
- –°–ø—É—Å—Ç–∏—Å—å –≤–Ω–∏–∑ (–Ω–∞–±–µ—Ä–∏ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω—É ‚Üí –∫—ñ–Ω–µ—Ç–∏—á–Ω—É)
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π —ñ–Ω–µ—Ä—Ü—ñ—é –¥–ª—è –ø—ñ–¥–π–æ–º—É
- –ú—ñ–Ω—ñ–º—ñ–∑—É–π –≤—Ç—Ä–∞—Ç–∏ –µ–Ω–µ—Ä–≥—ñ—ó

---

### 5.3 –¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó Q-Learning
![Q-Learning Trajectories](plots/trajectories_Q-Learning_bins20.png)

**–ï–ø—ñ–∑–æ–¥ 1 - ‚úì –£–°–ü–Ü–• (–∫—Ä–æ–∫—ñ–≤: ~110):**

**–§–∞–∑–∞ 1: –†–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è (–∫—Ä–æ–∫–∏ 0-40)**
- –ü–æ–∑–∏—Ü—ñ—è: -0.5 ‚Üí -1.1 ‚Üí -0.5
- –®–≤–∏–¥–∫—ñ—Å—Ç—å: –∫–æ–ª–∏–≤–∞–Ω–Ω—è ¬±0.04
- **–°—Ç—Ä–∞—Ç–µ–≥—ñ—è:** –Ω–∞–≤–º–∏—Å–Ω–∏–π —Ä—É—Ö –ª—ñ–≤–æ—Ä—É—á-–≤–Ω–∏–∑

**–§–∞–∑–∞ 2: –ù–∞–±—ñ—Ä —ñ–Ω–µ—Ä—Ü—ñ—ó (–∫—Ä–æ–∫–∏ 40-70)**
- –ü–æ–∑–∏—Ü—ñ—è: –¥–æ—Å—è–≥–∞—î –º—ñ–Ω—ñ–º—É–º—É -1.1
- –®–≤–∏–¥–∫—ñ—Å—Ç—å: –∑—Ä–æ—Å—Ç–∞—î –¥–æ +0.05
- **–ö—Ä–∏—Ç–∏—á–Ω–∏–π –º–æ–º–µ–Ω—Ç:** —Ä–æ–∑–≤–æ—Ä–æ—Ç –Ω–∞ –¥–Ω—ñ

**–§–∞–∑–∞ 3: –ü—ñ–¥–π–æ–º (–∫—Ä–æ–∫–∏ 70-100)**
- –ü–æ–∑–∏—Ü—ñ—è: -1.1 ‚Üí 0.5
- –®–≤–∏–¥–∫—ñ—Å—Ç—å: —Å—Ç–∞–±—ñ–ª—å–Ω–∞ +0.04 –¥–æ +0.06
- **–°—Ç—Ä–∞—Ç–µ–≥—ñ—è:** –º–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –ø—Ä–∞–≤–æ—Ä—É—á

**–§–∞–∑–∞ 4: –§—ñ–Ω—ñ—à (–∫—Ä–æ–∫–∏ 100-110)**
- –ü–æ–∑–∏—Ü—ñ—è: –ø–µ—Ä–µ—Ç–∏–Ω 0.5
- **–£–°–ü–Ü–•!**

**–ï–ø—ñ–∑–æ–¥ 2 - ‚úì –£–°–ü–Ü–• (–∫—Ä–æ–∫—ñ–≤: ~115):**
- –°—Ö–æ–∂–∏–π –ø–∞—Ç–µ—Ä–Ω
- –¢—Ä–æ—Ö–∏ –±—ñ–ª—å—à–µ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω—å (2 —Ü–∏–∫–ª–∏)
- –î–æ–≤—à–∏–π —á–∞—Å, –∞–ª–µ –≤—Å–µ —â–µ —É—Å–ø—ñ—à–Ω–∏–π

**–ï–ø—ñ–∑–æ–¥ 3 - ‚úì –£–°–ü–Ü–• (–∫—Ä–æ–∫—ñ–≤: ~105):**
- –ù–∞–π–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è
- –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –æ–¥–∏–Ω —Ü–∏–∫–ª —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è
- –®–≤–∏–¥–∫–µ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è –º–µ—Ç–∏

**–ö–ª—é—á–æ–≤—ñ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**

1. **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å:**
   - –í—Å—ñ 3 –µ–ø—ñ–∑–æ–¥–∏ —É—Å–ø—ñ—à–Ω—ñ
   - –°—Ö–æ–∂–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ–π
   - –ü—ñ–¥—Ç–≤–µ—Ä–¥–∂—É—î —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –ø–æ–ª—ñ—Ç–∏–∫–∏

2. **–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –ø–∞—Ç–µ—Ä–Ω:**
   - 1-2 —Ü–∏–∫–ª–∏ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è
   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≥–ª–∏–±–∏–Ω–∞: -1.1 –¥–æ -1.15
   - –ü–ª–∞–≤–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –ø—Ä–∞–≤–æ—Ä—É—á

3. **–®–≤–∏–¥–∫—ñ—Å—Ç—å vs –ü–æ–∑–∏—Ü—ñ—è:**
   - –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–æ–≤–∞–Ω—ñ –∫–æ–ª–∏–≤–∞–Ω–Ω—è
   - Phase shift: —à–≤–∏–¥–∫—ñ—Å—Ç—å –≤–∏–ø–µ—Ä–µ–¥–∂—É—î –ø–æ–∑–∏—Ü—ñ—é
   - **–§—ñ–∑–∏–∫–∞:** –∫–ª–∞—Å–∏—á–Ω–∏–π –≥–∞—Ä–º–æ–Ω—ñ—á–Ω–∏–π –æ—Å—Ü–∏–ª—è—Ç–æ—Ä

4. **–ï–Ω–µ—Ä–≥–µ—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑:**
   - –ü–æ—á–∞—Ç–∫–æ–≤–∞ –µ–Ω–µ—Ä–≥—ñ—è: –Ω–∏–∑—å–∫–∞
   - –ü—ñ—Å–ª—è —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è: –≤–∏—Å–æ–∫–∞
   - –î–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –ø–æ–¥–æ–ª–∞–Ω–Ω—è –±–∞—Ä'—î—Ä—É

---

### 5.4 –¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –ø–æ–∫—Ä–∞—â–µ–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó
![Advanced Strategy Trajectories](plots/trajectories_–ü–æ–∫—Ä–∞—â–µ–Ω–∞_—Å—Ç—Ä–∞—Ç–µ–≥—ñ—è_–ø–æ–∑–∏—Ü—ñ—è_+_—à–≤–∏–¥–∫—ñ—Å—Ç—å.png)

**–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ Q-Learning:**

**–ï–ø—ñ–∑–æ–¥ 1 - ‚úì –£–°–ü–Ü–•:**
- –î–æ–≤—à–∏–π (~140 –∫—Ä–æ–∫—ñ–≤)
- –ë—ñ–ª—å—à–µ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω—å (3-4 —Ü–∏–∫–ª–∏)
- –ú–µ–Ω—à –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è
- **–ü—Ä–∏—á–∏–Ω–∞:** –µ–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞

**–ï–ø—ñ–∑–æ–¥ 2 - ‚úó –ù–ï–í–î–ê–ß–ê:**
- –ó–∞—Å—Ç—Ä—è–≤ –Ω–∞ –ø–æ–∑–∏—Ü—ñ—ó ~0.3
- –ù–µ –≤–∏—Å—Ç–∞—á–∏–ª–æ —ñ–Ω–µ—Ä—Ü—ñ—ó –¥–ª—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∏–≤–∫–∞
- –í–µ–ª–∏–∫–∞ –∞–º–ø–ª—ñ—Ç—É–¥–∞ –∫–æ–ª–∏–≤–∞–Ω—å —à–≤–∏–¥–∫–æ—Å—Ç—ñ
- **–ü—Ä–æ–±–ª–µ–º–∞:** —Å—É–±–æ–ø—Ç–∏–º–∞–ª—å–Ω–µ —Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ —Ä–æ–∑–≤–æ—Ä–æ—Ç

**–ï–ø—ñ–∑–æ–¥ 3 - ‚úì –£–°–ü–Ü–•:**
- –£—Å–ø—ñ—à–Ω–∏–π, –∞–ª–µ ~150 –∫—Ä–æ–∫—ñ–≤
- –ë–∞–≥–∞—Ç–æ –∑–∞–π–≤–∏—Ö —Ä—É—Ö—ñ–≤
- –ù–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å

**–ö–ª—é—á–æ–≤—ñ –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤—ñ–¥ Q-Learning:**

**Q-Learning:**
‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω—å  
‚úÖ –¢–æ—á–Ω–∏–π –º–æ–º–µ–Ω—Ç —Ä–æ–∑–≤–æ—Ä–æ—Ç—É  
‚úÖ –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫—Ä–æ–∫—ñ–≤  
‚úÖ 100% success –≤ –ø–æ–∫–∞–∑–∞–Ω–∏—Ö –µ–ø—ñ–∑–æ–¥–∞—Ö  

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ –µ–≤—Ä–∏—Å—Ç–∏–∫–∞:**
‚ö†Ô∏è –ù–∞–¥–ª–∏—à–∫–æ–≤—ñ —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è  
‚ö†Ô∏è –ù–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π timing  
‚ö†Ô∏è –ë—ñ–ª—å—à–µ –∫—Ä–æ–∫—ñ–≤  
‚ùå –Ü–Ω–æ–¥—ñ –Ω–µ–≤–¥–∞—á—ñ  

**–ß–æ–º—É Q-Learning –∫—Ä–∞—â–∏–π:**

1. **–ù–∞–≤—á–∞–Ω–Ω—è –∑ –¥–æ—Å–≤—ñ–¥—É:**
   - –ë–∞—á–∏–≤ —Ç–∏—Å—è—á—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ–π
   - –ó–Ω–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ –¥—ñ—ó –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å—Ç–∞–Ω—É
   - –ê–¥–∞–ø—Ç–∏–≤–Ω–∏–π –¥–æ –Ω—é–∞–Ω—Å—ñ–≤

2. **–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ü—ñ–ª—ñ:**
   - –ë–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –º—ñ–Ω—ñ–º—ñ–∑—É—î –∫—Ä–æ–∫–∏
   - –ú–∞–∫—Å–∏–º—ñ–∑—É—î cumulative reward
   - Optimal policy –∑–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º

3. **–í—Ä–∞—Ö—É–≤–∞–Ω–Ω—è –¥–∏–Ω–∞–º—ñ–∫–∏:**
   - –†–æ–∑—É–º—ñ—î —Ñ—ñ–∑–∏–∫—É —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
   - –í—Ä–∞—Ö–æ–≤—É—î –∑–∞—Ç—Ä–∏–º–∫–∏ —Ç–∞ —ñ–Ω–µ—Ä—Ü—ñ—é
   - –ü–µ—Ä–µ–¥–±–∞—á–∞—î –º–∞–π–±—É—Ç–Ω—ñ —Å—Ç–∞–Ω–∏

**–ß–æ–º—É –µ–≤—Ä–∏—Å—Ç–∏–∫–∞ –º–∞—î –ø—Ä–∞–≤–æ –Ω–∞ –∂–∏—Ç—Ç—è:**

‚úÖ –ü—Ä–∞—Ü—é—î –±–µ–∑ –Ω–∞–≤—á–∞–Ω–Ω—è (0 –µ–ø—ñ–∑–æ–¥—ñ–≤)  
‚úÖ –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–∞ (–∑—Ä–æ–∑—É–º—ñ–ª—ñ –ø—Ä–∞–≤–∏–ª–∞)  
‚úÖ –®–≤–∏–¥–∫–∞ (–Ω–µ–º–∞—î –æ–±—á–∏—Å–ª–µ–Ω—å Q-values)  
‚úÖ 35-45% success - –∫—Ä–∞—â–µ –∑–∞ –≤–∏–ø–∞–¥–∫–æ–≤–µ  

**–í–∏—Å–Ω–æ–≤–æ–∫:**
Trade-off –º—ñ–∂ "–ø—Ä–∞—Ü—é—î –æ–¥—Ä–∞–∑—É" (–µ–≤—Ä–∏—Å—Ç–∏–∫–∞) —Ç–∞ "–ø—Ä–∞—Ü—é—î –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ" (Q-Learning).

---

## 6. –ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

### 6.1 –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π

**–ó–≤'—è–∑–æ–∫ –º—ñ–∂ –¥–≤–æ–º–∞ –ø—ñ–¥—Ö–æ–¥–∞–º–∏:**

**Supervised Learning (–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è):**
- –ó–∞–¥–∞—á–∞: –ø–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ success/failure –ø–æ –æ–∑–Ω–∞–∫–∞—Ö –µ–ø—ñ–∑–æ–¥—É
- –†–µ–∑—É–ª—å—Ç–∞—Ç: Gradient Boosting –¥–æ—Å—è–≥ AUC 0.98
- Insights: `max_position_reached` - –¥–æ–º—ñ–Ω—É—é—á–∞ –æ–∑–Ω–∞–∫–∞

**Reinforcement Learning (–°—Ç—Ä–∞—Ç–µ–≥—ñ—ó):**
- –ó–∞–¥–∞—á–∞: –Ω–∞–≤—á–∏—Ç–∏ –ø–æ–ª—ñ—Ç–∏–∫—É –¥–æ—Å—è–≥–∞—Ç–∏ –º–µ—Ç–∏
- –†–µ–∑—É–ª—å—Ç–∞—Ç: Q-Learning –¥–æ—Å—è–≥ 85-90% success rate
- Insights: —Ä–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è - –∫–ª—é—á–æ–≤–∞ —Ç–µ—Ö–Ω—ñ–∫–∞

**–°–∏–Ω–µ—Ä–≥—ñ—è:**

1. **–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —è–∫ –∫—Ä–∏—Ç–∏–∫:**
   - –ú–æ–∂–µ –æ—Ü—ñ–Ω–∏—Ç–∏ —è–∫—ñ—Å—Ç—å —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –Ω–∞ –ª—å–æ—Ç—É
   - Early stopping –¥–ª—è –±–µ–∑–Ω–∞–¥—ñ–π–Ω–∏—Ö –µ–ø—ñ–∑–æ–¥—ñ–≤
   - Predict success probability

2. **RL —è–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞–Ω–∏—Ö:**
   - Q-Learning —Å—Ç–≤–æ—Ä—é—î —è–∫—ñ—Å–Ω—ñ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç—É
   - –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π dataset –∑–∞–≤–¥—è–∫–∏ —Ä–æ–∑—É–º–Ω—ñ–π –ø–æ–ª—ñ—Ç–∏—Ü—ñ

3. **Feature importance ‚Üí Reward shaping:**
   - –í–∞–∂–ª–∏–≤—ñ –æ–∑–Ω–∞–∫–∏ (max_position) –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –¥–æ reward
   - –ü—Ä–∏—Å–∫–æ—Ä–∏—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è RL

**–ü—Ä–∞–∫—Ç–∏—á–Ω–µ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è:**

```python
# Hybrid –ø—ñ–¥—Ö—ñ–¥
def should_continue_episode(current_state, classifier):
    features = extract_features(trajectory_so_far)
    success_probability = classifier.predict_proba(features)
    
    if success_probability < 0.1 and steps > 100:
        return False  # Early stopping
    return True
```

---

### 6.2 –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

**–î–ª—è prediction tasks (–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ):**

**–í–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ:**
1. **Production:** Gradient Boosting
   - –ù–∞–π–≤–∏—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (AUC 0.98)
   - –°—Ç–∞–±—ñ–ª—å–Ω—ñ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—è
   - –ì—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏: `n_estimators=100`, `learning_rate=0.1`

2. **Fast prototyping:** Logistic Regression
   - –®–≤–∏–¥–∫–µ –Ω–∞–≤—á–∞–Ω–Ω—è (< 1 —Å–µ–∫)
   - –ü—Ä–∏–π–Ω—è—Ç–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (AUC 0.93)
   - –õ–µ–≥–∫–æ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É–≤–∞—Ç–∏ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏

3. **Edge devices:** Linear SVM
   - –ú–∞–ª–∏–π —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ
   - –®–≤–∏–¥–∫–∏–π inference
   - –ù–µ –ø–æ—Ç—Ä–µ–±—É—î –±–∞–≥–∞—Ç–æ –ø–∞–º'—è—Ç—ñ

**Feature engineering:**
- ‚úÖ –û–±–æ–≤'—è–∑–∫–æ–≤–æ: `max_position_reached`, `energy_max`, `positive_velocity_ratio`
- ‚ö†Ô∏è –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ: `velocity_abs_mean`, `high_velocity_ratio`
- ‚ùå –ú–æ–∂–Ω–∞ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏: `initial_position`, `initial_velocity`

**–ó–±—ñ—Ä –¥–∞–Ω–∏—Ö:**
- –ú—ñ–Ω—ñ–º—É–º 500 –µ–ø—ñ–∑–æ–¥—ñ–≤
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ mixed strategy (70% smart, 30% random)
- –ó–∞–±–µ–∑–ø–µ—á–∏—Ç–∏ balance –∫–ª–∞—Å—ñ–≤ (40-60% –∫–æ–∂–Ω–æ–≥–æ)

---

**–î–ª—è control tasks (–≤–∏–±—ñ—Ä –¥—ñ–π):**

**–í–∏–±—ñ—Ä —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó:**

**Scenario 1: Offline –Ω–∞–≤—á–∞–Ω–Ω—è –¥–æ—Å—Ç—É–ø–Ω–µ**
- ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Q-Learning
- –ù–∞–≤—á–∏—Ç–∏ –Ω–∞ 800-1000 –µ–ø—ñ–∑–æ–¥—ñ–≤
- –î–æ—Å—è–≥—Ç–∏ 85-90% success rate
- Deployment: lookup table (—à–≤–∏–¥–∫–æ)

**Scenario 2: Online learning (real-time)**
- ‚úÖ –ü–æ–∫—Ä–∞—â–µ–Ω–∞ –µ–≤—Ä–∏—Å—Ç–∏—á–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è
- –ü—Ä–∞—Ü—é—î –æ–¥—Ä–∞–∑—É –±–µ–∑ –Ω–∞–≤—á–∞–Ω–Ω—è
- 35-45% success rate
- –ú–æ–∂–Ω–∞ –∫–æ–º–±—ñ–Ω—É–≤–∞—Ç–∏ –∑ adaptive learning

**Scenario 3: Exploration –≤–∞–∂–ª–∏–≤–∏–π**
- ‚úÖ Epsilon-Greedy (Œµ=0.1-0.2)
- –ë–∞–ª–∞–Ω—Å –≤—ñ–¥–æ–º–∏—Ö —ñ –Ω–æ–≤–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π
- –ö–æ—Ä–∏—Å–Ω–æ –¥–ª—è non-stationary environments

**Scenario 4: –û–±–º–µ–∂–µ–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è**
- ‚úÖ Velocity-based —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è
- –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è
- –ö—Ä–∞—â–∏–π baseline –Ω—ñ–∂ random

**–ì—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏ Q-Learning:**
```python
optimal_params = {
    'n_bins': 20,  # 20x20 discretization
    'learning_rate': 0.1,
    'gamma': 0.99,  # high discount (long-term thinking)
    'epsilon': 0.1,  # 10% exploration
    'n_training_episodes': 800
}
```

---

### 6.3 –ù–∞—É–∫–æ–≤—ñ —ñ–Ω—Å–∞–π—Ç–∏

**–§—ñ–∑–∏–∫–∞ –∑–∞–¥–∞—á—ñ:**

1. **–ï–Ω–µ—Ä–≥–µ—Ç–∏—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥:**
   - MountainCar - —Ü–µ –∑–∞–¥–∞—á–∞ –ø—Ä–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –µ–Ω–µ—Ä–≥—ñ—ó
   - –ü–æ—Ç–µ–Ω—Ü—ñ–∞–ª—å–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è: E_p = m*g*h
   - –ö—ñ–Ω–µ—Ç–∏—á–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è: E_k = 0.5*m*v¬≤
   - –¶—ñ–ª—å: –Ω–∞–∫–æ–ø–∏—á–∏—Ç–∏ E_k + E_p > threshold

2. **–ì–∞—Ä–º–æ–Ω—ñ—á–Ω—ñ –∫–æ–ª–∏–≤–∞–Ω–Ω—è:**
   - –†–æ–∑–≥–æ–π–¥—É–≤–∞–Ω–Ω—è - —Ü–µ forced oscillations
   - –†–µ–∑–æ–Ω–∞–Ω—Å –¥–æ—Å—è–≥–∞—î—Ç—å—Å—è –ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ç–∞–π–º —Å–∏–Ω–≥—É
   - Q-Learning –∑–Ω–∞–π—à–æ–≤ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—É —á–∞—Å—Ç–æ—Ç—É

3. **–§–∞–∑–æ–≤–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä:**
   - (position, velocity) —É—Ç–≤–æ—Ä—é—é—Ç—å —Ñ–∞–∑–æ–≤–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä
   - –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—è - —Å–ø—ñ—Ä–∞–ª—å –¥–æ –º–µ—Ç–∏
   - Separatrix –ø–æ–¥—ñ–ª—è—î success/failure —Ä–µ–≥—ñ–æ–Ω–∏

**Machine Learning —ñ–Ω—Å–∞–π—Ç–∏:**

1. **Feature engineering > Raw data:**
   - –ê–≥—Ä–µ–≥–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏ (max, mean, ratio) –∫—Ä–∞—â—ñ –∑–∞ raw states
   - Temporal features –º–∞—é—Ç—å predictive power
   - Domain knowledge –∫—Ä–∏—Ç–∏—á–Ω–∏–π

2. **Tree ensembles > Linear models:**
   - –î–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –Ω–µ–ª—ñ–Ω—ñ–π–Ω–∏—Ö –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
   - –ê–ª–µ –ª—ñ–Ω—ñ–π–Ω—ñ –º–æ–¥–µ–ª—ñ —Ç–µ–∂ –ø—Ä–∞—Ü—é—é—Ç—å (AUC 0.92)
   - ‚Üí –ó–∞–¥–∞—á–∞ –º–∞—î underlying linear structure

3. **RL learns better than engineering:**
   - Q-Learning 2x –∫—Ä–∞—â–∏–π –∑–∞ hand-crafted heuristics
   - –ê–ª–µ –ø–æ—Ç—Ä–µ–±—É—î 1000x –±—ñ–ª—å—à–µ samples
   - Trade-off: sample efficiency vs performance

**Transferable lessons:**

1. **Balanced data –∫—Ä–∏—Ç–∏—á–Ω–∏–π:**
   - –ë–µ–∑ –±–∞–ª–∞–Ω—Å—É - –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–º–æ–∂–ª–∏–≤–µ
   - Mixed strategy –¥–ª—è data collection

2. **Start state –Ω–µ –∑–∞–≤–∂–¥–∏ –≤–∞–∂–ª–∏–≤–∏–π:**
   - Trajectory matters more than initial conditions
   - Markov property –≤ –±–∞–≥–∞—Ç—å–æ—Ö RL tasks

3. **Exploration essential:**
   - –ë–µ–∑ exploration –Ω–µ–º–æ–∂–ª–∏–≤–æ –∑–Ω–∞–π—Ç–∏ optimal policy
   - –ù–∞–≤—ñ—Ç—å 10% exploration (Œµ=0.1) –¥–æ—Å—Ç–∞—Ç–Ω—å–æ

---

### 6.4 –û–±–º–µ–∂–µ–Ω–Ω—è —Ç–∞ –º–∞–π–±—É—Ç–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è

**–ü–æ—Ç–æ—á–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è:**

**–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è:**
1. Overfitting risk –Ω–∞ –º–∞–ª–∏—Ö –¥–∞–Ω–∏—Ö (1000 samples)
2. Features –ø–æ—Ç—Ä–µ–±—É—é—Ç—å full trajectory (–Ω–µ online)
3. –ù–µ –≤—Ä–∞—Ö–æ–≤—É—î temporal dependencies
4. –ù–µ generalize –Ω–∞ —ñ–Ω—à—ñ MountainCar variants

**Q-Learning:**
1. –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—è 20x20 - –≤—Ç—Ä–∞—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ
2. Plateau –Ω–∞ 85-90% (–Ω–µ 100%)
3. 800 –µ–ø—ñ–∑–æ–¥—ñ–≤ –Ω–∞–≤—á–∞–Ω–Ω—è - –¥–æ–≤–≥–æ
4. –ù–µ transferable –Ω–∞ —ñ–Ω—à—ñ tasks

**–ú–∞–π–±—É—Ç–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:**

**–î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:**
1. **–ë—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö:** 5000-10000 –µ–ø—ñ–∑–æ–¥—ñ–≤
2. **Sequential models:** LSTM –¥–ª—è temporal patterns
3. **Online features:** predict –Ω–∞ —á–∞—Å—Ç–∫–æ–≤—ñ–π —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó
4. **Multi-task learning:** predict —Ä—ñ–∑–Ω—ñ metrics –æ–¥–Ω–æ—á–∞—Å–Ω–æ

**–î–ª—è RL:**
1. **Function approximation:** neural network –∑–∞–º—ñ—Å—Ç—å Q-table
   - –ë–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω—ñ states, no discretization
   - Generalization –º—ñ–∂ —Å—Ö–æ–∂–∏–º–∏ states

2. **Deep Q-Learning (DQN):**
   - CNN/MLP –¥–ª—è Q-function
   - Experience replay
   - Target network

3. **Policy gradient methods:**
   - REINFORCE, A2C, PPO
   - –ë–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –æ–ø—Ç–∏–º—ñ–∑—É—î –ø–æ–ª—ñ—Ç–∏–∫—É
   - –ö—Ä–∞—â–µ –¥–ª—è continuous actions

4. **Adaptive parameters:**
   - Decaying epsilon: 1.0 ‚Üí 0.01
   - Adaptive learning rate
   - Automatic hyperparameter tuning

5. **Reward shaping:**
   - –î–æ–¥–∞—Ç–∏ –ø—Ä–æ–º—ñ–∂–Ω—ñ rewards –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å
   - –ü—Ä–∏—Å–∫–æ—Ä–∏—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è –∑ 800 –¥–æ 300 –µ–ø—ñ–∑–æ–¥—ñ–≤

6. **Transfer learning:**
   - Pre-train –Ω–∞ —Å—Ö–æ–∂–∏—Ö tasks
   - Fine-tune –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ

**–†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ:**

1. **Continuous MountainCar:**
   - Continuous action space
   - –ë—ñ–ª—å—à —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–æ

2. **MountainCar –∑ –ø–µ—Ä–µ—à–∫–æ–¥–∞–º–∏:**
   - –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å
   - –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ robustness

3. **Multi-agent MountainCar:**
   - –ö–æ–æ–ø–µ—Ä–∞—Ü—ñ—è/–∑–º–∞–≥–∞–Ω–Ω—è
   - –°–∫–ª–∞–¥–Ω—ñ—à–∞ –¥–∏–Ω–∞–º—ñ–∫–∞

4. **Stochastic MountainCar:**
   - Wind disturbances
   - –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ

---

### 6.5 –§—ñ–Ω–∞–ª—å–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

**–©–æ –±—É–ª–æ –¥–æ—Å—è–≥–Ω—É—Ç–æ:**

‚úÖ **–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ:** AUC 0.98 (Gradient Boosting)  
‚úÖ **–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:** 85-90% success (Q-Learning)  
‚úÖ **Feature importance:** max_position >> initial_state  
‚úÖ **RL > Heuristics:** 2x –∫—Ä–∞—â–∏–π performance  
‚úÖ **–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π dataset:** mixed strategy works  

**–ö–ª—é—á–æ–≤—ñ —ñ–Ω—Å–∞–π—Ç–∏:**

üí° **–§—ñ–∑–∏–∫–∞:** MountainCar - –∑–∞–¥–∞—á–∞ –ø—Ä–æ –µ–Ω–µ—Ä–≥—ñ—é —Ç–∞ —ñ–Ω–µ—Ä—Ü—ñ—é  
üí° **ML:** Trajectory features >> Initial state features  
üí° **RL:** Exploration –∫—Ä–∏—Ç–∏—á–Ω–∏–π –¥–ª—è –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è optimal policy  
üí° **Trade-off:** Sample efficiency vs Performance  
üí° **Synergy:** Supervised + RL –º–æ–∂—É—Ç—å –¥–æ–ø–æ–≤–Ω—é–≤–∞—Ç–∏ –æ–¥–∏–Ω –æ–¥–Ω–æ–≥–æ  

**–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å:**

üéØ Framework –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É RL tasks —á–µ—Ä–µ–∑ ML –ø—Ä–∏–∑–º—É  
üéØ –†–µ—Ü–µ–ø—Ç–∏ –¥–ª—è data collection –≤ imbalanced scenarios  
üéØ Benchmark –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤  
üéØ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–ª—è —Ä–æ–∑—É–º—ñ–Ω–Ω—è learned policies  

**–ù–∞—É–∫–æ–≤–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å:**

üî¨ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –ø–µ—Ä–µ–≤–∞–≥ data-driven –ø—ñ–¥—Ö–æ–¥—ñ–≤  
üî¨ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è feature-based vs policy-based methods  
üî¨ –ê–Ω–∞–ª—ñ–∑ convergence —Ç–∞ stability  
üî¨ Insights –ø—Ä–æ structure MountainCar task  

---

## –î–æ–¥–∞—Ç–æ–∫: –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó

–í—Å—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ñ —É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó `plots/`:

**–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö:**
- [`class_distribution.png`](plots/class_distribution.png) - –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤
- [`features_distribution.png`](plots/features_distribution.png) - –†–æ–∑–ø–æ–¥—ñ–ª 6 –∫–ª—é—á–æ–≤–∏—Ö –æ–∑–Ω–∞–∫
- [`correlation_matrix.png`](plots/correlation_matrix.png) - –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
- [`feature_importance.png`](plots/feature_importance.png) - –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (Random Forest)

**–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è:**
- [`classifiers_comparison.png`](plots/classifiers_comparison.png) - –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è 7 –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤
- [`roc_curves_all.png`](plots/roc_curves_all.png) - ROC-–∫—Ä–∏–≤—ñ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π
- [`confusion_matrices_all.png`](plots/confusion_matrices_all.png) - –ú–∞—Ç—Ä–∏—Ü—ñ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–µ–π

**–°—Ç—Ä–∞—Ç–µ–≥—ñ—ó:**
- [`strategy_comparison.png`](plots/strategy_comparison.png) - –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è 5 —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π
- [`reward_distributions.png`](plots/reward_distributions.png) - Box plots –Ω–∞–≥–æ—Ä–æ–¥
- [`episode_lengths.png`](plots/episode_lengths.png) - –ì—ñ—Å—Ç–æ–≥—Ä–∞–º–∏ –¥–æ–≤–∂–∏–Ω–∏ –µ–ø—ñ–∑–æ–¥—ñ–≤

**Q-Learning:**
- [`qlearning_learning_curve.png`](plots/qlearning_learning_curve.png) - –ö—Ä–∏–≤–∞ –Ω–∞–≤—á–∞–Ω–Ω—è
- [`qlearning_policy_visualization.png`](plots/qlearning_policy_visualization.png) - –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–ª—ñ—Ç–∏–∫–∏
- [`trajectories_Q-Learning_bins20.png`](plots/trajectories_Q-Learning_bins20.png) - –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç—Ä–∞—î–∫—Ç–æ—Ä—ñ–π

**–ï–≤—Ä–∏—Å—Ç–∏–∫–∏:**
- [`trajectories_–ü–æ–∫—Ä–∞—â–µ–Ω–∞_—Å—Ç—Ä–∞—Ç–µ–≥—ñ—è_–ø–æ–∑–∏—Ü—ñ—è_+_—à–≤–∏–¥–∫—ñ—Å—Ç—å.png`](plots/trajectories_–ü–æ–∫—Ä–∞—â–µ–Ω–∞_—Å—Ç—Ä–∞—Ç–µ–≥—ñ—è_–ø–æ–∑–∏—Ü—ñ—è_+_—à–≤–∏–¥–∫—ñ—Å—Ç—å.png) - –¢—Ä–∞—î–∫—Ç–æ—Ä—ñ—ó –ø–æ–∫—Ä–∞—â–µ–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó

---

**–î–æ–∫—É–º–µ–Ω—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ:** 2 –≥—Ä—É–¥–Ω—è 2025  
**–ü—Ä–æ–µ–∫—Ç:** Decision Strategies –¥–ª—è MountainCar  
**–î–∞—Ç–∞—Å–µ—Ç:** 1000 –µ–ø—ñ–∑–æ–¥—ñ–≤, 27 –æ–∑–Ω–∞–∫, –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π  
**–ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å:** Gradient Boosting (AUC 0.98)  
**–ù–∞–π–∫—Ä–∞—â–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è:** Q-Learning (Success Rate 85-90%)

